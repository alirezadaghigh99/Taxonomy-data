output file:
processed_pyro_calculate_knots386.json
function:
_calculate_knots
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape2]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape0]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape2]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape1] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape1]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape1] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape0] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape1]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape0] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape2] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape1]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape0] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape0]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape1] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape1]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape2] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape1] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape1] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape1] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape2]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape1]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape2]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape2] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape1] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape1] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape1] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape0] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape2] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape1]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape0] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape2] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape0]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape1] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape0] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape2] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape0]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape1]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape1] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape1]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape2]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape0] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape0]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape0]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape0] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape1] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape2] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape2]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape2] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape0]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape2]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape2] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape2]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape2]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape2]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape2]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape0] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape0]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape1] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape1] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape2] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape0] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape2] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape0] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape2] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape2]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape2]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape0]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape1]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape1] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape1]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape0]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape2] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape2] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape1] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape2]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape0]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape0] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape0]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape0]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape0] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape2]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape1]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape1] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape0] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape1]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape1]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape0] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape2]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape2]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape1]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape2] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape1]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape1] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape1]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape0] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape0] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape2]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape1]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape0]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape1]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape0]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape2] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape0] FAILED', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape2] FAILED', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape0]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape0]', 'FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape0]', '../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape2] FAILED'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pyro/pyro/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pyro/pyro
configfile: setup.cfg
collecting ... collected 54 items

../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape2] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape0] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape1] FAILED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape2] FAILED

=================================== FAILURES ===================================
________ test_conditional_compose_transform_module[0-2-2-batch_shape0] _________

batch_shape = (), input_dim = 2, context_dim = 2, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-2-2-batch_shape1] _________

batch_shape = (7,), input_dim = 2, context_dim = 2, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-2-2-batch_shape2] _________

batch_shape = (6, 7), input_dim = 2, context_dim = 2, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-2-3-batch_shape0] _________

batch_shape = (), input_dim = 3, context_dim = 2, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-2-3-batch_shape1] _________

batch_shape = (7,), input_dim = 3, context_dim = 2, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-2-3-batch_shape2] _________

batch_shape = (6, 7), input_dim = 3, context_dim = 2, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-2-5-batch_shape0] _________

batch_shape = (), input_dim = 5, context_dim = 2, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-2-5-batch_shape1] _________

batch_shape = (7,), input_dim = 5, context_dim = 2, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-2-5-batch_shape2] _________

batch_shape = (6, 7), input_dim = 5, context_dim = 2, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-3-2-batch_shape0] _________

batch_shape = (), input_dim = 2, context_dim = 3, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-3-2-batch_shape1] _________

batch_shape = (7,), input_dim = 2, context_dim = 3, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-3-2-batch_shape2] _________

batch_shape = (6, 7), input_dim = 2, context_dim = 3, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-3-3-batch_shape0] _________

batch_shape = (), input_dim = 3, context_dim = 3, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-3-3-batch_shape1] _________

batch_shape = (7,), input_dim = 3, context_dim = 3, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-3-3-batch_shape2] _________

batch_shape = (6, 7), input_dim = 3, context_dim = 3, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-3-5-batch_shape0] _________

batch_shape = (), input_dim = 5, context_dim = 3, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-3-5-batch_shape1] _________

batch_shape = (7,), input_dim = 5, context_dim = 3, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-3-5-batch_shape2] _________

batch_shape = (6, 7), input_dim = 5, context_dim = 3, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-5-2-batch_shape0] _________

batch_shape = (), input_dim = 2, context_dim = 5, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-5-2-batch_shape1] _________

batch_shape = (7,), input_dim = 2, context_dim = 5, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-5-2-batch_shape2] _________

batch_shape = (6, 7), input_dim = 2, context_dim = 5, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-5-3-batch_shape0] _________

batch_shape = (), input_dim = 3, context_dim = 5, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-5-3-batch_shape1] _________

batch_shape = (7,), input_dim = 3, context_dim = 5, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-5-3-batch_shape2] _________

batch_shape = (6, 7), input_dim = 3, context_dim = 5, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-5-5-batch_shape0] _________

batch_shape = (), input_dim = 5, context_dim = 5, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-5-5-batch_shape1] _________

batch_shape = (7,), input_dim = 5, context_dim = 5, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[0-5-5-batch_shape2] _________

batch_shape = (6, 7), input_dim = 5, context_dim = 5, cache_size = 0

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-2-2-batch_shape0] _________

batch_shape = (), input_dim = 2, context_dim = 2, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-2-2-batch_shape1] _________

batch_shape = (7,), input_dim = 2, context_dim = 2, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-2-2-batch_shape2] _________

batch_shape = (6, 7), input_dim = 2, context_dim = 2, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-2-3-batch_shape0] _________

batch_shape = (), input_dim = 3, context_dim = 2, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-2-3-batch_shape1] _________

batch_shape = (7,), input_dim = 3, context_dim = 2, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-2-3-batch_shape2] _________

batch_shape = (6, 7), input_dim = 3, context_dim = 2, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-2-5-batch_shape0] _________

batch_shape = (), input_dim = 5, context_dim = 2, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-2-5-batch_shape1] _________

batch_shape = (7,), input_dim = 5, context_dim = 2, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-2-5-batch_shape2] _________

batch_shape = (6, 7), input_dim = 5, context_dim = 2, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-3-2-batch_shape0] _________

batch_shape = (), input_dim = 2, context_dim = 3, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-3-2-batch_shape1] _________

batch_shape = (7,), input_dim = 2, context_dim = 3, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-3-2-batch_shape2] _________

batch_shape = (6, 7), input_dim = 2, context_dim = 3, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-3-3-batch_shape0] _________

batch_shape = (), input_dim = 3, context_dim = 3, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-3-3-batch_shape1] _________

batch_shape = (7,), input_dim = 3, context_dim = 3, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-3-3-batch_shape2] _________

batch_shape = (6, 7), input_dim = 3, context_dim = 3, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-3-5-batch_shape0] _________

batch_shape = (), input_dim = 5, context_dim = 3, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-3-5-batch_shape1] _________

batch_shape = (7,), input_dim = 5, context_dim = 3, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-3-5-batch_shape2] _________

batch_shape = (6, 7), input_dim = 5, context_dim = 3, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-5-2-batch_shape0] _________

batch_shape = (), input_dim = 2, context_dim = 5, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-5-2-batch_shape1] _________

batch_shape = (7,), input_dim = 2, context_dim = 5, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-5-2-batch_shape2] _________

batch_shape = (6, 7), input_dim = 2, context_dim = 5, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 1.8673,  0.5217,  2.3036,  0.5586, -0.6322, -1.0159, -0.8111, -1.8162],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-5-3-batch_shape0] _________

batch_shape = (), input_dim = 3, context_dim = 5, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-5-3-batch_shape1] _________

batch_shape = (7,), input_dim = 3, context_dim = 5, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-5-3-batch_shape2] _________

batch_shape = (6, 7), input_dim = 3, context_dim = 5, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[ 0.2260, -1.5024, -1.9946,  0.3893, -1.4302,  0.2602,  1.2458, -1.7302],
        [ 0.6044,  ...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-5-5-batch_shape0] _________

batch_shape = (), input_dim = 5, context_dim = 5, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-5-5-batch_shape1] _________

batch_shape = (7,), input_dim = 5, context_dim = 5, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
________ test_conditional_compose_transform_module[1-5-5-batch_shape2] _________

batch_shape = (6, 7), input_dim = 5, context_dim = 5, cache_size = 1

    @pytest.mark.parametrize("batch_shape", [(), (7,), (6, 7)])
    @pytest.mark.parametrize("input_dim", [2, 3, 5])
    @pytest.mark.parametrize("context_dim", [2, 3, 5])
    @pytest.mark.parametrize("cache_size", [0, 1])
    def test_conditional_compose_transform_module(
        batch_shape, input_dim, context_dim, cache_size
    ):
        conditional_transforms = [
            T.AffineTransform(1.0, 2.0),
            T.Spline(input_dim),
            T.conditional_spline(input_dim, context_dim, [5]),
            T.SoftplusTransform(),
            T.conditional_spline(input_dim, context_dim, [6]),
        ]
        cond_transform = dist.conditional.ConditionalComposeTransformModule(
            conditional_transforms, cache_size=cache_size
        )
    
        base_dist = dist.Normal(0, 1).expand(batch_shape + (input_dim,)).to_event(1)
        cond_dist = dist.ConditionalTransformedDistribution(base_dist, [cond_transform])
    
        context = torch.rand(batch_shape + (context_dim,))
        d = cond_dist.condition(context)
        transform = d.transforms[0]
        assert isinstance(transform, T.ComposeTransformModule)
    
>       data = d.rsample()

../publishablew/pyro/pyro/tests/distributions/test_transforms.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transformed_distribution.py:155: in rsample
    x = transform(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:358: in __call__
    x = part(x)
../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/distributions/transforms.py:162: in __call__
    y = self._call(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:147: in _call
    y, log_detJ = self.spline_op(x)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:174: in spline_op
    y, log_detJ = _monotonic_rational_spline(x, w, h, d, l, bound=self.bound, **kwargs)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:70: in _monotonic_rational_spline
    widths, cumwidths = _calculate_knots(widths, left, right)
../publishablew/pyro/pyro/pyro/distributions/transforms/spline.py:33: in _calculate_knots
    return _calculate_knots(lengths, lower, upper)
../publishablew/pyro/pyro/pyro/distributions/transforms/temp.py:17: in _calculate_knots
    adjusted_lengths = torch.diff(torch.cat((torch.tensor([lower]), knot_positions)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils._device.DeviceContext object at 0x7f271f71fed0>
func = <built-in method cat of type object at 0x7f27e44d0240>, types = ()
args = ((tensor([-3.]), tensor([[-0.7775, -1.9200, -2.0357, -1.2797, -1.5925, -2.2816, -1.5718, -2.5594],
        [-0.2603, -...],
        [ 3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000,  3.0000]],
       grad_fn=<AddBackward0>)),)
kwargs = {}

    def __torch_function__(self, func, types, args=(), kwargs=None):
        kwargs = kwargs or {}
        if func in _device_constructors() and kwargs.get('device') is None:
            kwargs['device'] = self.device
>       return func(*args, **kwargs)
E       RuntimeError: Tensors must have same number of dimensions: got 1 and 2

../publishablew/pyro/pyro/venv/lib/python3.11/site-packages/torch/utils/_device.py:106: RuntimeError
=========================== short test summary info ============================
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape2]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape0]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape1]
FAILED ../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape2]
============================== 54 failed in 2.69s ==============================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pyro/pyro/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pyro/pyro
configfile: setup.cfg
collecting ... collected 54 items

../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape2] PASSED

============================== 54 passed in 1.65s ==============================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/pyro/pyro/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/pyro/pyro
configfile: setup.cfg
collecting ... collected 54 items

../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-2-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-3-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-2-5-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-2-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-3-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-3-5-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-2-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-3-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[0-5-5-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-2-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-3-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-2-5-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-2-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-3-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-3-5-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-2-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-3-batch_shape2] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape0] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape1] PASSED
../publishablew/pyro/pyro/tests/distributions/test_transforms.py::test_conditional_compose_transform_module[1-5-5-batch_shape2] PASSED

============================== 54 passed in 1.78s ==============================
