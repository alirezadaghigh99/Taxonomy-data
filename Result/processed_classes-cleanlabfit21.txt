output file:
processed_classes-cleanlabfit21.json
function:
fit
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[numpy] FAILED [ 45%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data0] FAILED [  1%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[sparse]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[numpy]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[numpy] FAILED [ 30%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm FAILED [ 27%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[dataframe]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data0]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[dataframe] FAILED [ 38%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[sparse] FAILED [ 72%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[3] FAILED [ 77%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data2] FAILED [ 11%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_invalid_inputs FAILED [ 13%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[sparse] FAILED [ 67%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[numpy]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[dataframe]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[numpy] FAILED [ 40%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[numpy] FAILED [ 71%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[numpy]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[sparse]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[dataframe]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[sparse] FAILED [ 37%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl_default_clf', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data2] FAILED [  5%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[numpy] FAILED [ 50%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[3]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[sparse]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[dataframe] FAILED [ 33%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[dataframe]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_inm FAILED [ 28%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[dataframe]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data1]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[dataframe] FAILED [ 74%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[sparse]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data2]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_1D_formats FAILED [ 81%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[dataframe] FAILED [ 49%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[numpy] FAILED [ 35%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_sklearn_gridsearchcv FAILED [ 83%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[sparse]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[numpy]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_sklearn_gridsearchcv', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[4] FAILED [ 79%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data1] FAILED [ 10%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[sparse] FAILED [ 47%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[dataframe]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data2]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data0] FAILED [  8%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_validation_data', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[1] FAILED [ 76%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_inm', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[numpy]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_aux_inputs FAILED [ 15%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[4]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[numpy] FAILED [ 66%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[1]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data0]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_aux_inputs', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[dataframe] FAILED [ 69%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[numpy]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data1] FAILED [  3%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl_default_clf FAILED [  6%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[sparse] FAILED [ 32%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[numpy]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[sparse] FAILED [ 42%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[sparse]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[dataframe]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[dataframe] FAILED [ 44%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_invalid_inputs', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data1]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[sparse] FAILED [ 52%]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_validation_data FAILED [ 16%]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_1D_formats', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[sparse]', '../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[dataframe] FAILED [ 54%]'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/bin/python3
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/cleanlab/cleanlab
configfile: pyproject.toml
collecting ... collected 59 items

../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data0] FAILED [  1%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data1] FAILED [  3%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data2] FAILED [  5%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl_default_clf FAILED [  6%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data0] FAILED [  8%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data1] FAILED [ 10%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data2] FAILED [ 11%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_invalid_inputs FAILED [ 13%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_aux_inputs FAILED [ 15%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_validation_data FAILED [ 16%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_raise_error_no_clf_fit PASSED [ 18%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_raise_error_no_clf_predict_proba PASSED [ 20%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_raise_error_no_clf_predict PASSED [ 22%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_seed PASSED [ 23%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_default_clf PASSED [ 25%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm FAILED [ 27%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_inm FAILED [ 28%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[numpy] FAILED [ 30%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[sparse] FAILED [ 32%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[dataframe] FAILED [ 33%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[numpy] FAILED [ 35%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[sparse] FAILED [ 37%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[dataframe] FAILED [ 38%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[numpy] FAILED [ 40%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[sparse] FAILED [ 42%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[dataframe] FAILED [ 44%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[numpy] FAILED [ 45%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[sparse] FAILED [ 47%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[dataframe] FAILED [ 49%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[numpy] FAILED [ 50%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[sparse] FAILED [ 52%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[dataframe] FAILED [ 54%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_score[numpy] PASSED [ 55%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_score[sparse] PASSED [ 57%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_score[dataframe] PASSED [ 59%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_score[numpy] PASSED [ 61%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_score[sparse] PASSED [ 62%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_score[dataframe] PASSED [ 64%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[numpy] FAILED [ 66%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[sparse] FAILED [ 67%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[dataframe] FAILED [ 69%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[numpy] FAILED [ 71%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[sparse] FAILED [ 72%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[dataframe] FAILED [ 74%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[1] FAILED [ 76%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[3] FAILED [ 77%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[4] FAILED [ 79%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_1D_formats FAILED [ 81%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_sklearn_gridsearchcv FAILED [ 83%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[0-both] PASSED [ 84%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[0-confident_learning] PASSED [ 86%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[6-both] PASSED [ 88%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[6-confident_learning] PASSED [ 89%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[2-both] PASSED [ 91%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[2-confident_learning] PASSED [ 93%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_find_label_issues_uses_thresholds PASSED [ 94%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_find_issues_missing_classes PASSED [ 96%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_find_issues_low_memory PASSED [ 98%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_confident_joint_setting_in_find_label_issues_kwargs PASSED [100%]

=================================== FAILURES ===================================
________________________________ test_cl[data0] ________________________________

data = {'X_test': array([[ 4.07615093,  2.25546055],
       [ 4.68817463,  2.89435521],
       [ 5.56970345, -0.16890759],
  ...06578127, 0.12870278],
       [0.17760123, 0.90507285, 0.09035261],
       [0.10841622, 0.02914588, 0.7809446 ]]), ...}

    @pytest.mark.parametrize("data", list(DATA_FORMATS.values()))
    def test_cl(data):
        cl = CleanLearning(clf=LogisticRegression(solver="lbfgs", random_state=SEED))
        X_train_og = deepcopy(data["X_train"])
>       cl.fit(data["X_train"], data["labels"])

../publishablew/cleanlab/cleanlab/tests/test_classification.py:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(random_state=1),
              find_label_issues_kwargs={'confident_joint': array... 8],
       [16, 47,  4],
       [12,  2, 37]]),
                                        'min_examples_per_class': 10})
X = array([[-0.75073318,  2.79426808],
       [ 3.93518489,  0.88852811],
       [ 0.55994988,  1.09788438],
       [-1.05... 9.04068597],
       [ 0.65105019,  8.27861528],
       [-3.50445673,  7.97608746],
       [ 2.6961701 ,  9.39529131]])
labels = array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2, 1, 2, 2, 2, 2,
       2, 2])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       0.663263            0      ...            2                2
199           False       0.539214            2                2

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
________________________________ test_cl[data1] ________________________________

data = {'X_test': <Compressed Sparse Row sparse matrix of dtype 'float64'
	with 400 stored elements and shape (200, 2)>, 'X_t...06578127, 0.12870278],
       [0.17760123, 0.90507285, 0.09035261],
       [0.10841622, 0.02914588, 0.7809446 ]]), ...}

    @pytest.mark.parametrize("data", list(DATA_FORMATS.values()))
    def test_cl(data):
        cl = CleanLearning(clf=LogisticRegression(solver="lbfgs", random_state=SEED))
        X_train_og = deepcopy(data["X_train"])
>       cl.fit(data["X_train"], data["labels"])

../publishablew/cleanlab/cleanlab/tests/test_classification.py:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(random_state=1),
              find_label_issues_kwargs={'confident_joint': array... 9],
       [16, 47,  4],
       [12,  3, 36]]),
                                        'min_examples_per_class': 10})
X = <Compressed Sparse Row sparse matrix of dtype 'float64'
	with 400 stored elements and shape (200, 2)>
labels = array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2, 1, 2, 2, 2, 2,
       2, 2])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       0.675402            0      ...            2                2
199           False       0.545990            2                2

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
________________________________ test_cl[data2] ________________________________

data = {'X_test':             0          1
0    4.076151   2.255461
1    4.688175   2.894355
2    5.569703  -0.168908
3    6....06578127, 0.12870278],
       [0.17760123, 0.90507285, 0.09035261],
       [0.10841622, 0.02914588, 0.7809446 ]]), ...}

    @pytest.mark.parametrize("data", list(DATA_FORMATS.values()))
    def test_cl(data):
        cl = CleanLearning(clf=LogisticRegression(solver="lbfgs", random_state=SEED))
        X_train_og = deepcopy(data["X_train"])
>       cl.fit(data["X_train"], data["labels"])

../publishablew/cleanlab/cleanlab/tests/test_classification.py:161: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(random_state=1),
              find_label_issues_kwargs={'confident_joint': array... 8],
       [16, 47,  4],
       [11,  5, 35]]),
                                        'min_examples_per_class': 10})
X =             0         1
0   -0.750733  2.794268
1    3.935185  0.888528
2    0.559950  1.097884
3   -1.052172  2.78335...196  0.660621  9.040686
197  0.651050  8.278615
198 -3.504457  7.976087
199  2.696170  9.395291

[200 rows x 2 columns]
labels = array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2, 1, 2, 2, 2, 2,
       2, 2])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       0.664556            0      ...            2                2
199           False       0.544756            2                2

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
_____________________________ test_cl_default_clf ______________________________

    def test_cl_default_clf():
        cl = CleanLearning()  # default clf is LogisticRegression
        X_train_og = deepcopy(HIGH_DIM_DATA["X_train"])
>       cl.fit(HIGH_DIM_DATA["X_train"], HIGH_DIM_DATA["labels_train"])

../publishablew/cleanlab/cleanlab/tests/test_classification.py:174: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(),
              find_label_issues_kwargs={'confident_joint': array([[1, 2, 3, 3,... 2, 0],
       [2, 1, 4, 2, 3, 0, 2, 1, 0, 1]]),
                                        'min_examples_per_class': 10})
X = array([[[0.14509804, 0.92156863, 0.54901961, ..., 0.91764706,
         0.61176471, 0.61568627],
        [0.55686275, 0...4313725, 0.64313725],
        [0.80784314, 0.55686275, 0.05490196, ..., 0.6627451 ,
         0.51372549, 0.52156863]]])
labels = array([1, 7, 5, 7, 1, 6, 4, 3, 3, 5, 3, 7, 4, 7, 8, 5, 5, 4, 8, 1, 2, 7,
       2, 4, 1, 8, 8, 3, 8, 0, 9, 9, 5, 4, 2,...3, 8, 4, 4, 6, 3, 9, 4, 3, 7, 8,
       1, 5, 2, 2, 2, 3, 1, 2, 2, 3, 0, 6, 6, 0, 0, 6, 5, 7, 0, 4, 0, 4,
       5, 4])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       0.064212            1      ...            5                4
199            True       0.047795            4                2

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
____________________________ test_rare_label[data0] ____________________________

data = {'X_test': array([[ 4.07615093,  2.25546055],
       [ 4.68817463,  2.89435521],
       [ 5.56970345, -0.16890759],
  ...06578127, 0.12870278],
       [0.17760123, 0.90507285, 0.09035261],
       [0.10841622, 0.02914588, 0.7809446 ]]), ...}

    @pytest.mark.filterwarnings("ignore::UserWarning")
    @pytest.mark.parametrize("data", list(DATA_FORMATS.values()))
    def test_rare_label(data):
        data = make_rare_label(data)
>       test_cl(data)

../publishablew/cleanlab/cleanlab/tests/test_classification.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/cleanlab/cleanlab/tests/test_classification.py:161: in test_cl
    cl.fit(data["X_train"], data["labels"])
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(random_state=1),
              find_label_issues_kwargs={'confident_joint': array...      [  0, 134,  14],
       [  0,  14,  37]]),
                                        'min_examples_per_class': 10})
X = array([[-0.75073318,  2.79426808],
       [ 3.93518489,  0.88852811],
       [ 0.55994988,  1.09788438],
       [-1.05... 9.04068597],
       [ 0.65105019,  8.27861528],
       [-3.50445673,  7.97608746],
       [ 2.6961701 ,  9.39529131]])
labels = array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2,
       2, 2])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       1.000000            0      ...            2                2
199           False       0.466197            2                1

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
____________________________ test_rare_label[data1] ____________________________

data = {'X_test': <Compressed Sparse Row sparse matrix of dtype 'float64'
	with 400 stored elements and shape (200, 2)>, 'X_t...06578127, 0.12870278],
       [0.17760123, 0.90507285, 0.09035261],
       [0.10841622, 0.02914588, 0.7809446 ]]), ...}

    @pytest.mark.filterwarnings("ignore::UserWarning")
    @pytest.mark.parametrize("data", list(DATA_FORMATS.values()))
    def test_rare_label(data):
        data = make_rare_label(data)
>       test_cl(data)

../publishablew/cleanlab/cleanlab/tests/test_classification.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/cleanlab/cleanlab/tests/test_classification.py:161: in test_cl
    cl.fit(data["X_train"], data["labels"])
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(random_state=1),
              find_label_issues_kwargs={'confident_joint': array...      [  0, 134,  14],
       [  0,  12,  39]]),
                                        'min_examples_per_class': 10})
X = <Compressed Sparse Row sparse matrix of dtype 'float64'
	with 400 stored elements and shape (200, 2)>
labels = array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2,
       2, 2])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       1.000000            0      ...            2                2
199           False       0.500678            2                2

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
____________________________ test_rare_label[data2] ____________________________

data = {'X_test':             0          1
0    4.076151   2.255461
1    4.688175   2.894355
2    5.569703  -0.168908
3    6....06578127, 0.12870278],
       [0.17760123, 0.90507285, 0.09035261],
       [0.10841622, 0.02914588, 0.7809446 ]]), ...}

    @pytest.mark.filterwarnings("ignore::UserWarning")
    @pytest.mark.parametrize("data", list(DATA_FORMATS.values()))
    def test_rare_label(data):
        data = make_rare_label(data)
>       test_cl(data)

../publishablew/cleanlab/cleanlab/tests/test_classification.py:203: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/cleanlab/cleanlab/tests/test_classification.py:161: in test_cl
    cl.fit(data["X_train"], data["labels"])
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(random_state=1),
              find_label_issues_kwargs={'confident_joint': array...      [  0, 135,  13],
       [  0,  12,  39]]),
                                        'min_examples_per_class': 10})
X =             0         1
0   -0.750733  2.794268
1    3.935185  0.888528
2    0.559950  1.097884
3   -1.052172  2.78335...196  0.660621  9.040686
197  0.651050  8.278615
198 -3.504457  7.976087
199  2.696170  9.395291

[200 rows x 2 columns]
labels = array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1,
       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,...2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2,
       2, 2])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       1.000000            0      ...            2                2
199           False       0.541094            2                2

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
_____________________________ test_invalid_inputs ______________________________

    def test_invalid_inputs():
        data = make_data(sizes=[1, 1, 1])
        try:
            test_cl(data)
        except Exception as e:
            assert "Need more data" in str(e)
        else:
            raise Exception("expected test to raise Exception")
        try:
            cl = CleanLearning(
                clf=LogisticRegression(solver="lbfgs", random_state=SEED),
                find_label_issues_kwargs={"return_indices_ranked_by": "self_confidence"},
            )
>           cl.fit(
                data["X_train"],
                data["labels"],
            )

../publishablew/cleanlab/cleanlab/tests/test_classification.py:219: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(random_state=1),
              find_label_issues_kwargs={'return_indices_ranked_by': 'self_confidence'})
X = array([[-0.75073318,  2.79426808],
       [ 5.1023396 ,  9.07909963],
       [-0.19992896,  7.09474511]])
labels = array([0, 1, 2]), y = None, sample_weight = None, label_issues = None

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
>           label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
E           TypeError: CleanLearning.find_label_issues() got an unexpected keyword argument 'return_indices_ranked_by'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:239: TypeError

During handling of the above exception, another exception occurred:

    def test_invalid_inputs():
        data = make_data(sizes=[1, 1, 1])
        try:
            test_cl(data)
        except Exception as e:
            assert "Need more data" in str(e)
        else:
            raise Exception("expected test to raise Exception")
        try:
            cl = CleanLearning(
                clf=LogisticRegression(solver="lbfgs", random_state=SEED),
                find_label_issues_kwargs={"return_indices_ranked_by": "self_confidence"},
            )
            cl.fit(
                data["X_train"],
                data["labels"],
            )
        except Exception as e:
>           assert "not supported" in str(e) or "Need more data from each class" in str(e)
E           assert ('not supported' in "CleanLearning.find_label_issues() got an unexpected keyword argument 'return_indices_ranked_by'" or 'Need more data from each class' in "CleanLearning.find_label_issues() got an unexpected keyword argument 'return_indices_ranked_by'")
E            +  where "CleanLearning.find_label_issues() got an unexpected keyword argument 'return_indices_ranked_by'" = str(TypeError("CleanLearning.find_label_issues() got an unexpected keyword argument 'return_indices_ranked_by'"))
E            +  and   "CleanLearning.find_label_issues() got an unexpected keyword argument 'return_indices_ranked_by'" = str(TypeError("CleanLearning.find_label_issues() got an unexpected keyword argument 'return_indices_ranked_by'"))

../publishablew/cleanlab/cleanlab/tests/test_classification.py:224: AssertionError
_______________________________ test_aux_inputs ________________________________

    @pytest.mark.filterwarnings("ignore::UserWarning")
    def test_aux_inputs():
        data = DATA
        K = len(np.unique(data["labels"]))
        confident_joint = np.ones(shape=(K, K))
        np.fill_diagonal(confident_joint, 10)
        find_label_issues_kwargs = {
            "confident_joint": confident_joint,
            "min_examples_per_class": 2,
        }
        cl = CleanLearning(
            clf=LogisticRegression(solver="lbfgs", random_state=SEED),
            find_label_issues_kwargs=find_label_issues_kwargs,
            verbose=1,
        )
        label_issues_df = cl.find_label_issues(data["X_train"], data["labels"], clf_kwargs={})
        assert isinstance(label_issues_df, pd.DataFrame)
        FIND_OUTPUT_COLUMNS = ["is_label_issue", "label_quality", "given_label", "predicted_label"]
        assert list(label_issues_df.columns) == FIND_OUTPUT_COLUMNS
        assert label_issues_df.equals(cl.get_label_issues())
>       cl.fit(
            data["X_train"],
            data["labels"],
            label_issues=label_issues_df,
            clf_kwargs={},
            clf_final_kwargs={},
        )
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'clf_kwargs'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:249: TypeError
----------------------------- Captured stdout call -----------------------------
Computing label noise estimates from provided noise matrix ...
Computing out of sample predicted probabilities via 5-fold cross validation. May take a while ...
Using predicted probabilities to identify label issues ...
Identified 6 examples with label issues.
_____________________________ test_validation_data _____________________________

    def test_validation_data():
        data = DATA
        cl = CleanLearning(clf=LogisticRegressionWithValidationData())
>       cl.fit(
            data["X_train"],
            data["labels"],
            validation_func=val_func,
        )
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'validation_func'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:352: TypeError
_______________________________ test_clf_fit_nm ________________________________

    def test_clf_fit_nm():
        cl = CleanLearning()
        # Example of a bad noise matrix (impossible to learn from)
        nm = np.array([[0, 1], [1, 0]])
        try:
>           cl.fit(X=np.arange(3), labels=np.array([0, 0, 1]), noise_matrix=nm)
E           TypeError: CleanLearning.fit() got an unexpected keyword argument 'noise_matrix'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:424: TypeError

During handling of the above exception, another exception occurred:

    def test_clf_fit_nm():
        cl = CleanLearning()
        # Example of a bad noise matrix (impossible to learn from)
        nm = np.array([[0, 1], [1, 0]])
        try:
            cl.fit(X=np.arange(3), labels=np.array([0, 0, 1]), noise_matrix=nm)
        except Exception as e:
>           assert "Trace(noise_matrix)" in str(e)
E           assert 'Trace(noise_matrix)' in "CleanLearning.fit() got an unexpected keyword argument 'noise_matrix'"
E            +  where "CleanLearning.fit() got an unexpected keyword argument 'noise_matrix'" = str(TypeError("CleanLearning.fit() got an unexpected keyword argument 'noise_matrix'"))

../publishablew/cleanlab/cleanlab/tests/test_classification.py:426: AssertionError
_______________________________ test_clf_fit_inm _______________________________

    def test_clf_fit_inm():
        cl = CleanLearning()
        # Example of a bad noise matrix (impossible to learn from)
        inm = np.array([[0.1, 0.9], [0.9, 0.1]])
        try:
>           cl.fit(X=np.arange(3), labels=np.array([0, 0, 1]), inverse_noise_matrix=inm)
E           TypeError: CleanLearning.fit() got an unexpected keyword argument 'inverse_noise_matrix'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:436: TypeError

During handling of the above exception, another exception occurred:

    def test_clf_fit_inm():
        cl = CleanLearning()
        # Example of a bad noise matrix (impossible to learn from)
        inm = np.array([[0.1, 0.9], [0.9, 0.1]])
        try:
            cl.fit(X=np.arange(3), labels=np.array([0, 0, 1]), inverse_noise_matrix=inm)
        except Exception as e:
>           assert "Trace(inverse_noise_matrix)" in str(e)
E           assert 'Trace(inverse_noise_matrix)' in "CleanLearning.fit() got an unexpected keyword argument 'inverse_noise_matrix'"
E            +  where "CleanLearning.fit() got an unexpected keyword argument 'inverse_noise_matrix'" = str(TypeError("CleanLearning.fit() got an unexpected keyword argument 'inverse_noise_matrix'"))

../publishablew/cleanlab/cleanlab/tests/test_classification.py:438: AssertionError
___________________________ test_fit_with_nm[numpy] ____________________________

format = 'numpy', seed = 1, used_by_another_test = False

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_fit_with_nm(
        format,
        seed=SEED,
        used_by_another_test=False,
    ):
        data = DATA_FORMATS[format]
        cl = CleanLearning(
            seed=seed,
        )
        nm = data["noise_matrix"]
        # Learn with noisy labels with noise matrix given
>       cl.fit(data["X_train"], data["labels"], noise_matrix=nm)
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'noise_matrix'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:455: TypeError
___________________________ test_fit_with_nm[sparse] ___________________________

format = 'sparse', seed = 1, used_by_another_test = False

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_fit_with_nm(
        format,
        seed=SEED,
        used_by_another_test=False,
    ):
        data = DATA_FORMATS[format]
        cl = CleanLearning(
            seed=seed,
        )
        nm = data["noise_matrix"]
        # Learn with noisy labels with noise matrix given
>       cl.fit(data["X_train"], data["labels"], noise_matrix=nm)
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'noise_matrix'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:455: TypeError
_________________________ test_fit_with_nm[dataframe] __________________________

format = 'dataframe', seed = 1, used_by_another_test = False

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_fit_with_nm(
        format,
        seed=SEED,
        used_by_another_test=False,
    ):
        data = DATA_FORMATS[format]
        cl = CleanLearning(
            seed=seed,
        )
        nm = data["noise_matrix"]
        # Learn with noisy labels with noise matrix given
>       cl.fit(data["X_train"], data["labels"], noise_matrix=nm)
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'noise_matrix'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:455: TypeError
___________________________ test_fit_with_inm[numpy] ___________________________

format = 'numpy', seed = 1, used_by_another_test = False

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_fit_with_inm(
        format,
        seed=SEED,
        used_by_another_test=False,
    ):
        data = DATA_FORMATS[format]
        cl = CleanLearning(
            seed=seed,
        )
        inm = compute_inv_noise_matrix(
            py=data["py"],
            noise_matrix=data["noise_matrix"],
            ps=data["ps"],
        )
        # Learn with noisy labels with inverse noise matrix given
>       cl.fit(data["X_train"], data["labels"], inverse_noise_matrix=inm)
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'inverse_noise_matrix'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:488: TypeError
__________________________ test_fit_with_inm[sparse] ___________________________

format = 'sparse', seed = 1, used_by_another_test = False

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_fit_with_inm(
        format,
        seed=SEED,
        used_by_another_test=False,
    ):
        data = DATA_FORMATS[format]
        cl = CleanLearning(
            seed=seed,
        )
        inm = compute_inv_noise_matrix(
            py=data["py"],
            noise_matrix=data["noise_matrix"],
            ps=data["ps"],
        )
        # Learn with noisy labels with inverse noise matrix given
>       cl.fit(data["X_train"], data["labels"], inverse_noise_matrix=inm)
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'inverse_noise_matrix'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:488: TypeError
_________________________ test_fit_with_inm[dataframe] _________________________

format = 'dataframe', seed = 1, used_by_another_test = False

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_fit_with_inm(
        format,
        seed=SEED,
        used_by_another_test=False,
    ):
        data = DATA_FORMATS[format]
        cl = CleanLearning(
            seed=seed,
        )
        inm = compute_inv_noise_matrix(
            py=data["py"],
            noise_matrix=data["noise_matrix"],
            ps=data["ps"],
        )
        # Learn with noisy labels with inverse noise matrix given
>       cl.fit(data["X_train"], data["labels"], inverse_noise_matrix=inm)
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'inverse_noise_matrix'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:488: TypeError
__________________________ test_clf_fit_nm_inm[numpy] __________________________

format = 'numpy'

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_clf_fit_nm_inm(format):
        data = DATA_FORMATS[format]
        cl = CleanLearning(seed=SEED)
        nm = data["noise_matrix"]
        inm = compute_inv_noise_matrix(
            py=data["py"],
            noise_matrix=nm,
            ps=data["ps"],
        )
>       cl.fit(
            X=data["X_train"],
            labels=data["labels"],
            noise_matrix=nm,
            inverse_noise_matrix=inm,
        )
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'noise_matrix'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:515: TypeError
_________________________ test_clf_fit_nm_inm[sparse] __________________________

format = 'sparse'

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_clf_fit_nm_inm(format):
        data = DATA_FORMATS[format]
        cl = CleanLearning(seed=SEED)
        nm = data["noise_matrix"]
        inm = compute_inv_noise_matrix(
            py=data["py"],
            noise_matrix=nm,
            ps=data["ps"],
        )
>       cl.fit(
            X=data["X_train"],
            labels=data["labels"],
            noise_matrix=nm,
            inverse_noise_matrix=inm,
        )
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'noise_matrix'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:515: TypeError
________________________ test_clf_fit_nm_inm[dataframe] ________________________

format = 'dataframe'

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_clf_fit_nm_inm(format):
        data = DATA_FORMATS[format]
        cl = CleanLearning(seed=SEED)
        nm = data["noise_matrix"]
        inm = compute_inv_noise_matrix(
            py=data["py"],
            noise_matrix=nm,
            ps=data["ps"],
        )
>       cl.fit(
            X=data["X_train"],
            labels=data["labels"],
            noise_matrix=nm,
            inverse_noise_matrix=inm,
        )
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'noise_matrix'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:515: TypeError
_________________________ test_clf_fit_y_alias[numpy] __________________________

format = 'numpy'

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_clf_fit_y_alias(format):
        data = DATA_FORMATS[format]
        cl = CleanLearning(seed=SEED)
    
        # Valid signature
>       cl.fit(data["X_train"], data["labels"])

../publishablew/cleanlab/cleanlab/tests/test_classification.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(),
              find_label_issues_kwargs={'confident_joint': array([[72,  3,  7]...4],
       [12,  4, 35]]),
                                        'min_examples_per_class': 10},
              seed=1)
X = array([[-0.75073318,  2.79426808],
       [ 3.93518489,  0.88852811],
       [ 0.55994988,  1.09788438],
       [-1.05... 9.04068597],
       [ 0.65105019,  8.27861528],
       [-3.50445673,  7.97608746],
       [ 2.6961701 ,  9.39529131]])
labels = array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2, 1, 2, 2, 2, 2,
       2, 2])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       0.674421            0      ...            2                2
199           False       0.538089            2                2

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
_________________________ test_clf_fit_y_alias[sparse] _________________________

format = 'sparse'

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_clf_fit_y_alias(format):
        data = DATA_FORMATS[format]
        cl = CleanLearning(seed=SEED)
    
        # Valid signature
>       cl.fit(data["X_train"], data["labels"])

../publishablew/cleanlab/cleanlab/tests/test_classification.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(),
              find_label_issues_kwargs={'confident_joint': array([[72,  3,  7]...4],
       [12,  4, 35]]),
                                        'min_examples_per_class': 10},
              seed=1)
X = <Compressed Sparse Row sparse matrix of dtype 'float64'
	with 400 stored elements and shape (200, 2)>
labels = array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2, 1, 2, 2, 2, 2,
       2, 2])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       0.674421            0      ...            2                2
199           False       0.538089            2                2

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
_______________________ test_clf_fit_y_alias[dataframe] ________________________

format = 'dataframe'

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_clf_fit_y_alias(format):
        data = DATA_FORMATS[format]
        cl = CleanLearning(seed=SEED)
    
        # Valid signature
>       cl.fit(data["X_train"], data["labels"])

../publishablew/cleanlab/cleanlab/tests/test_classification.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(),
              find_label_issues_kwargs={'confident_joint': array([[72,  3,  7]...4],
       [12,  4, 35]]),
                                        'min_examples_per_class': 10},
              seed=1)
X =             0         1
0   -0.750733  2.794268
1    3.935185  0.888528
2    0.559950  1.097884
3   -1.052172  2.78335...196  0.660621  9.040686
197  0.651050  8.278615
198 -3.504457  7.976087
199  2.696170  9.395291

[200 rows x 2 columns]
labels = array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2, 1, 2, 2, 2, 2,
       2, 2])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       0.674421            0      ...            2                2
199           False       0.538089            2                2

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
_______________________ test_pred_and_pred_proba[numpy] ________________________

format = 'numpy'

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_pred_and_pred_proba(format):
        data = DATA_FORMATS[format]
        cl = CleanLearning()
>       cl.fit(data["X_train"], data["labels"])

../publishablew/cleanlab/cleanlab/tests/test_classification.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(),
              find_label_issues_kwargs={'confident_joint': array([[72,  3,  7],
       [16, 47,  4],
       [12,  4, 35]]),
                                        'min_examples_per_class': 10})
X = array([[-0.75073318,  2.79426808],
       [ 3.93518489,  0.88852811],
       [ 0.55994988,  1.09788438],
       [-1.05... 9.04068597],
       [ 0.65105019,  8.27861528],
       [-3.50445673,  7.97608746],
       [ 2.6961701 ,  9.39529131]])
labels = array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2, 1, 2, 2, 2, 2,
       2, 2])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       0.674421            0      ...            2                2
199           False       0.538089            2                2

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
_______________________ test_pred_and_pred_proba[sparse] _______________________

format = 'sparse'

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_pred_and_pred_proba(format):
        data = DATA_FORMATS[format]
        cl = CleanLearning()
>       cl.fit(data["X_train"], data["labels"])

../publishablew/cleanlab/cleanlab/tests/test_classification.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(),
              find_label_issues_kwargs={'confident_joint': array([[72,  2,  8],
       [18, 45,  4],
       [11,  2, 38]]),
                                        'min_examples_per_class': 10})
X = <Compressed Sparse Row sparse matrix of dtype 'float64'
	with 400 stored elements and shape (200, 2)>
labels = array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2, 1, 2, 2, 2, 2,
       2, 2])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       0.624701            0      ...            2                2
199           False       0.511945            2                2

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
_____________________ test_pred_and_pred_proba[dataframe] ______________________

format = 'dataframe'

    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_pred_and_pred_proba(format):
        data = DATA_FORMATS[format]
        cl = CleanLearning()
>       cl.fit(data["X_train"], data["labels"])

../publishablew/cleanlab/cleanlab/tests/test_classification.py:560: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=LogisticRegression(),
              find_label_issues_kwargs={'confident_joint': array([[72,  3,  7],
       [17, 46,  4],
       [11,  4, 36]]),
                                        'min_examples_per_class': 10})
X =             0         1
0   -0.750733  2.794268
1    3.935185  0.888528
2    0.559950  1.097884
3   -1.052172  2.78335...196  0.660621  9.040686
197  0.651050  8.278615
198 -3.504457  7.976087
199  2.696170  9.395291

[200 rows x 2 columns]
labels = array([0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0,
       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,...2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2,
       2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 2, 2, 1, 2, 1, 2, 2, 2, 2,
       2, 2])
y = None, sample_weight = None
label_issues =      is_label_issue  label_quality  given_label  predicted_label
0             False       0.662915            0      ...            2                2
199           False       0.504121            2                2

[200 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
_______________________ test_no_fit_sample_weight[numpy] _______________________

format = 'numpy'

    @pytest.mark.filterwarnings("ignore::UserWarning")
    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_no_fit_sample_weight(format):
        data = DATA_FORMATS[format]
    
        class Struct:
            def fit(self, X, y):
                pass
    
            def predict_proba(self):
                pass
    
            def predict(self, X):
                return data["true_labels_test"]
    
        n = np.shape(data["true_labels_test"])[0]
        m = len(np.unique(data["true_labels_test"]))
        pred_probs = np.zeros(shape=(n, m))
        cl = CleanLearning(clf=Struct())
>       cl.fit(
            data["X_train"],
            data["true_labels_train"],
            pred_probs=pred_probs,
            noise_matrix=data["noise_matrix"],
        )
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'pred_probs'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:631: TypeError
______________________ test_no_fit_sample_weight[sparse] _______________________

format = 'sparse'

    @pytest.mark.filterwarnings("ignore::UserWarning")
    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_no_fit_sample_weight(format):
        data = DATA_FORMATS[format]
    
        class Struct:
            def fit(self, X, y):
                pass
    
            def predict_proba(self):
                pass
    
            def predict(self, X):
                return data["true_labels_test"]
    
        n = np.shape(data["true_labels_test"])[0]
        m = len(np.unique(data["true_labels_test"]))
        pred_probs = np.zeros(shape=(n, m))
        cl = CleanLearning(clf=Struct())
>       cl.fit(
            data["X_train"],
            data["true_labels_train"],
            pred_probs=pred_probs,
            noise_matrix=data["noise_matrix"],
        )
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'pred_probs'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:631: TypeError
_____________________ test_no_fit_sample_weight[dataframe] _____________________

format = 'dataframe'

    @pytest.mark.filterwarnings("ignore::UserWarning")
    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_no_fit_sample_weight(format):
        data = DATA_FORMATS[format]
    
        class Struct:
            def fit(self, X, y):
                pass
    
            def predict_proba(self):
                pass
    
            def predict(self, X):
                return data["true_labels_test"]
    
        n = np.shape(data["true_labels_test"])[0]
        m = len(np.unique(data["true_labels_test"]))
        pred_probs = np.zeros(shape=(n, m))
        cl = CleanLearning(clf=Struct())
>       cl.fit(
            data["X_train"],
            data["true_labels_train"],
            pred_probs=pred_probs,
            noise_matrix=data["noise_matrix"],
        )
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'pred_probs'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:631: TypeError
__________________________ test_fit_pred_probs[numpy] __________________________

format = 'numpy'

    @pytest.mark.filterwarnings("ignore::UserWarning")
    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_fit_pred_probs(format):
        data = DATA_FORMATS[format]
    
        cl = CleanLearning()
        pred_probs = estimate_cv_predicted_probabilities(
            X=data["X_train"],
            labels=data["true_labels_train"],
        )
>       cl.fit(X=data["X_train"], labels=data["true_labels_train"], pred_probs=pred_probs)
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'pred_probs'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:650: TypeError
_________________________ test_fit_pred_probs[sparse] __________________________

format = 'sparse'

    @pytest.mark.filterwarnings("ignore::UserWarning")
    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_fit_pred_probs(format):
        data = DATA_FORMATS[format]
    
        cl = CleanLearning()
        pred_probs = estimate_cv_predicted_probabilities(
            X=data["X_train"],
            labels=data["true_labels_train"],
        )
>       cl.fit(X=data["X_train"], labels=data["true_labels_train"], pred_probs=pred_probs)
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'pred_probs'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:650: TypeError
________________________ test_fit_pred_probs[dataframe] ________________________

format = 'dataframe'

    @pytest.mark.filterwarnings("ignore::UserWarning")
    @pytest.mark.parametrize("format", list(DATA_FORMATS.keys()))
    def test_fit_pred_probs(format):
        data = DATA_FORMATS[format]
    
        cl = CleanLearning()
        pred_probs = estimate_cv_predicted_probabilities(
            X=data["X_train"],
            labels=data["true_labels_train"],
        )
>       cl.fit(X=data["X_train"], labels=data["true_labels_train"], pred_probs=pred_probs)
E       TypeError: CleanLearning.fit() got an unexpected keyword argument 'pred_probs'

../publishablew/cleanlab/cleanlab/tests/test_classification.py:650: TypeError
_________________________________ test_dimN[1] _________________________________

N = 1

    @pytest.mark.filterwarnings("ignore::RuntimeWarning")
    @pytest.mark.parametrize("N", [1, 3, 4])
    def test_dimN(N):
        X, labels = dimN_data(N)
        cl = CleanLearning(clf=ReshapingLogisticRegression())
        # just make sure we don't crash...
>       cl.fit(X, labels)

../publishablew/cleanlab/cleanlab/tests/test_classification.py:702: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=ReshapingLogisticRegression(),
              find_label_issues_kwargs={'confident_joint': array([[15...    [11,  0,  1,  8],
       [21,  0,  2,  6]]),
                                        'min_examples_per_class': 10})
X = array([-3.52650982e-01, -1.08657154e+00, -1.26855934e+00,  1.00792598e-02,
        1.33428865e+00,  2.44715733e-01,  3...4804e+00,  5.45441179e-01,  3.92422170e-01,
       -1.86135850e+00,  1.40516065e-01,  8.51104101e-01,  8.91938682e-01])
labels = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3,...0,
       2, 1, 3, 2, 3, 3, 0, 3, 0, 3, 3, 3, 3, 1, 3, 2, 3, 1, 0, 3, 0, 3,
       1, 1, 0, 0, 3, 2, 0, 1, 1, 0, 2, 0])
y = None, sample_weight = None
label_issues =     is_label_issue  label_quality  given_label  predicted_label
0            False       0.320519            0        ...1            2                0
99            True       0.281868            0                3

[100 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
_________________________________ test_dimN[3] _________________________________

N = 3

    @pytest.mark.filterwarnings("ignore::RuntimeWarning")
    @pytest.mark.parametrize("N", [1, 3, 4])
    def test_dimN(N):
        X, labels = dimN_data(N)
        cl = CleanLearning(clf=ReshapingLogisticRegression())
        # just make sure we don't crash...
>       cl.fit(X, labels)

../publishablew/cleanlab/cleanlab/tests/test_classification.py:702: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=ReshapingLogisticRegression(),
              find_label_issues_kwargs={'confident_joint': array([[ 8...    [ 4, 10,  6,  7],
       [ 5,  5, 12,  1]]),
                                        'min_examples_per_class': 10})
X = array([[[ 1.73458325e-01,  9.83384002e-01, -2.78358934e-01],
        [-3.92454083e-01, -1.43929644e+00,  5.30205761e-0...    [ 1.22967321e+00, -2.57882850e+00, -1.62591523e-01],
        [-6.45984809e-01,  9.59926599e-01, -7.95888895e-02]]])
labels = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3,...2,
       1, 3, 3, 0, 1, 3, 2, 0, 1, 1, 1, 2, 3, 0, 2, 1, 3, 0, 0, 2, 1, 2,
       1, 3, 3, 2, 1, 0, 3, 3, 2, 3, 2, 0])
y = None, sample_weight = None
label_issues =     is_label_issue  label_quality  given_label  predicted_label
0            False       0.432050            0        ...1            2                0
99           False       0.574227            0                0

[100 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
_________________________________ test_dimN[4] _________________________________

N = 4

    @pytest.mark.filterwarnings("ignore::RuntimeWarning")
    @pytest.mark.parametrize("N", [1, 3, 4])
    def test_dimN(N):
        X, labels = dimN_data(N)
        cl = CleanLearning(clf=ReshapingLogisticRegression())
        # just make sure we don't crash...
>       cl.fit(X, labels)

../publishablew/cleanlab/cleanlab/tests/test_classification.py:702: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=ReshapingLogisticRegression(),
              find_label_issues_kwargs={'confident_joint': array([[6,... 8],
       [1, 7, 4, 8],
       [7, 7, 5, 9]]),
                                        'min_examples_per_class': 10})
X = array([[[[ 1.09330663, -0.74622428,  0.90626141],
         [ 1.46662474, -0.14259029,  0.26593014],
         [ 0.22518...2, -0.14069045],
         [ 1.18391882,  1.55520159,  2.04898474],
         [ 0.68593475,  0.44069264,  0.54805929]]]])
labels = array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2,
       2, 2, 2, 2, 2, 2, 2, 2, 0, 3, 3, 3, 3,...2,
       1, 0, 1, 3, 3, 0, 2, 3, 2, 3, 0, 2, 3, 0, 3, 2, 3, 1, 3, 2, 3, 2,
       0, 3, 1, 1, 1, 1, 1, 1, 3, 3, 0, 1])
y = None, sample_weight = None
label_issues =     is_label_issue  label_quality  given_label  predicted_label
0             True       0.044414            0        ...0            0                1
99           False       0.317750            1                3

[100 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
_______________________________ test_1D_formats ________________________________

    @pytest.mark.filterwarnings("ignore::UserWarning")
    def test_1D_formats():
        X, labels = dimN_data(1)
        X_series = pd.Series(X)
        labels_series = pd.Series(labels)
        idx = list(np.random.choice(len(labels), size=len(labels), replace=False))
        X_series.index = idx
        labels_series.index = idx
        cl = CleanLearning(clf=ReshapingLogisticRegression())
        # just make sure we don't crash...
>       cl.fit(X_series, labels_series)

../publishablew/cleanlab/cleanlab/tests/test_classification.py:718: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = CleanLearning(clf=ReshapingLogisticRegression(),
              find_label_issues_kwargs={'confident_joint': array([[ 1...    [ 1,  2,  1, 19],
       [ 4,  9,  0, 15]]),
                                        'min_examples_per_class': 10})
X = 62    0.807138
26   -1.117130
58   -0.630753
51    0.144217
83    0.895816
        ...   
17    0.005726
57    0.272269
94   -2.047478
22    0.002486
53    2.922790
Length: 100, dtype: float64
labels = 62    0
26    0
58    0
51    0
83    0
     ..
17    1
57    2
94    2
22    3
53    3
Length: 100, dtype: int64
y = None, sample_weight = None
label_issues =     is_label_issue  label_quality  given_label  predicted_label
0            False       0.260721            0        ...0            3                3
99            True       0.056402            3                0

[100 rows x 4 columns]

    def fit(self, X, labels=None, y=None, sample_weight=None, label_issues=None):
        if labels is None and y is None or (labels is not None and y is not None):
            raise ValueError("Either 'labels' or 'y' must be provided, but not both.")
        labels = labels if labels is not None else y
        if self.clf is None and X.ndim != 2:
            raise ValueError('Input data X must be two-dimensional.')
        clf_kwargs = self.clf_kwargs or {}
        clf_final_kwargs = self.clf_final_kwargs or {}
        fit_kwargs = {**clf_kwargs, **clf_final_kwargs}
        if sample_weight is not None:
            if not hasattr(self.clf, 'fit'):
                raise ValueError('The classifier does not support sample weights.')
            fit_kwargs['sample_weight'] = sample_weight
        if label_issues is None:
            label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
        if isinstance(label_issues, dict) and 'label_quality_scores' in label_issues:
            label_quality_scores = label_issues['label_quality_scores']
        else:
            label_quality_scores = None
        if isinstance(label_issues, dict) and 'label_issues_mask' in label_issues:
            label_issues_mask = label_issues['label_issues_mask']
        else:
            label_issues_mask = [False] * len(labels)
>       x_cleaned = X[~label_issues_mask]
E       TypeError: bad operand type for unary ~: 'list'

../publishablew/cleanlab/cleanlab/cleanlab/classification.py:248: TypeError
__________________________ test_sklearn_gridsearchcv ___________________________

    @sre_deprecation_pytestmark  # Allow sre_constants deprecation warning for Python 3.11
    @pytest.mark.filterwarnings("error")  # All other warnings are treated as errors
    @pytest.mark.skipif(
        uses_sklearn_1_5_0,
        reason="Test is skipped because sklearn 1.5.0 is installed, which has a regression for GridSearchCV.",
    )  # TODO: Remove this line once sklearn 1.5.1 is released
    def test_sklearn_gridsearchcv():
        # hyper-parameters for grid search
        param_grid = {
            "find_label_issues_kwargs": [
                {"filter_by": "prune_by_noise_rate"},
                {"filter_by": "prune_by_class"},
                {"filter_by": "both"},
                {"filter_by": "confident_learning"},
                {"filter_by": "predicted_neq_given"},
            ],
            "converge_latent_estimates": [True, False],
        }
    
        clf = LogisticRegression(random_state=0, solver="lbfgs")
    
        cv = GridSearchCV(
            estimator=CleanLearning(clf),
            param_grid=param_grid,
            cv=3,
        )
    
        # cv.fit() raises a warning if some fits fail (including raising
        # exceptions); we don't expect any fits to fail, so ensure that the code
        # doesn't raise any warnings
>       cv.fit(X=DATA["X_train"], y=DATA["labels"])

../publishablew/cleanlab/cleanlab/tests/test_classification.py:802: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/cleanlab/cleanlab/venv/lib/python3.11/site-packages/sklearn/base.py:1473: in wrapper
    return fit_method(estimator, *args, **kwargs)
../publishablew/cleanlab/cleanlab/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1019: in fit
    self._run_search(evaluate_candidates)
../publishablew/cleanlab/cleanlab/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1573: in _run_search
    evaluate_candidates(ParameterGrid(self.param_grid))
../publishablew/cleanlab/cleanlab/venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:996: in evaluate_candidates
    _warn_or_raise_about_fit_failures(out, self.error_score)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

results = [{'fit_error': 'Traceback (most recent call last):\n  File "/local/data0/moved_data/publishablew/cleanlab/cleanlab/ven...word argument \'filter_by\'\n', 'fit_time': 2.8371810913085938e-05, 'n_test_samples': 66, 'score_time': 0.0, ...}, ...]
error_score = nan

    def _warn_or_raise_about_fit_failures(results, error_score):
        fit_errors = [
            result["fit_error"] for result in results if result["fit_error"] is not None
        ]
        if fit_errors:
            num_failed_fits = len(fit_errors)
            num_fits = len(results)
            fit_errors_counter = Counter(fit_errors)
            delimiter = "-" * 80 + "\n"
            fit_errors_summary = "\n".join(
                f"{delimiter}{n} fits failed with the following error:\n{error}"
                for error, n in fit_errors_counter.items()
            )
    
            if num_failed_fits == num_fits:
                all_fits_failed_message = (
                    f"\nAll the {num_fits} fits failed.\n"
                    "It is very likely that your model is misconfigured.\n"
                    "You can try to debug the error by setting error_score='raise'.\n\n"
                    f"Below are more details about the failures:\n{fit_errors_summary}"
                )
>               raise ValueError(all_fits_failed_message)
E               ValueError: 
E               All the 30 fits failed.
E               It is very likely that your model is misconfigured.
E               You can try to debug the error by setting error_score='raise'.
E               
E               Below are more details about the failures:
E               --------------------------------------------------------------------------------
E               30 fits failed with the following error:
E               Traceback (most recent call last):
E                 File "/local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py", line 888, in _fit_and_score
E                   estimator.fit(X_train, y_train, **fit_params)
E                 File "/local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/classification.py", line 239, in fit
E                   label_issues = self.find_label_issues(X, labels, **self.find_label_issues_kwargs)
E                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
E               TypeError: CleanLearning.find_label_issues() got an unexpected keyword argument 'filter_by'

../publishablew/cleanlab/cleanlab/venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:529: ValueError
=============================== warnings summary ===============================
tests/test_classification.py::test_find_issues_low_memory
  /local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/classification.py:421: UserWarning: `find_label_issues_kwargs` is not used when `low_memory=True`.
    warnings.warn(f'`find_label_issues_kwargs` is not used when `low_memory=True`.')

tests/test_classification.py::test_find_issues_low_memory
  /local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/classification.py:425: UserWarning: `noise_matrix` is not used when `low_memory=True`.
    warnings.warn(f'`{arg_name}` is not used when `low_memory=True`.')

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data0]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data1]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data2]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl_default_clf
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data0]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data1]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data2]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_invalid_inputs
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_aux_inputs
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_validation_data
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_inm
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[numpy]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[sparse]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[dataframe]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[numpy]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[sparse]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[dataframe]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[numpy]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[sparse]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[dataframe]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[numpy]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[sparse]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[dataframe]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[numpy]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[sparse]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[dataframe]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[numpy]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[sparse]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[dataframe]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[numpy]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[sparse]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[dataframe]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[1]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[3]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[4]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_1D_formats
FAILED ../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_sklearn_gridsearchcv
================== 38 failed, 21 passed, 2 warnings in 7.96s ===================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/bin/python3
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/cleanlab/cleanlab
configfile: pyproject.toml
collecting ... collected 59 items

../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data0] PASSED [  1%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data1] PASSED [  3%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data2] PASSED [  5%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl_default_clf PASSED [  6%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data0] PASSED [  8%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data1] PASSED [ 10%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data2] PASSED [ 11%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_invalid_inputs PASSED [ 13%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_aux_inputs PASSED [ 15%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_validation_data PASSED [ 16%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_raise_error_no_clf_fit PASSED [ 18%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_raise_error_no_clf_predict_proba PASSED [ 20%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_raise_error_no_clf_predict PASSED [ 22%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_seed PASSED [ 23%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_default_clf PASSED [ 25%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm PASSED [ 27%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_inm PASSED [ 28%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[numpy] PASSED [ 30%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[sparse] PASSED [ 32%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[dataframe] PASSED [ 33%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[numpy] PASSED [ 35%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[sparse] PASSED [ 37%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[dataframe] PASSED [ 38%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[numpy] PASSED [ 40%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[sparse] PASSED [ 42%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[dataframe] PASSED [ 44%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[numpy] PASSED [ 45%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[sparse] PASSED [ 47%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[dataframe] PASSED [ 49%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[numpy] PASSED [ 50%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[sparse] PASSED [ 52%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[dataframe] PASSED [ 54%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_score[numpy] PASSED [ 55%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_score[sparse] PASSED [ 57%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_score[dataframe] PASSED [ 59%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_score[numpy] PASSED [ 61%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_score[sparse] PASSED [ 62%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_score[dataframe] PASSED [ 64%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[numpy] PASSED [ 66%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[sparse] PASSED [ 67%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[dataframe] PASSED [ 69%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[numpy] PASSED [ 71%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[sparse] PASSED [ 72%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[dataframe] PASSED [ 74%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[1] PASSED [ 76%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[3] PASSED [ 77%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[4] PASSED [ 79%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_1D_formats PASSED [ 81%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_sklearn_gridsearchcv PASSED [ 83%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[0-both] PASSED [ 84%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[0-confident_learning] PASSED [ 86%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[6-both] PASSED [ 88%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[6-confident_learning] PASSED [ 89%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[2-both] PASSED [ 91%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[2-confident_learning] PASSED [ 93%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_find_label_issues_uses_thresholds PASSED [ 94%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_find_issues_missing_classes PASSED [ 96%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_find_issues_low_memory PASSED [ 98%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_confident_joint_setting_in_find_label_issues_kwargs PASSED [100%]

=============================== warnings summary ===============================
tests/test_classification.py::test_find_issues_low_memory
  /local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/classification.py:810: UserWarning: `find_label_issues_kwargs` is not used when `low_memory=True`.
    warnings.warn(f"`find_label_issues_kwargs` is not used when `low_memory=True`.")

tests/test_classification.py::test_find_issues_low_memory
  /local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/classification.py:818: UserWarning: `noise_matrix` is not used when `low_memory=True`.
    warnings.warn(f"`{arg_name}` is not used when `low_memory=True`.")

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================= 59 passed, 2 warnings in 16.01s ========================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/bin/python3
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/cleanlab/cleanlab
configfile: pyproject.toml
collecting ... collected 59 items

../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data0] PASSED [  1%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data1] PASSED [  3%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl[data2] PASSED [  5%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cl_default_clf PASSED [  6%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data0] PASSED [  8%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data1] PASSED [ 10%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_rare_label[data2] PASSED [ 11%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_invalid_inputs PASSED [ 13%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_aux_inputs PASSED [ 15%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_validation_data PASSED [ 16%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_raise_error_no_clf_fit PASSED [ 18%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_raise_error_no_clf_predict_proba PASSED [ 20%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_raise_error_no_clf_predict PASSED [ 22%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_seed PASSED [ 23%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_default_clf PASSED [ 25%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm PASSED [ 27%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_inm PASSED [ 28%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[numpy] PASSED [ 30%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[sparse] PASSED [ 32%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_nm[dataframe] PASSED [ 33%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[numpy] PASSED [ 35%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[sparse] PASSED [ 37%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_with_inm[dataframe] PASSED [ 38%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[numpy] PASSED [ 40%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[sparse] PASSED [ 42%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_nm_inm[dataframe] PASSED [ 44%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[numpy] PASSED [ 45%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[sparse] PASSED [ 47%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_clf_fit_y_alias[dataframe] PASSED [ 49%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[numpy] PASSED [ 50%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[sparse] PASSED [ 52%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_pred_and_pred_proba[dataframe] PASSED [ 54%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_score[numpy] PASSED [ 55%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_score[sparse] PASSED [ 57%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_score[dataframe] PASSED [ 59%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_score[numpy] PASSED [ 61%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_score[sparse] PASSED [ 62%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_score[dataframe] PASSED [ 64%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[numpy] PASSED [ 66%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[sparse] PASSED [ 67%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_no_fit_sample_weight[dataframe] PASSED [ 69%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[numpy] PASSED [ 71%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[sparse] PASSED [ 72%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_fit_pred_probs[dataframe] PASSED [ 74%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[1] PASSED [ 76%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[3] PASSED [ 77%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_dimN[4] PASSED [ 79%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_1D_formats PASSED [ 81%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_sklearn_gridsearchcv PASSED [ 83%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[0-both] PASSED [ 84%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[0-confident_learning] PASSED [ 86%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[6-both] PASSED [ 88%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[6-confident_learning] PASSED [ 89%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[2-both] PASSED [ 91%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_cj_in_find_label_issues_kwargs[2-confident_learning] PASSED [ 93%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_find_label_issues_uses_thresholds PASSED [ 94%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_find_issues_missing_classes PASSED [ 96%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_find_issues_low_memory PASSED [ 98%]
../publishablew/cleanlab/cleanlab/tests/test_classification.py::test_confident_joint_setting_in_find_label_issues_kwargs PASSED [100%]

=============================== warnings summary ===============================
tests/test_classification.py::test_find_issues_low_memory
  /local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/classification.py:810: UserWarning: `find_label_issues_kwargs` is not used when `low_memory=True`.
    warnings.warn(f"`find_label_issues_kwargs` is not used when `low_memory=True`.")

tests/test_classification.py::test_find_issues_low_memory
  /local/data0/moved_data/publishablew/cleanlab/cleanlab/cleanlab/classification.py:818: UserWarning: `noise_matrix` is not used when `low_memory=True`.
    warnings.warn(f"`{arg_name}` is not used when `low_memory=True`.")

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================= 59 passed, 2 warnings in 17.08s ========================
