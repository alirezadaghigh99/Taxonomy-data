output file:
processed_kornianormalize_kernel2d313.json
function:
normalize_kernel2d
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-1-kernel_size1] FAILED', '../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_gradcheck[cpu] FAILED', '../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_module[cpu-float32] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-1-5]', 'FAILED ../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-1-kernel_size1]', 'FAILED ../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-2-kernel_size1]', 'FAILED ../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_module[cpu-float32]', '../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-2-5] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-2-5]', '../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-2-kernel_size1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_gradcheck[cpu]', '../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-1-5] FAILED'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'inductor', 'jit', 'cudagraphs', 'tvm', 'openxla', 'onnxrt', None}
model weights cached: ['checkpoints']

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1
collecting ... collected 33 items

../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel1d[cpu-float32-5] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel1d[cpu-float32-11] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel2d[cpu-float32-5] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel2d[cpu-float32-11] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel2d[cpu-float32-window_size2] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel1d_exact[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel2d_exact[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-5-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-5-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-kernel_size1-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-kernel_size1-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-kernel_size2-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-kernel_size2-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-5-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-5-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-kernel_size1-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-kernel_size1-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-kernel_size2-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-kernel_size2-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-5-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-5-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-kernel_size1-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-kernel_size1-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-3-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-3-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_exception SKIPPED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_noncontiguous[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_gradcheck[cpu] FAILED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_module[cpu-float32] FAILED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-1-5] FAILED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-1-kernel_size1] FAILED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-2-5] FAILED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-2-kernel_size1] FAILED

=================================== FAILURES ===================================
______________________ TestLaplacian.test_gradcheck[cpu] _______________________

self = <test_laplacian.TestLaplacian object at 0x7dae2f8f7d90>
device = device(type='cpu')

    def test_gradcheck(self, device):
        # test parameters
        batch_shape = (1, 2, 5, 7)
        kernel_size = 3
    
        # evaluate function gradient
        sample = torch.rand(batch_shape, device=device, dtype=torch.float64)
>       self.gradcheck(laplacian, (sample, kernel_size))

../publishablew/kornia/kornia/tests/filters/test_laplacian.py:87: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2081: in _gradcheck_helper
    _gradcheck_real_imag(
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:1491: in _gradcheck_real_imag
    gradcheck_fn(
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:1925: in _fast_gradcheck
    _check_analytical_numerical_equal(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

all_analytical = [[tensor(nan, dtype=torch.float64)]]
all_numerical = [[tensor(nan, dtype=torch.float64)]], complex_indices = None
tupled_inputs = (tensor([[[[0.2560, 0.5819, 0.5138, 0.7828, 0.0862, 0.7183, 0.7095],
          [0.5451, 0.2290, 0.3319, 0.7094, 0.5784...       [0.4308, 0.0996, 0.8779, 0.1620, 0.6273, 0.2407, 0.5250]]]],
       dtype=torch.float64, requires_grad=True), 3)
outputs = (tensor([[[[nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, na...an, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan]]]], dtype=torch.float64,
       grad_fn=<ViewBackward0>),)
func = <function laplacian at 0x7daeb6a26710>
all_v = [tensor([0.1808, 0.0118, 0.0713, 0.0616, 0.1861, 0.1731, 0.1666, 0.0942, 0.1823,
        0.0594, 0.1473, 0.0508, 0.030..., 0.1189, 0.1824, 0.0912,
        0.1017, 0.1195, 0.0121, 0.1954, 0.1019, 0.1151, 0.1580],
       dtype=torch.float64)]
all_u = [tensor([0.0578, 0.1888, 0.0725, 0.0872, 0.1703, 0.0990, 0.0156, 0.2102, 0.1546,
        0.0925, 0.0183, 0.1061, 0.036..., 0.0507, 0.0299, 0.1371,
        0.0204, 0.1025, 0.2150, 0.2019, 0.0025, 0.1845, 0.1320],
       dtype=torch.float64)]
rtol = 0.001, atol = 1e-05, eps = 1e-06, test_imag = False

    def _check_analytical_numerical_equal(
        all_analytical,
        all_numerical,
        complex_indices,
        tupled_inputs,
        outputs,
        func,
        all_v,
        all_u,
        rtol,
        atol,
        eps,
        test_imag,
        *,
        is_forward_ad=False,
    ):
        for i, all_numerical_for_input_i in enumerate(all_numerical):
            for j, n in enumerate(all_numerical_for_input_i):
                # Forward AD generates the transpose of what this function expects
                if is_forward_ad:
                    a = all_analytical[i][j]
                else:
                    a = all_analytical[j][i]
                n = n.to(device=a.device)
                updated_atol = _adjusted_atol(atol, all_u[i], all_v[j] if all_v else None)
                if not _allclose_with_type_promotion(a, n.to(a.device), rtol, updated_atol):
                    jacobians_str = _run_slow_mode_and_get_error(
                        func, tupled_inputs, outputs, i, j, rtol, atol, eps, is_forward_ad
                    )
>                   raise GradcheckError(
                        _get_notallclose_msg(
                            a, n, j, i, complex_indices, test_imag, is_forward_ad
                        )
                        + jacobians_str
                    )
E                   torch.autograd.gradcheck.GradcheckError: Jacobian mismatch for output 0 with respect to input 0,
E                   numerical:tensor(nan, dtype=torch.float64)
E                   analytical:tensor(nan, dtype=torch.float64)
E                   
E                   The above quantities relating the numerical and analytical jacobians are computed 
E                   in fast mode. See: https://github.com/pytorch/pytorch/issues/53876 for more background 
E                   about fast mode. Below, we recompute numerical and analytical jacobians in slow mode:
E                   
E                   Numerical:
E                    tensor([[nan, nan, nan,  ..., nan, nan, nan],
E                           [nan, nan, nan,  ..., nan, nan, nan],
E                           [nan, nan, nan,  ..., nan, nan, nan],
E                           ...,
E                           [nan, nan, nan,  ..., nan, nan, nan],
E                           [nan, nan, nan,  ..., nan, nan, nan],
E                           [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64)
E                   Analytical:
E                   tensor([[nan, nan, nan,  ..., nan, nan, nan],
E                           [nan, nan, nan,  ..., nan, nan, nan],
E                           [nan, nan, nan,  ..., nan, nan, nan],
E                           ...,
E                           [nan, nan, nan,  ..., nan, nan, nan],
E                           [nan, nan, nan,  ..., nan, nan, nan],
E                           [nan, nan, nan,  ..., nan, nan, nan]], dtype=torch.float64)
E                   
E                   The max per-element difference (slow mode) is: nan.

../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:1854: GradcheckError
____________________ TestLaplacian.test_module[cpu-float32] ____________________

self = <test_laplacian.TestLaplacian object at 0x7dae2f71c0d0>
device = device(type='cpu'), dtype = torch.float32

    def test_module(self, device, dtype):
        params = [3]
        op = laplacian
        op_module = Laplacian(*params)
    
        img = torch.ones(1, 3, 5, 5, device=device, dtype=dtype)
>       self.assert_close(op(img, *params), op_module(img))

../publishablew/kornia/kornia/tests/filters/test_laplacian.py:95: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/testing/base.py:106: in assert_close
    return assert_close(actual, expected, rtol=rtol, atol=atol)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
       ...nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
expected = tensor([[[[nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
       ...nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan]]]])
rtol = 0.0001, atol = 1e-05, kwargs = {}

    def assert_close(
        actual: Tensor, expected: Tensor, *, rtol: Optional[float] = None, atol: Optional[float] = None, **kwargs: Any
    ) -> None:
        if rtol is None and atol is None:
            # `torch.testing.assert_close` used different default tolerances than `torch.testing.assert_allclose`.
            # TODO: remove this special handling as soon as https://github.com/kornia/kornia/issues/1134 is resolved
            #  Basically, this whole wrapper function can be removed and `torch.testing.assert_close` can be used
            #  directly.
            rtol, atol = _default_tolerances(actual, expected)
    
>       return _assert_close(
            actual,
            expected,
            rtol=rtol,
            atol=atol,
            # this is the default value for torch>=1.10, but not for torch==1.9
            # TODO: remove this if kornia relies on torch>=1.10
            check_stride=False,
            equal_nan=False,
            **kwargs,
        )
E       AssertionError: Tensor-likes are not close!
E       
E       Mismatched elements: 75 / 75 (100.0%)
E       Greatest absolute difference: nan at index (0, 0, 0, 0) (up to 1e-05 allowed)
E       Greatest relative difference: nan at index (0, 0, 0, 0) (up to 0.0001 allowed)

../publishablew/kornia/kornia/testing/base.py:37: AssertionError
_____________ TestLaplacian.test_dynamo[cpu-float32-inductor-1-5] ______________

self = <test_laplacian.TestLaplacian object at 0x7dae2f8f78b0>, batch_size = 1
kernel_size = 5, device = device(type='cpu'), dtype = torch.float32
torch_optimizer = functools.partial(<function compile at 0x7daf14ddd990>, backend='inductor')

    @pytest.mark.parametrize("kernel_size", [5, (5, 7)])
    @pytest.mark.parametrize("batch_size", [1, 2])
    def test_dynamo(self, batch_size, kernel_size, device, dtype, torch_optimizer):
        data = torch.ones(batch_size, 3, 10, 10, device=device, dtype=dtype)
        op = Laplacian(kernel_size)
        op_optimized = torch_optimizer(op)
    
>       self.assert_close(op(data), op_optimized(data))

../publishablew/kornia/kornia/tests/filters/test_laplacian.py:104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/testing/base.py:106: in assert_close
    return assert_close(actual, expected, rtol=rtol, atol=atol)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = tensor([[[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]]])
expected = tensor([[[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]]])
rtol = 0.0001, atol = 1e-05, kwargs = {}

    def assert_close(
        actual: Tensor, expected: Tensor, *, rtol: Optional[float] = None, atol: Optional[float] = None, **kwargs: Any
    ) -> None:
        if rtol is None and atol is None:
            # `torch.testing.assert_close` used different default tolerances than `torch.testing.assert_allclose`.
            # TODO: remove this special handling as soon as https://github.com/kornia/kornia/issues/1134 is resolved
            #  Basically, this whole wrapper function can be removed and `torch.testing.assert_close` can be used
            #  directly.
            rtol, atol = _default_tolerances(actual, expected)
    
>       return _assert_close(
            actual,
            expected,
            rtol=rtol,
            atol=atol,
            # this is the default value for torch>=1.10, but not for torch==1.9
            # TODO: remove this if kornia relies on torch>=1.10
            check_stride=False,
            equal_nan=False,
            **kwargs,
        )
E       AssertionError: Tensor-likes are not close!
E       
E       Mismatched elements: 300 / 300 (100.0%)
E       Greatest absolute difference: nan at index (0, 0, 0, 0) (up to 1e-05 allowed)
E       Greatest relative difference: nan at index (0, 0, 0, 0) (up to 0.0001 allowed)

../publishablew/kornia/kornia/testing/base.py:37: AssertionError
________ TestLaplacian.test_dynamo[cpu-float32-inductor-1-kernel_size1] ________

self = <test_laplacian.TestLaplacian object at 0x7dae2f8f6ec0>, batch_size = 1
kernel_size = (5, 7), device = device(type='cpu'), dtype = torch.float32
torch_optimizer = functools.partial(<function compile at 0x7daf14ddd990>, backend='inductor')

    @pytest.mark.parametrize("kernel_size", [5, (5, 7)])
    @pytest.mark.parametrize("batch_size", [1, 2])
    def test_dynamo(self, batch_size, kernel_size, device, dtype, torch_optimizer):
        data = torch.ones(batch_size, 3, 10, 10, device=device, dtype=dtype)
        op = Laplacian(kernel_size)
        op_optimized = torch_optimizer(op)
    
>       self.assert_close(op(data), op_optimized(data))

../publishablew/kornia/kornia/tests/filters/test_laplacian.py:104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/testing/base.py:106: in assert_close
    return assert_close(actual, expected, rtol=rtol, atol=atol)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = tensor([[[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]]])
expected = tensor([[[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]]])
rtol = 0.0001, atol = 1e-05, kwargs = {}

    def assert_close(
        actual: Tensor, expected: Tensor, *, rtol: Optional[float] = None, atol: Optional[float] = None, **kwargs: Any
    ) -> None:
        if rtol is None and atol is None:
            # `torch.testing.assert_close` used different default tolerances than `torch.testing.assert_allclose`.
            # TODO: remove this special handling as soon as https://github.com/kornia/kornia/issues/1134 is resolved
            #  Basically, this whole wrapper function can be removed and `torch.testing.assert_close` can be used
            #  directly.
            rtol, atol = _default_tolerances(actual, expected)
    
>       return _assert_close(
            actual,
            expected,
            rtol=rtol,
            atol=atol,
            # this is the default value for torch>=1.10, but not for torch==1.9
            # TODO: remove this if kornia relies on torch>=1.10
            check_stride=False,
            equal_nan=False,
            **kwargs,
        )
E       AssertionError: Tensor-likes are not close!
E       
E       Mismatched elements: 300 / 300 (100.0%)
E       Greatest absolute difference: nan at index (0, 0, 0, 0) (up to 1e-05 allowed)
E       Greatest relative difference: nan at index (0, 0, 0, 0) (up to 0.0001 allowed)

../publishablew/kornia/kornia/testing/base.py:37: AssertionError
_____________ TestLaplacian.test_dynamo[cpu-float32-inductor-2-5] ______________

self = <test_laplacian.TestLaplacian object at 0x7dae2f71c520>, batch_size = 2
kernel_size = 5, device = device(type='cpu'), dtype = torch.float32
torch_optimizer = functools.partial(<function compile at 0x7daf14ddd990>, backend='inductor')

    @pytest.mark.parametrize("kernel_size", [5, (5, 7)])
    @pytest.mark.parametrize("batch_size", [1, 2])
    def test_dynamo(self, batch_size, kernel_size, device, dtype, torch_optimizer):
        data = torch.ones(batch_size, 3, 10, 10, device=device, dtype=dtype)
        op = Laplacian(kernel_size)
        op_optimized = torch_optimizer(op)
    
>       self.assert_close(op(data), op_optimized(data))

../publishablew/kornia/kornia/tests/filters/test_laplacian.py:104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/testing/base.py:106: in assert_close
    return assert_close(actual, expected, rtol=rtol, atol=atol)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = tensor([[[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]]])
expected = tensor([[[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]]])
rtol = 0.0001, atol = 1e-05, kwargs = {}

    def assert_close(
        actual: Tensor, expected: Tensor, *, rtol: Optional[float] = None, atol: Optional[float] = None, **kwargs: Any
    ) -> None:
        if rtol is None and atol is None:
            # `torch.testing.assert_close` used different default tolerances than `torch.testing.assert_allclose`.
            # TODO: remove this special handling as soon as https://github.com/kornia/kornia/issues/1134 is resolved
            #  Basically, this whole wrapper function can be removed and `torch.testing.assert_close` can be used
            #  directly.
            rtol, atol = _default_tolerances(actual, expected)
    
>       return _assert_close(
            actual,
            expected,
            rtol=rtol,
            atol=atol,
            # this is the default value for torch>=1.10, but not for torch==1.9
            # TODO: remove this if kornia relies on torch>=1.10
            check_stride=False,
            equal_nan=False,
            **kwargs,
        )
E       AssertionError: Tensor-likes are not close!
E       
E       Mismatched elements: 600 / 600 (100.0%)
E       Greatest absolute difference: nan at index (0, 0, 0, 0) (up to 1e-05 allowed)
E       Greatest relative difference: nan at index (0, 0, 0, 0) (up to 0.0001 allowed)

../publishablew/kornia/kornia/testing/base.py:37: AssertionError
________ TestLaplacian.test_dynamo[cpu-float32-inductor-2-kernel_size1] ________

self = <test_laplacian.TestLaplacian object at 0x7dae2f71c640>, batch_size = 2
kernel_size = (5, 7), device = device(type='cpu'), dtype = torch.float32
torch_optimizer = functools.partial(<function compile at 0x7daf14ddd990>, backend='inductor')

    @pytest.mark.parametrize("kernel_size", [5, (5, 7)])
    @pytest.mark.parametrize("batch_size", [1, 2])
    def test_dynamo(self, batch_size, kernel_size, device, dtype, torch_optimizer):
        data = torch.ones(batch_size, 3, 10, 10, device=device, dtype=dtype)
        op = Laplacian(kernel_size)
        op_optimized = torch_optimizer(op)
    
>       self.assert_close(op(data), op_optimized(data))

../publishablew/kornia/kornia/tests/filters/test_laplacian.py:104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/testing/base.py:106: in assert_close
    return assert_close(actual, expected, rtol=rtol, atol=atol)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

actual = tensor([[[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]]])
expected = tensor([[[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...   [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],
          [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]]])
rtol = 0.0001, atol = 1e-05, kwargs = {}

    def assert_close(
        actual: Tensor, expected: Tensor, *, rtol: Optional[float] = None, atol: Optional[float] = None, **kwargs: Any
    ) -> None:
        if rtol is None and atol is None:
            # `torch.testing.assert_close` used different default tolerances than `torch.testing.assert_allclose`.
            # TODO: remove this special handling as soon as https://github.com/kornia/kornia/issues/1134 is resolved
            #  Basically, this whole wrapper function can be removed and `torch.testing.assert_close` can be used
            #  directly.
            rtol, atol = _default_tolerances(actual, expected)
    
>       return _assert_close(
            actual,
            expected,
            rtol=rtol,
            atol=atol,
            # this is the default value for torch>=1.10, but not for torch==1.9
            # TODO: remove this if kornia relies on torch>=1.10
            check_stride=False,
            equal_nan=False,
            **kwargs,
        )
E       AssertionError: Tensor-likes are not close!
E       
E       Mismatched elements: 600 / 600 (100.0%)
E       Greatest absolute difference: nan at index (0, 0, 0, 0) (up to 1e-05 allowed)
E       Greatest relative difference: nan at index (0, 0, 0, 0) (up to 0.0001 allowed)

../publishablew/kornia/kornia/testing/base.py:37: AssertionError
=========================== short test summary info ============================
FAILED ../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_gradcheck[cpu]
FAILED ../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_module[cpu-float32]
FAILED ../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-1-5]
FAILED ../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-1-kernel_size1]
FAILED ../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-2-5]
FAILED ../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-2-kernel_size1]
=================== 6 failed, 26 passed, 1 skipped in 2.41s ====================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'openxla', 'tvm', 'onnxrt', 'jit', 'cudagraphs', 'inductor', None}
model weights cached: ['checkpoints']

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1
collecting ... collected 33 items

../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel1d[cpu-float32-5] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel1d[cpu-float32-11] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel2d[cpu-float32-5] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel2d[cpu-float32-11] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel2d[cpu-float32-window_size2] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel1d_exact[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel2d_exact[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-5-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-5-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-kernel_size1-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-kernel_size1-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-kernel_size2-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-kernel_size2-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-5-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-5-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-kernel_size1-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-kernel_size1-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-kernel_size2-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-kernel_size2-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-5-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-5-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-kernel_size1-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-kernel_size1-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-3-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-3-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_exception SKIPPED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_noncontiguous[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_gradcheck[cpu] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_module[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-1-5] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-1-kernel_size1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-2-5] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-2-kernel_size1] PASSED

======================== 32 passed, 1 skipped in 2.24s =========================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'jit', 'cudagraphs', 'onnxrt', 'tvm', 'inductor', 'openxla', None}
model weights cached: ['checkpoints']

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1
collecting ... collected 33 items

../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel1d[cpu-float32-5] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel1d[cpu-float32-11] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel2d[cpu-float32-5] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel2d[cpu-float32-11] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel2d[cpu-float32-window_size2] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel1d_exact[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::test_get_laplacian_kernel2d_exact[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-5-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-5-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-kernel_size1-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-kernel_size1-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-kernel_size2-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-True-kernel_size2-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-5-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-5-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-kernel_size1-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-kernel_size1-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-kernel_size2-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_smoke[cpu-float32-False-kernel_size2-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-5-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-5-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-kernel_size1-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-kernel_size1-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-3-shape0] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_cardinality[cpu-float32-3-shape1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_exception SKIPPED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_noncontiguous[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_gradcheck[cpu] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_module[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-1-5] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-1-kernel_size1] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-2-5] PASSED
../publishablew/kornia/kornia/tests/filters/test_laplacian.py::TestLaplacian::test_dynamo[cpu-float32-inductor-2-kernel_size1] PASSED

======================== 32 passed, 1 skipped in 2.50s =========================
