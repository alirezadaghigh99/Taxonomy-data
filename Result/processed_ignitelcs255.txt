output file:
processed_ignitelcs255.json
function:
lcs
Error Cases:

Pass or Failed: 1

Related Failed Test Cases:
set()

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/ignite/ignite/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/ignite/ignite
configfile: setup.cfg
collecting ... collected 4 items

../publishablew/ignite/ignite/tests/ignite/metrics/nlp/test_utils.py::test_lcs[seq_a0-seq_b0-0] PASSED
../publishablew/ignite/ignite/tests/ignite/metrics/nlp/test_utils.py::test_lcs[seq_a1-seq_b1-3] PASSED
../publishablew/ignite/ignite/tests/ignite/metrics/nlp/test_utils.py::test_lcs[seq_a2-seq_b2-2] PASSED
../publishablew/ignite/ignite/tests/ignite/metrics/nlp/test_utils.py::test_lcs[academy-abracadabra-4] PASSED

=============================== warnings summary ===============================
../publishablew/ignite/ignite/ignite/handlers/checkpoint.py:16
  /local/data0/moved_data/publishablew/ignite/ignite/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
    from torch.distributed.optim import ZeroRedundancyOptimizer

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================= 4 passed, 1 warning in 0.04s =========================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/ignite/ignite/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/ignite/ignite
configfile: setup.cfg
collecting ... collected 4 items

../publishablew/ignite/ignite/tests/ignite/metrics/nlp/test_utils.py::test_lcs[seq_a0-seq_b0-0] PASSED
../publishablew/ignite/ignite/tests/ignite/metrics/nlp/test_utils.py::test_lcs[seq_a1-seq_b1-3] PASSED
../publishablew/ignite/ignite/tests/ignite/metrics/nlp/test_utils.py::test_lcs[seq_a2-seq_b2-2] PASSED
../publishablew/ignite/ignite/tests/ignite/metrics/nlp/test_utils.py::test_lcs[academy-abracadabra-4] PASSED

=============================== warnings summary ===============================
../publishablew/ignite/ignite/ignite/handlers/checkpoint.py:16
  /local/data0/moved_data/publishablew/ignite/ignite/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
    from torch.distributed.optim import ZeroRedundancyOptimizer

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================= 4 passed, 1 warning in 0.01s =========================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/ignite/ignite/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/ignite/ignite
configfile: setup.cfg
collecting ... collected 4 items

../publishablew/ignite/ignite/tests/ignite/metrics/nlp/test_utils.py::test_lcs[seq_a0-seq_b0-0] PASSED
../publishablew/ignite/ignite/tests/ignite/metrics/nlp/test_utils.py::test_lcs[seq_a1-seq_b1-3] PASSED
../publishablew/ignite/ignite/tests/ignite/metrics/nlp/test_utils.py::test_lcs[seq_a2-seq_b2-2] PASSED
../publishablew/ignite/ignite/tests/ignite/metrics/nlp/test_utils.py::test_lcs[academy-abracadabra-4] PASSED

=============================== warnings summary ===============================
../publishablew/ignite/ignite/ignite/handlers/checkpoint.py:16
  /local/data0/moved_data/publishablew/ignite/ignite/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
    from torch.distributed.optim import ZeroRedundancyOptimizer

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================= 4 passed, 1 warning in 0.01s =========================
