output file:
processed_Laplacefit15.json
function:
fit
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace]', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] FAILED', 'FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace]', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] FAILED', '../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] FAILED'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] FAILED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] FAILED

=================================== FAILURES ===================================
___________ test_laplace_init_prior_mean_and_scatter[FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa752290>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d22750>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

../publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
___________ test_laplace_init_prior_mean_and_scatter[KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da4260f9550>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.KronLLLaplace object at 0x7da3fa741610>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

../publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
___________ test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa740d50>

    @pytest.mark.parametrize("laplace", flavors)
    def test_laplace_init_prior_mean_and_scatter(laplace, model, class_loader):
        lap_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=1.0,
        )
        assert torch.allclose(lap_scalar_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1),
        )
        assert torch.allclose(lap_tensor_mean.prior_mean, torch.tensor([1.0]))
        lap_tensor_scalar_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(1)[0],
        )
        assert torch.allclose(lap_tensor_scalar_mean.prior_mean, torch.tensor(1.0))
        lap_tensor_full_mean = laplace(
            model,
            "classification",
            last_layer_name="1",
            prior_precision=1e-2,
            prior_mean=torch.ones(20 * 2 + 2),
        )
        assert torch.allclose(lap_tensor_full_mean.prior_mean, torch.ones(20 * 2 + 2))
    
        lap_scalar_mean.fit(class_loader)
        lap_tensor_mean.fit(class_loader)
        lap_tensor_scalar_mean.fit(class_loader)
        lap_tensor_full_mean.fit(class_loader)
        expected = lap_scalar_mean.scatter
        assert expected.ndim == 0
        assert torch.allclose(lap_tensor_mean.scatter, expected)
        assert lap_tensor_mean.scatter.shape == expected.shape
        assert torch.allclose(lap_tensor_scalar_mean.scatter, expected)
        assert lap_tensor_scalar_mean.scatter.shape == expected.shape
>       assert torch.allclose(lap_tensor_full_mean.scatter, expected)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:315: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3faaf3fd0>

    @property
    def scatter(self) -> torch.Tensor:
        """Computes the _scatter_, a term of the log marginal likelihood that
        corresponds to L-2 regularization:
        `scatter` = \\((\\theta_{MAP} - \\mu_0)^{T} P_0 (\\theta_{MAP} - \\mu_0) \\).
    
        Returns
        -------
        scatter: torch.Tensor
        """
>       delta = self.mean - self.prior_mean
E       RuntimeError: The size of tensor a (122) must match the size of tensor b (42) at non-singleton dimension 0

../publishablew/Laplace/Laplace/laplace/baselaplace.py:943: RuntimeError
__ test_laplace_functionality[pick_first-False-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d64d90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d66490>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d663d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d66210>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d641d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[pick_first-False-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9347150>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9346e90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9346dd0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f93473d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f9347490>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__ test_laplace_functionality[pick_first-False-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa798d10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa79bd50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa798790>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa798650>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[pick_first-False-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa753610>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa753450>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa750f10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa751110>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__ test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7f9890>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7f8310>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7f8050>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7f8490>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa7f87d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_first'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d07850>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d06550>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d07e90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d071d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f5d06190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_first-True-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faae44d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faae6890>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faae7a90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faae56d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3faae59d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_first-True-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da51d1b6290>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da51d1b5fd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa751490>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa751710>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa750d10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_first-True-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da4260f9410>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da4260fa850>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa72f450>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa72c8d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_first-True-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7b2950>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7b3ad0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7b1550>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7b30d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f938dc50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f938df10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f938e950>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f938eb90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f938c610>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_first'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9f6610>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9f7210>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9edc10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ed8d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa9ee2d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_last-False-FullLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faaecfd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da4021519d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d34f10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d35810>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d371d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_last-False-FullLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d73a10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d71490>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d734d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d71f50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d70e10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_last-False-KronLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ee2d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ee550>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ee390>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9eced0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_last-False-KronLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7b4890>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7b4a50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7b4f50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7b4ed0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] ___

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa71bf50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa71bd10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa71bdd0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa71bc50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa718490>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'pick_last'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9347750>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9344b90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9347910>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9345750>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9344e50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___ test_laplace_functionality[pick_last-True-FullLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d21b90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d234d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d20990>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d23cd0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d226d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[pick_last-True-FullLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da51b6c86d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da51b6c8790>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da51b6c9410>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7f4a50>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa7f7990>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___ test_laplace_functionality[pick_last-True-KronLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9347450>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9344050>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9347c90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f93454d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[pick_last-True-KronLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa775bd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa775fd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa777c10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7778d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___ test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7f8bd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7f8a90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7fa1d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7fb490>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa7f9c50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'pick_last'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa775bd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa775e10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7753d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa776f10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa777550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[average-False-FullLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa834490>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa834550>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7070d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa707850>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa705a50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[average-False-FullLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7a9ad0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7a97d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7ab050>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7ab490>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa7aa6d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[average-False-KronLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ee7d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ef850>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ef510>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9eebd0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[average-False-KronLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa776ad0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa777390>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa777d50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7779d0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[average-False-DiagLLLaplace-classification] ____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9347f50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9347750>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9346f90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9344950>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9345950>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[average-False-DiagLLLaplace-regression] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = 'average'
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9dcae10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9dcb190>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9dcac10>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9dcb490>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9dcbf90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____ test_laplace_functionality[average-True-FullLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8df990>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8df850>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8dd250>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8dd450>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa8dc7d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[average-True-FullLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ed950>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9effd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ed510>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ee150>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa9ed3d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____ test_laplace_functionality[average-True-KronLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faaf0c10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faaf1ad0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faaf1990>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faaf3310>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[average-True-KronLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8dde50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8de290>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8df910>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8dcd90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____ test_laplace_functionality[average-True-DiagLLLaplace-classification] _____

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faaf3ed0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ecb10>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ee090>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa9ef510>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa9eec50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[average-True-DiagLLLaplace-regression] _______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = 'average'
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa741e10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa741fd0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa741710>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa742710>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa742d50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____ test_laplace_functionality[None-False-FullLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d83010>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d82950>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d80110>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d83150>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d83350>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______ test_laplace_functionality[None-False-FullLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faaf1f10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faaf30d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faaf37d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faaf1150>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa9edc90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____ test_laplace_functionality[None-False-KronLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7a9250>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7aac90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7a8950>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7a8490>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______ test_laplace_functionality[None-False-KronLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa72e790>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa72ff90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa72de90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa72e690>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____ test_laplace_functionality[None-False-DiagLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7a9e10>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7aa850>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7aa950>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3faaeee10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa9ede10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______ test_laplace_functionality[None-False-DiagLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = False, reduction = None
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d735d0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d700d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d71c50>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d71550>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f5d70490>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______ test_laplace_functionality[None-True-FullLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d64f90>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d67b90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d661d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d66410>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d65b90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_laplace_functionality[None-True-FullLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa706cd0>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa704c50>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7043d0>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa707e90>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa707650>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______ test_laplace_functionality[None-True-KronLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d73850>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d73910>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d71b90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d71f10>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_laplace_functionality[None-True-KronLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9d53e50>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9d51c90>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9d51710>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9d53150>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______ test_laplace_functionality[None-True-DiagLLLaplace-classification] ______

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'classification'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8be850>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8bf9d0>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8bf310>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8bd510>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa8bc090>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_laplace_functionality[None-True-DiagLLLaplace-regression] ________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>, lh = 'regression'
multidim = True, reduction = None
model = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
model_with_reduction = Model(
  (fc1): Linear(in_features=3, out_features=20, bias=True)
  (fc2): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8bd450>
multidim_reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8be390>
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8bfa90>
multidim_class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8bedd0>

    @pytest.mark.parametrize(
        "laplace,lh", product(flavors, ["classification", "regression"])
    )
    @pytest.mark.parametrize("multidim", [False, True])
    @pytest.mark.parametrize("reduction", [f.value for f in FeatureReduction] + [None])
    def test_laplace_functionality(
        laplace,
        lh,
        multidim,
        reduction,
        model,
        model_with_reduction,
        reg_loader,
        multidim_reg_loader,
        class_loader,
        multidim_class_loader,
    ):
        if lh == "classification":
            loader = class_loader if not multidim else multidim_class_loader
            sigma_noise = 1.0
        else:
            loader = reg_loader if not multidim else multidim_reg_loader
            sigma_noise = 0.3
    
        if not multidim:
            last_layer_name = "1"
        else:
            model = model_with_reduction
            last_layer_name = "fc2"
    
        lap = laplace(
            model,
            lh,
            sigma_noise=sigma_noise,
            prior_precision=0.7,
            feature_reduction=reduction,
        )
>       lap.fit(loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:398: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa8bcf10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________________ test_regression_predictive[FullLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8bca50>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa8bcb50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________________ test_regression_predictive[KronLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa821850>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________________ test_regression_predictive[DiagLLLaplace] ___________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7f6e10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:474: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa7f6a50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________________ test_classification_predictive[FullLLLaplace] _________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa808490>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d73ad0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________________ test_classification_predictive[KronLLLaplace] _________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7ab290>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________________ test_classification_predictive[DiagLLLaplace] _________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa82ef10>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:498: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9d22010>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_regression_predictive_samples[FullLLLaplace] _______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7aa650>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa82e6d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_regression_predictive_samples[KronLLLaplace] _______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7c5f50>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_regression_predictive_samples[DiagLLLaplace] _______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7f8a50>

    @pytest.mark.parametrize("laplace", flavors)
    def test_regression_predictive_samples(laplace, model, reg_loader):
        lap = laplace(model, "regression", sigma_noise=0.3, prior_precision=0.7)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:539: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa7fbb90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_classification_predictive_samples[FullLLLaplace] _____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7779d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa774810>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_classification_predictive_samples[KronLLLaplace] _____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7f99d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_classification_predictive_samples[DiagLLLaplace] _____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
class_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9db8810>

    @pytest.mark.parametrize("laplace", flavors)
    def test_classification_predictive_samples(laplace, model, class_loader):
        lap = laplace(model, "classification", prior_precision=0.7)
>       lap.fit(class_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:559: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9db8ad0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________________ test_functional_variance_fast[FullLLLaplace] _________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7c5fd0>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, DiagLLLaplace, KronLLLaplace])
    def test_functional_variance_fast(laplace, model, reg_loader):
        if laplace == KronLLLaplace:
            # TODO still!
            return
    
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fd11ba10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________________ test_functional_variance_fast[DiagLLLaplace] _________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7f8d90>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, DiagLLLaplace, KronLLLaplace])
    def test_functional_variance_fast(laplace, model, reg_loader):
        if laplace == KronLLLaplace:
            # TODO still!
            return
    
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:588: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa7f8890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______________________ test_backprop_glm[FullLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa71b290>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa71b650>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______________________ test_backprop_glm[KronLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7a99d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______________________ test_backprop_glm[DiagLLLaplace] _______________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7fbb90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:614: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa7f8150>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________________ test_backprop_glm_joint[FullLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa707ed0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa704f50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________________ test_backprop_glm_joint[KronLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f5d4c590>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________________ test_backprop_glm_joint[DiagLLLaplace] ____________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9d49bd0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_joint(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:633: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9d49ed0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________________ test_backprop_glm_mc[FullLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7fa4d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa7fbb90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________________ test_backprop_glm_mc[KronLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa8bcc90>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________________ test_backprop_glm_mc[DiagLLLaplace] ______________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9d20190>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_glm_mc(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:652: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9d204d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_______________________ test_backprop_nn[FullLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa82e210>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa82e050>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_______________________ test_backprop_nn[KronLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9db7fd0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_______________________ test_backprop_nn[DiagLLLaplace] ________________________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9da19d0>

    @pytest.mark.parametrize("laplace", flavors)
    def test_backprop_nn(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        X.requires_grad = True
    
        lap = laplace(model, "regression", enable_backprop=True)
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:671: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9da2690>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_reg_glm_predictive_correct_behavior[FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3f9347e50>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa7e2fd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_reg_glm_predictive_correct_behavior[KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7abb50>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_reg_glm_predictive_correct_behavior[DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
model = Sequential(
  (0): Linear(in_features=3, out_features=20, bias=True)
  (1): Linear(in_features=20, out_features=2, bias=True)
)
reg_loader = <torch.utils.data.dataloader.DataLoader object at 0x7da3fa7071d0>

    @pytest.mark.parametrize("laplace", [FullLLLaplace, KronLLLaplace, DiagLLLaplace])
    def test_reg_glm_predictive_correct_behavior(laplace, model, reg_loader):
        X, y = reg_loader.dataset.tensors
        n_batch = X.shape[0]
        n_outputs = y.shape[-1]
    
        lap = laplace(model, "regression")
>       lap.fit(reg_loader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:691: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa707150>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f9db40d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9da3e50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa89fc90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9344190>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa7f99d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9346750>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d67090>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa72d650>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d66950>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9d706d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa7184d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f5d4c210>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f9d49bd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9dc8890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f9dcb110>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9d23790>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa7e1a10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f77b05d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa89ecd0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9d51690>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa8df790>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa7e06d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa8df890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa8df390>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa72e490>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f5d366d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa7c40d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f7730d50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa8de290>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f7784d10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] __________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa78c450>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] __________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] __________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f7733990>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d4dc50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_________ test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f77031d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] _________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa8be250>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] _________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
________ test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] _________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'classification'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3fa8bda50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa8de9d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f5d4db10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f938d950>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f775d810>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d40310>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float16
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9d252d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa7c5d90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f7757850>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d04550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f5d40b50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f7784a90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float16

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float16, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f5d40a90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f77ba6d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f5d41ed0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f77b1d10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f5d428d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f9354290>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float32
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f5d43c10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3fa73cd90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f7761d10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d437d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9d4bd10>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f77962d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float32

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float32, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9df5890>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f5d04490>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
______________ test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f77ff5d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] ______________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f7754550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] ______________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
_____________ test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] ______________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.asdl.AsdlGGN'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f9dc6a90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f77b9550>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
____________ test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackEF'>, dtype = torch.float64
likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f779b610>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] ____________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f9d52110>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] ____________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] ____________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.backpack.BackPackGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f7795d50>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f9355210>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
___________ test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsEF'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f77967d0>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] ___________

laplace = <class 'laplace.lllaplace.FullLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1576: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.FullLLLaplace object at 0x7da3f7731e90>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:1557: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] ___________

laplace = <class 'laplace.lllaplace.KronLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:1741: in fit
    super().fit(train_loader, override=override, progress_bar=progress_bar)
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
../publishablew/Laplace/Laplace/laplace/lllaplace.py:273: in _init_H
    self.H = Kron.init_from_model(self.model.last_layer, self._device, self._dtype)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'laplace.utils.matrix.Kron'>, model = None
device = device(type='cpu'), dtype = torch.float64

    @classmethod
    def init_from_model(
        cls,
        model: nn.Module | Iterable[nn.Parameter],
        device: torch.device,
        dtype: torch.dtype,
    ) -> Kron:
        """Initialize Kronecker factors based on a models architecture.
    
        Parameters
        ----------
        model: `nn.Module` or iterable of parameters, e.g. `model.parameters()`
        device: The device where each of the Kronecker factor lives in.
        dtype: The data type of each Kronecker factor.
    
        Returns
        -------
        kron : Kron
        """
        if isinstance(model, torch.nn.Module):
            params = model.parameters()
        else:
            params = model
    
        kfacs = list()
>       for p in params:
E       TypeError: 'NoneType' object is not iterable

../publishablew/Laplace/Laplace/laplace/utils/matrix.py:58: TypeError
__________ test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] ___________

laplace = <class 'laplace.lllaplace.DiagLLLaplace'>
backend = <class 'laplace.curvature.curvlinops.CurvlinopsGGN'>
dtype = torch.float64, likelihood = 'regression'

    @pytest.mark.parametrize("laplace", flavors)
    @pytest.mark.parametrize(
        "backend", [AsdlEF, AsdlGGN, BackPackEF, BackPackGGN, CurvlinopsEF, CurvlinopsGGN]
    )
    @pytest.mark.parametrize("dtype", [torch.half, torch.float, torch.double])
    @pytest.mark.parametrize("likelihood", ["classification", "regression"])
    def test_dtype(laplace, backend, dtype, likelihood):
        X = torch.randn((10, 3), dtype=dtype)
        Y = torch.randn((10, 3), dtype=dtype)
    
        data = TensorDataset(X, Y)
        dataloader = DataLoader(data, batch_size=10)
    
        model = nn.Linear(3, 3, dtype=dtype)
    
        try:
            la = laplace(model, likelihood, backend=backend)
>           la.fit(dataloader)

../publishablew/Laplace/Laplace/tests/test_lllaplace.py:725: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/Laplace/Laplace/laplace/baselaplace.py:871: in fit
    self._init_H()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <laplace.lllaplace.DiagLLLaplace object at 0x7da3f777d710>

    def _init_H(self) -> None:
>       self.H: torch.Tensor = torch.zeros(
            self.n_params, device=self._device, dtype=self._dtype
        )
E       TypeError: zeros() received an invalid combination of arguments - got (NoneType, dtype=torch.dtype, device=torch.device), but expected one of:
E        * (tuple of ints size, *, tuple of names names, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)
E        * (tuple of ints size, *, Tensor out = None, torch.dtype dtype = None, torch.layout layout = None, torch.device device = None, bool pin_memory = False, bool requires_grad = False)

../publishablew/Laplace/Laplace/laplace/baselaplace.py:2003: TypeError
=============================== warnings summary ===============================
../publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace]
FAILED ../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace]
================= 188 failed, 24 passed, 3 warnings in 21.84s ==================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED

=============================== warnings summary ===============================
../publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py: 27 warnings
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================= 212 passed, 29 warnings in 63.62s (0:01:03) ==================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/Laplace/Laplace/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/Laplace/Laplace
configfile: pyproject.toml
plugins: mock-3.14.0, cov-6.0.0
collecting ... collected 212 items

../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_nollname[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_large_init_nollname[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_invalid_likelihood[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_noise[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_precision[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_prior_mean_and_scatter[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_init_temperature[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-False-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_first-True-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-False-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[pick_last-True-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-False-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[average-True-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-False-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-FullLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-KronLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-classification] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_laplace_functionality[None-True-DiagLLLaplace-regression] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_regression_predictive_samples[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_classification_predictive_samples[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_functional_variance_fast[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_joint[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_glm_mc[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_backprop_nn[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_reg_glm_predictive_correct_behavior[DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[classification-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-AsdlGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-BackPackGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype0-CurvlinopsGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-AsdlGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-BackPackGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype1-CurvlinopsGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-AsdlGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-BackPackGGN-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsEF-DiagLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-FullLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-KronLLLaplace] PASSED
../publishablew/Laplace/Laplace/tests/test_lllaplace.py::test_dtype[regression-dtype2-CurvlinopsGGN-DiagLLLaplace] PASSED

=============================== warnings summary ===============================
../publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:18: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION = LooseVersion(version("torch"))

../publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/unfoldNd/utils.py:19: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    TORCH_VERSION_AT_LEAST_1_12_0 = TORCH_VERSION >= LooseVersion("1.12.0")

tests/test_lllaplace.py: 27 warnings
  /local/data0/moved_data/publishablew/Laplace/Laplace/venv/lib/python3.11/site-packages/curvlinops/_base.py:299: UserWarning: Input matrix is float64, while linear operator is float32. Converting to float32.
    warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================= 212 passed, 29 warnings in 65.91s (0:01:05) ==================
