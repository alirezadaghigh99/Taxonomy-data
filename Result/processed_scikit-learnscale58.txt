output file:
processed_scikit-learnscale58.json
function:
scale
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0] FAILED', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler0] FAILED', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0] FAILED', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0] FAILED', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler0]', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler0] FAILED', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0] FAILED', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0]', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0]', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0]', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0]', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0]', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0]', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler0]', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0]', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0]', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0] FAILED', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0] FAILED', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0] FAILED', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0] FAILED', 'FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0]', '../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0] FAILED'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.9.0, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/scikit-learn/scikit-learn
configfile: setup.cfg
plugins: cov-6.0.0
collecting ... collected 120 items

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-None-scaler0] I: Seeding RNGs with 942391805
PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0] FAILED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_array-scaler1] SKIPPED

=================================== FAILURES ===================================
__ test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_matrix'>
dtype = <class 'numpy.float32'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse matrix of type '<class 'numpy.float32'>'
	with 0 stored elements in Compressed Sparse Column format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
__ test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0] ___

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_array'>
dtype = <class 'numpy.float32'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse array of type '<class 'numpy.float32'>'
	with 0 stored elements in Compressed Sparse Column format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
__ test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_matrix'>
dtype = <class 'numpy.float32'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse matrix of type '<class 'numpy.float32'>'
	with 0 stored elements in Compressed Sparse Row format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
__ test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0] ___

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_array'>
dtype = <class 'numpy.float32'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse array of type '<class 'numpy.float32'>'
	with 0 stored elements in Compressed Sparse Row format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
__ test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_matrix'>
dtype = <class 'numpy.float64'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Column format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
__ test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0] ___

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_array'>
dtype = <class 'numpy.float64'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse array of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Column format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
__ test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_matrix'>
dtype = <class 'numpy.float64'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse matrix of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
__ test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0] ___

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_array'>
dtype = <class 'numpy.float64'>, constant = 0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse array of type '<class 'numpy.float64'>'
	with 0 stored elements in Compressed Sparse Row format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
____ test_standard_scaler_constant_features[1.0-float32-False-None-scaler0] ____

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = None, dtype = <class 'numpy.float32'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
            X_scaled_2 = scale(X, with_mean=scaler.with_mean)
            assert X_scaled_2 is not X  # make sure we did a copy
>           assert_allclose_dense_sparse(X_scaled_2, X)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:285: in assert_allclose_dense_sparse
    assert_allclose(x, y, rtol=rtol, atol=atol, err_msg=err_msg)
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:239: in assert_allclose
    np_assert_allclose(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<function assert_allclose.<locals>.compare at 0x7072645c6c10>, array([[0.],
       [0.],
       [0.],
       [0.],
  ...      [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]], dtype=float32))
kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-07, atol=1e-09', 'strict': False, ...}

    @wraps(func)
    def inner(*args, **kwds):
        with self._recreate_cm():
>           return func(*args, **kwds)
E           AssertionError: 
E           Not equal to tolerance rtol=1e-07, atol=1e-09
E           
E           Mismatched elements: 100 / 100 (100%)
E           Max absolute difference among violations: 1.
E           Max relative difference among violations: 1.
E            ACTUAL: array([[0.],
E                  [0.],
E                  [0.],...
E            DESIRED: array([[1.],
E                  [1.],
E                  [1.],...

/usr/local/lib/python3.9/contextlib.py:79: AssertionError
_ test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_matrix'>
dtype = <class 'numpy.float32'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse matrix of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Column format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
_ test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_array'>
dtype = <class 'numpy.float32'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse array of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Column format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
_ test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_matrix'>
dtype = <class 'numpy.float32'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse matrix of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Row format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
_ test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_array'>
dtype = <class 'numpy.float32'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse array of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Row format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
____ test_standard_scaler_constant_features[1.0-float64-False-None-scaler0] ____

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = None, dtype = <class 'numpy.float64'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
            X_scaled_2 = scale(X, with_mean=scaler.with_mean)
            assert X_scaled_2 is not X  # make sure we did a copy
>           assert_allclose_dense_sparse(X_scaled_2, X)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:285: in assert_allclose_dense_sparse
    assert_allclose(x, y, rtol=rtol, atol=atol, err_msg=err_msg)
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:239: in assert_allclose
    np_assert_allclose(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<function assert_allclose.<locals>.compare at 0x707266dab700>, array([[0.],
       [0.],
       [0.],
       [0.],
  ...
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.],
       [1.]]))
kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-07, atol=1e-09', 'strict': False, ...}

    @wraps(func)
    def inner(*args, **kwds):
        with self._recreate_cm():
>           return func(*args, **kwds)
E           AssertionError: 
E           Not equal to tolerance rtol=1e-07, atol=1e-09
E           
E           Mismatched elements: 100 / 100 (100%)
E           Max absolute difference among violations: 1.
E           Max relative difference among violations: 1.
E            ACTUAL: array([[0.],
E                  [0.],
E                  [0.],...
E            DESIRED: array([[1.],
E                  [1.],
E                  [1.],...

/usr/local/lib/python3.9/contextlib.py:79: AssertionError
_ test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_matrix'>
dtype = <class 'numpy.float64'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse matrix of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Column format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
_ test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_array'>
dtype = <class 'numpy.float64'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse array of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Column format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
_ test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_matrix'>
dtype = <class 'numpy.float64'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse matrix of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Row format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
_ test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0] __

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_array'>
dtype = <class 'numpy.float64'>, constant = 1.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse array of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Row format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
___ test_standard_scaler_constant_features[100.0-float32-False-None-scaler0] ___

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = None, dtype = <class 'numpy.float32'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
            X_scaled_2 = scale(X, with_mean=scaler.with_mean)
            assert X_scaled_2 is not X  # make sure we did a copy
>           assert_allclose_dense_sparse(X_scaled_2, X)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:285: in assert_allclose_dense_sparse
    assert_allclose(x, y, rtol=rtol, atol=atol, err_msg=err_msg)
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:239: in assert_allclose
    np_assert_allclose(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<function assert_allclose.<locals>.compare at 0x70726c864430>, array([[0.],
       [0.],
       [0.],
       [0.],
  ...     [100.],
       [100.],
       [100.],
       [100.],
       [100.],
       [100.],
       [100.]], dtype=float32))
kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-07, atol=1e-09', 'strict': False, ...}

    @wraps(func)
    def inner(*args, **kwds):
        with self._recreate_cm():
>           return func(*args, **kwds)
E           AssertionError: 
E           Not equal to tolerance rtol=1e-07, atol=1e-09
E           
E           Mismatched elements: 100 / 100 (100%)
E           Max absolute difference among violations: 100.
E           Max relative difference among violations: 1.
E            ACTUAL: array([[0.],
E                  [0.],
E                  [0.],...
E            DESIRED: array([[100.],
E                  [100.],
E                  [100.],...

/usr/local/lib/python3.9/contextlib.py:79: AssertionError
_ test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_matrix'>
dtype = <class 'numpy.float32'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse matrix of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Column format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
_ test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_array'>
dtype = <class 'numpy.float32'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse array of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Column format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
_ test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_matrix'>
dtype = <class 'numpy.float32'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse matrix of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Row format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
_ test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_array'>
dtype = <class 'numpy.float32'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse array of type '<class 'numpy.float32'>'
	with 100 stored elements in Compressed Sparse Row format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
___ test_standard_scaler_constant_features[100.0-float64-False-None-scaler0] ___

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = None, dtype = <class 'numpy.float64'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
            X_scaled_2 = scale(X, with_mean=scaler.with_mean)
            assert X_scaled_2 is not X  # make sure we did a copy
>           assert_allclose_dense_sparse(X_scaled_2, X)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:269: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:285: in assert_allclose_dense_sparse
    assert_allclose(x, y, rtol=rtol, atol=atol, err_msg=err_msg)
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_testing.py:239: in assert_allclose
    np_assert_allclose(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = (<function assert_allclose.<locals>.compare at 0x707266dab700>, array([[0.],
       [0.],
       [0.],
       [0.],
  ...     [100.],
       [100.],
       [100.],
       [100.],
       [100.],
       [100.],
       [100.],
       [100.]]))
kwds = {'equal_nan': True, 'err_msg': '', 'header': 'Not equal to tolerance rtol=1e-07, atol=1e-09', 'strict': False, ...}

    @wraps(func)
    def inner(*args, **kwds):
        with self._recreate_cm():
>           return func(*args, **kwds)
E           AssertionError: 
E           Not equal to tolerance rtol=1e-07, atol=1e-09
E           
E           Mismatched elements: 100 / 100 (100%)
E           Max absolute difference among violations: 100.
E           Max relative difference among violations: 1.
E            ACTUAL: array([[0.],
E                  [0.],
E                  [0.],...
E            DESIRED: array([[100.],
E                  [100.],
E                  [100.],...

/usr/local/lib/python3.9/contextlib.py:79: AssertionError
_ test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_matrix'>
dtype = <class 'numpy.float64'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse matrix of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Column format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
_ test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csc.csc_array'>
dtype = <class 'numpy.float64'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse array of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Column format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
_ test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_matrix'>
dtype = <class 'numpy.float64'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse matrix of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Row format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
_ test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0] _

scaler = StandardScaler(with_mean=False), add_sample_weight = False
sparse_container = <class 'scipy.sparse._csr.csr_array'>
dtype = <class 'numpy.float64'>, constant = 100.0

    @pytest.mark.parametrize(
        "scaler",
        [
            StandardScaler(with_mean=False),
            RobustScaler(with_centering=False),
        ],
    )
    @pytest.mark.parametrize("sparse_container", [None] + CSC_CONTAINERS + CSR_CONTAINERS)
    @pytest.mark.parametrize("add_sample_weight", [False, True])
    @pytest.mark.parametrize("dtype", [np.float32, np.float64])
    @pytest.mark.parametrize("constant", [0, 1.0, 100.0])
    def test_standard_scaler_constant_features(
        scaler, add_sample_weight, sparse_container, dtype, constant
    ):
        if isinstance(scaler, RobustScaler) and add_sample_weight:
            pytest.skip(f"{scaler.__class__.__name__} does not yet support sample_weight")
    
        rng = np.random.RandomState(0)
        n_samples = 100
        n_features = 1
        if add_sample_weight:
            fit_params = dict(sample_weight=rng.uniform(size=n_samples) * 2)
        else:
            fit_params = {}
        X_array = np.full(shape=(n_samples, n_features), fill_value=constant, dtype=dtype)
        X = X_array if sparse_container is None else sparse_container(X_array)
        X_scaled = scaler.fit(X, **fit_params).transform(X)
    
        if isinstance(scaler, StandardScaler):
            # The variance info should be close to zero for constant features.
            assert_allclose(scaler.var_, np.zeros(X.shape[1]), atol=1e-7)
    
        # Constant features should not be scaled (scale of 1.):
        assert_allclose(scaler.scale_, np.ones(X.shape[1]))
    
        assert X_scaled is not X  # make sure we make a copy
        assert_allclose_dense_sparse(X_scaled, X)
    
        if isinstance(scaler, StandardScaler) and not add_sample_weight:
            # Also check consistency with the standard scale function.
>           X_scaled_2 = scale(X, with_mean=scaler.with_mean)

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py:267: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/scikit-learn/scikit-learn/sklearn/utils/_param_validation.py:216: in wrapper
    return func(*args, **kwargs)
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/_data.py:62: in scale
    return scale(X)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = <100x1 sparse array of type '<class 'numpy.float64'>'
	with 100 stored elements in Compressed Sparse Row format>
axis = 0, with_mean = True, with_std = True, copy = True

    def scale(X, axis=0, with_mean=True, with_std=True, copy=True):
        """
        Standardize a dataset along any axis.
    
        Parameters
        ----------
        X : {array-like, sparse matrix} of shape (n_samples, n_features)
            The data to center and scale.
    
        axis : {0, 1}, default=0
            Axis used to compute the means and standard deviations along. If 0,
            independently standardize each feature, otherwise (if 1) standardize
            each sample.
    
        with_mean : bool, default=True
            If True, center the data before scaling.
    
        with_std : bool, default=True
            If True, scale the data to unit variance (or equivalently,
            unit standard deviation).
    
        copy : bool, default=True
            If False, try to avoid a copy and scale in place.
    
        Returns
        -------
        X_tr : {ndarray, sparse matrix} of shape (n_samples, n_features)
            The transformed data.
        """
        if sparse.issparse(X):
>           raise TypeError('Sparse matrices are not supported by this function.')
E           TypeError: Sparse matrices are not supported by this function.

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/temp.py:49: TypeError
=========================== short test summary info ============================
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0]
FAILED ../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0]
================== 28 failed, 62 passed, 30 skipped in 2.70s ===================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.9.0, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/scikit-learn/scikit-learn
configfile: setup.cfg
plugins: cov-6.0.0
collecting ... collected 120 items

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-None-scaler0] I: Seeding RNGs with 51123837
PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_array-scaler1] SKIPPED

======================== 90 passed, 30 skipped in 0.62s ========================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.9.0, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/scikit-learn/scikit-learn/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/scikit-learn/scikit-learn
configfile: setup.cfg
plugins: cov-6.0.0
collecting ... collected 120 items

../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-None-scaler0] I: Seeding RNGs with 1528078056
PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float32-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[0-float64-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float32-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[1.0-float64-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float32-True-csr_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-None-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csc_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_matrix-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-False-csr_array-scaler1] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-None-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-None-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csc_array-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_matrix-scaler1] SKIPPED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_array-scaler0] PASSED
../publishablew/scikit-learn/scikit-learn/sklearn/preprocessing/tests/test_data.py::test_standard_scaler_constant_features[100.0-float64-True-csr_array-scaler1] SKIPPED

======================== 90 passed, 30 skipped in 0.66s ========================
