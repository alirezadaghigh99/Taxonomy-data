output file:
processed_cleanlab_subtract_confident_thresholds229.json
function:
_subtract_confident_thresholds
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0] FAILED', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1]', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0]', '../publishablew/cleanlab/cleanlab/tests/test_rank.py::test__subtract_confident_thresholds FAILED', 'FAILED ../publishablew/cleanlab/cleanlab/tests/test_rank.py::test__subtract_confident_thresholds', '../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1] FAILED'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/cleanlab/cleanlab
configfile: pyproject.toml
collecting ... collected 36 items

../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_get_normalized_margin_for_each_label PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_get_self_confidence_for_each_label PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_rank_by_parameter_error PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func0] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func1] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func2] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0] FAILED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1] FAILED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func2] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test__subtract_confident_thresholds FAILED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-self_confidence] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-normalized_margin] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-confidence_weighted_entropy] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-self_confidence] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-normalized_margin] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-confidence_weighted_entropy] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-self_confidence] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-normalized_margin] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-confidence_weighted_entropy] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-self_confidence] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-normalized_margin] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-confidence_weighted_entropy] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-self_confidence] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-normalized_margin] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-confidence_weighted_entropy] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-self_confidence] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-normalized_margin] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-confidence_weighted_entropy] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_weight_ensemble_members_by_parameter_error Weighting scheme for ensemble: not_a_real_method
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_custom_weights Weighting scheme for ensemble: custom
Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_empty_custom_weights_error Weighting scheme for ensemble: custom
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_wrong_length_custom_weights_error Weighting scheme for ensemble: custom
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_wrong_weight_ensemble_members_by_for_custom_weights_error PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_pred_probs_list_parameter_error PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_unsupported_method_for_adjust_pred_probs PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_find_top_issues PASSED

=================================== FAILURES ===================================
_ test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0] _

scoring_method_func = ('self_confidence', <function get_self_confidence_for_each_label at 0x7aa16266d800>)
adjust_pred_probs = True

    @pytest.mark.parametrize(
        "scoring_method_func",
        [
            ("self_confidence", rank.get_self_confidence_for_each_label),
            ("normalized_margin", rank.get_normalized_margin_for_each_label),
            ("confidence_weighted_entropy", rank.get_confidence_weighted_entropy_for_each_label),
        ],
    )
    @pytest.mark.parametrize("adjust_pred_probs", [False, True])
    def test_order_label_issues_using_scoring_func_ranking(scoring_method_func, adjust_pred_probs):
        # test all scoring methods with the scoring function
    
        method, scoring_func = scoring_method_func
    
        # check if method supports adjust_pred_probs
        # do not run the test below if the method does not support adjust_pred_probs
        # confidence_weighted_entropy scoring method does not support adjust_pred_probs
        if not (adjust_pred_probs == True and method == "confidence_weighted_entropy"):
            indices = np.arange(len(data["label_errors_mask"]))[
                data["label_errors_mask"]
            ]  # indices of label issues
    
            label_issues_indices = rank.order_label_issues(
                label_issues_mask=data["label_errors_mask"],
                labels=data["labels"],
                pred_probs=data["pred_probs"],
                rank_by=method,
                rank_by_kwargs={"adjust_pred_probs": adjust_pred_probs},
            )
    
            # test scoring function with scoring method passed as arg
            scores = rank.get_label_quality_scores(
                data["labels"],
                data["pred_probs"],
                method=method,
                adjust_pred_probs=adjust_pred_probs,
            )
            scores = scores[data["label_errors_mask"]]
            score_idx = sorted(list(zip(scores, indices)), key=lambda y: y[0])  # sort indices by score
            label_issues_indices2 = [z[1] for z in score_idx]
>           assert all(
                label_issues_indices == label_issues_indices2
            ), f"Test failed with scoring method: {method}"
E           AssertionError: Test failed with scoring method: self_confidence
E           assert False
E            +  where False = all(array([  2, 1...66, 159,  55]) == [2, 10, 20, 27, 31, 32, ...]
E               
E               Full diff:
E               + array([  2, 150, 141, 134, 132, 131, 123, 115, 105,  83,  79,  78,  77,
E               +         76,  70, 151,  67,  64,  59,  58,  46,  45,  40,  39,  33,  32,
E               +         31,  27,  20,  10,  66, 159,  55])
E               - [
E               -     2,...
E               
E               ...Full output truncated (33 lines hidden), use '-vv' to show)

../publishablew/cleanlab/cleanlab/tests/test_rank.py:178: AssertionError
_ test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1] _

scoring_method_func = ('normalized_margin', <function get_normalized_margin_for_each_label at 0x7aa16266d8a0>)
adjust_pred_probs = True

    @pytest.mark.parametrize(
        "scoring_method_func",
        [
            ("self_confidence", rank.get_self_confidence_for_each_label),
            ("normalized_margin", rank.get_normalized_margin_for_each_label),
            ("confidence_weighted_entropy", rank.get_confidence_weighted_entropy_for_each_label),
        ],
    )
    @pytest.mark.parametrize("adjust_pred_probs", [False, True])
    def test_order_label_issues_using_scoring_func_ranking(scoring_method_func, adjust_pred_probs):
        # test all scoring methods with the scoring function
    
        method, scoring_func = scoring_method_func
    
        # check if method supports adjust_pred_probs
        # do not run the test below if the method does not support adjust_pred_probs
        # confidence_weighted_entropy scoring method does not support adjust_pred_probs
        if not (adjust_pred_probs == True and method == "confidence_weighted_entropy"):
            indices = np.arange(len(data["label_errors_mask"]))[
                data["label_errors_mask"]
            ]  # indices of label issues
    
            label_issues_indices = rank.order_label_issues(
                label_issues_mask=data["label_errors_mask"],
                labels=data["labels"],
                pred_probs=data["pred_probs"],
                rank_by=method,
                rank_by_kwargs={"adjust_pred_probs": adjust_pred_probs},
            )
    
            # test scoring function with scoring method passed as arg
            scores = rank.get_label_quality_scores(
                data["labels"],
                data["pred_probs"],
                method=method,
                adjust_pred_probs=adjust_pred_probs,
            )
            scores = scores[data["label_errors_mask"]]
            score_idx = sorted(list(zip(scores, indices)), key=lambda y: y[0])  # sort indices by score
            label_issues_indices2 = [z[1] for z in score_idx]
>           assert all(
                label_issues_indices == label_issues_indices2
            ), f"Test failed with scoring method: {method}"
E           AssertionError: Test failed with scoring method: normalized_margin
E           assert False
E            +  where False = all(array([  2, 1...76,  33,  55]) == [2, 20, 27, 31, 32, 39, ...]
E               
E               Full diff:
E               + array([  2, 150, 141, 134, 132, 131, 123, 115, 105,  83,  79,  78,  77,
E               +         70, 151,  67,  64,  20,  27,  31,  32,  66,  40,  39,  46,  58,
E               +         59, 159,  45,  10,  76,  33,  55])
E               - [
E               -     2,...
E               
E               ...Full output truncated (33 lines hidden), use '-vv' to show)

../publishablew/cleanlab/cleanlab/tests/test_rank.py:178: AssertionError
_____________________ test__subtract_confident_thresholds ______________________

    def test__subtract_confident_thresholds():
        labels = data["labels"]
        pred_probs = data["pred_probs"]
    
        # subtract confident class thresholds and renormalize
        pred_probs_adj = _subtract_confident_thresholds(labels, pred_probs)
    
>       assert (pred_probs_adj > 0).all()  # all pred_prob are positive numbers
E       assert False
E        +  where False = <built-in method all of numpy.ndarray object at 0x7aa0a7cd1350>()
E        +    where <built-in method all of numpy.ndarray object at 0x7aa0a7cd1350> = array([[0.5903487 , 0.        , 0.4096513 ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [0.91219817, 0.        , 0.08780183],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [0.22304638, 0.77695362, 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [0.86141985, 0.13858015, 0.        ],\n       [0.60643822, 0.        , 0.39356178],\n       [1.        , 0.        , 0.        ],\n       [0.59397991, 0.40602009, 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.        , 0.        ],\n       [1.        , 0.      ...  , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.20752045, 0.        , 0.79247955],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.17451738, 0.        , 0.82548262],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.10924585, 0.89075415],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.        , 1.        , 0.        ],\n       [0.        , 0.        , 1.        ],\n       [0.54316281, 0.        , 0.45683719],\n       [0.        , 0.        , 1.        ],\n       [0.53299673, 0.        , 0.46700327],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ],\n       [0.        , 0.        , 1.        ]]) > 0.all

../publishablew/cleanlab/cleanlab/tests/test_rank.py:203: AssertionError
=========================== short test summary info ============================
FAILED ../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1]
FAILED ../publishablew/cleanlab/cleanlab/tests/test_rank.py::test__subtract_confident_thresholds
========================= 3 failed, 33 passed in 1.56s =========================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/cleanlab/cleanlab
configfile: pyproject.toml
collecting ... collected 36 items

../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_get_normalized_margin_for_each_label PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_get_self_confidence_for_each_label PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_rank_by_parameter_error PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func0] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func1] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func2] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func2] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test__subtract_confident_thresholds PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-self_confidence] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-normalized_margin] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-confidence_weighted_entropy] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-self_confidence] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-normalized_margin] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-confidence_weighted_entropy] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-self_confidence] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-normalized_margin] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-confidence_weighted_entropy] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-self_confidence] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-normalized_margin] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-confidence_weighted_entropy] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-self_confidence] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-normalized_margin] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-confidence_weighted_entropy] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-self_confidence] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-normalized_margin] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-confidence_weighted_entropy] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_weight_ensemble_members_by_parameter_error Weighting scheme for ensemble: not_a_real_method
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_custom_weights Weighting scheme for ensemble: custom
Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_empty_custom_weights_error Weighting scheme for ensemble: custom
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_wrong_length_custom_weights_error Weighting scheme for ensemble: custom
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_wrong_weight_ensemble_members_by_for_custom_weights_error PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_pred_probs_list_parameter_error PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_unsupported_method_for_adjust_pred_probs PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_find_top_issues PASSED

============================== 36 passed in 1.56s ==============================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/cleanlab/cleanlab/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/cleanlab/cleanlab
configfile: pyproject.toml
collecting ... collected 36 items

../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_get_normalized_margin_for_each_label PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_get_self_confidence_for_each_label PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_rank_by_parameter_error PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func0] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func1] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[False-scoring_method_func2] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func0] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func1] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_order_label_issues_using_scoring_func_ranking[True-scoring_method_func2] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test__subtract_confident_thresholds PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-self_confidence] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-normalized_margin] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-False-confidence_weighted_entropy] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-self_confidence] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-normalized_margin] Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[uniform-True-confidence_weighted_entropy] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-self_confidence] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-normalized_margin] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-False-confidence_weighted_entropy] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-self_confidence] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-normalized_margin] Weighting scheme for ensemble: accuracy
Ensemble members will be weighted by their relative accuracy
  Model 0 accuracy : 0.74375
  Model 0 weight   : 0.3333333333333333
  Model 1 accuracy : 0.74375
  Model 1 weight   : 0.3333333333333333
  Model 2 accuracy : 0.74375
  Model 2 weight   : 0.3333333333333333
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[accuracy-True-confidence_weighted_entropy] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-self_confidence] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-normalized_margin] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-False-confidence_weighted_entropy] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-self_confidence] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-normalized_margin] Weighting scheme for ensemble: log_loss_search
Ensemble members will be weighted by log-loss between their predicted probabilities and given labels
  Model 0 weight   : 0.33333333333333337
  Model 1 weight   : 0.33333333333333337
  Model 2 weight   : 0.33333333333333337
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_ensemble_scoring_func[log_loss_search-True-confidence_weighted_entropy] PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_weight_ensemble_members_by_parameter_error Weighting scheme for ensemble: not_a_real_method
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_custom_weights Weighting scheme for ensemble: custom
Weighting scheme for ensemble: uniform
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_empty_custom_weights_error Weighting scheme for ensemble: custom
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_wrong_length_custom_weights_error Weighting scheme for ensemble: custom
PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_wrong_weight_ensemble_members_by_for_custom_weights_error PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_bad_pred_probs_list_parameter_error PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_unsupported_method_for_adjust_pred_probs PASSED
../publishablew/cleanlab/cleanlab/tests/test_rank.py::test_find_top_issues PASSED

============================== 36 passed in 1.72s ==============================
