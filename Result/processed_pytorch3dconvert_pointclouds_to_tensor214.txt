output file:
processed_pytorch3dconvert_pointclouds_to_tensor214.json
function:
convert_pointclouds_to_tensor
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh FAILED', 'FAILED ../pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh', 'FAILED ../pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation', '../pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation FAILED'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 3 items

../pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh FAILED
../pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs FAILED
../pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation FAILED

=================================== FAILURES ===================================
______________________ TestICP.test_compare_with_trimesh _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_compare_with_trimesh>

    def test_compare_with_trimesh(self):
        """
        Compares the outputs of `iterative_closest_point` with the results
        of `trimesh.registration.icp` from the `trimesh` python package:
        https://github.com/mikedh/trimesh
    
        We have run `trimesh.registration.icp` on several random problems
        with different point cloud sizes. The results of trimesh, together with
        the randomly generated input clouds are loaded in the constructor of
        this class and this test compares the loaded results to our runs.
        """
        for n_points_X in (10, 20, 50, 100):
            for n_points_Y in (10, 20, 50, 100):
>               self._compare_with_trimesh(n_points_X=n_points_X, n_points_Y=n_points_Y)

../pytorch3d/tests/test_points_alignment.py:257: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../pytorch3d/tests/test_points_alignment.py:283: in _compare_with_trimesh
    ) = points_alignment.iterative_closest_point(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = tensor([[[-7.6644e-02,  3.5988e-01, -7.8202e-01],
         [ 7.1528e-02,  6.6484e-01, -2.8678e-01],
         [ 1.6206e...
         [-7.8433e-02, -2.6398e-02, -5.0173e-02],
         [ 5.4569e-01,  1.0037e+00, -6.6791e-01]]], device='cuda:0')
Y = tensor([[[-0.7658, -1.5857, -0.1757],
         [ 1.0614, -0.0049,  1.1813],
         [ 0.7498,  1.4699,  1.4263],
    ...4348,  0.9885,  0.3908],
         [ 1.1048, -0.2426, -0.1243],
         [-0.6120, -1.2204,  1.6596]]], device='cuda:0')
init_transform = None, max_iterations = 100, relative_rmse_thr = 1e-06
estimate_scale = False, allow_reflection = False, verbose = False

    def iterative_closest_point(
        X: Union[torch.Tensor, "Pointclouds"],
        Y: Union[torch.Tensor, "Pointclouds"],
        init_transform: Optional[SimilarityTransform] = None,
        max_iterations: int = 100,
        relative_rmse_thr: float = 1e-6,
        estimate_scale: bool = False,
        allow_reflection: bool = False,
        verbose: bool = False,
    ) -> ICPSolution:
        """
        Executes the iterative closest point (ICP) algorithm [1, 2] in order to find
        a similarity transformation (rotation `R`, translation `T`, and
        optionally scale `s`) between two given differently-sized sets of
        `d`-dimensional points `X` and `Y`, such that:
    
        `s[i] X[i] R[i] + T[i] = Y[NN[i]]`,
    
        for all batch indices `i` in the least squares sense. Here, Y[NN[i]] stands
        for the indices of nearest neighbors from `Y` to each point in `X`.
        Note, however, that the solution is only a local optimum.
    
        Args:
            **X**: Batch of `d`-dimensional points
                of shape `(minibatch, num_points_X, d)` or a `Pointclouds` object.
            **Y**: Batch of `d`-dimensional points
                of shape `(minibatch, num_points_Y, d)` or a `Pointclouds` object.
            **init_transform**: A named-tuple `SimilarityTransform` of tensors
                `R`, `T, `s`, where `R` is a batch of orthonormal matrices of
                shape `(minibatch, d, d)`, `T` is a batch of translations
                of shape `(minibatch, d)` and `s` is a batch of scaling factors
                of shape `(minibatch,)`.
            **max_iterations**: The maximum number of ICP iterations.
            **relative_rmse_thr**: A threshold on the relative root mean squared error
                used to terminate the algorithm.
            **estimate_scale**: If `True`, also estimates a scaling component `s`
                of the transformation. Otherwise assumes the identity
                scale and returns a tensor of ones.
            **allow_reflection**: If `True`, allows the algorithm to return `R`
                which is orthonormal but has determinant==-1.
            **verbose**: If `True`, prints status messages during each ICP iteration.
    
        Returns:
            A named tuple `ICPSolution` with the following fields:
            **converged**: A boolean flag denoting whether the algorithm converged
                successfully (=`True`) or not (=`False`).
            **rmse**: Attained root mean squared error after termination of ICP.
            **Xt**: The point cloud `X` transformed with the final transformation
                (`R`, `T`, `s`). If `X` is a `Pointclouds` object, returns an
                instance of `Pointclouds`, otherwise returns `torch.Tensor`.
            **RTs**: A named tuple `SimilarityTransform` containing
            a batch of similarity transforms with fields:
                **R**: Batch of orthonormal matrices of shape `(minibatch, d, d)`.
                **T**: Batch of translations of shape `(minibatch, d)`.
                **s**: batch of scaling factors of shape `(minibatch, )`.
            **t_history**: A list of named tuples `SimilarityTransform`
                the transformation parameters after each ICP iteration.
    
        References:
            [1] Besl & McKay: A Method for Registration of 3-D Shapes. TPAMI, 1992.
            [2] https://en.wikipedia.org/wiki/Iterative_closest_point
        """
    
        # make sure we convert input Pointclouds structures to
        # padded tensors of shape (N, P, 3)
        Xt, num_points_X = oputil.convert_pointclouds_to_tensor(X)
        Yt, num_points_Y = oputil.convert_pointclouds_to_tensor(Y)
    
        b, size_X, dim = Xt.shape
    
        if (Xt.shape[2] != Yt.shape[2]) or (Xt.shape[0] != Yt.shape[0]):
            raise ValueError(
                "Point sets X and Y have to have the same "
                + "number of batches and data dimensions."
            )
    
>       if ((num_points_Y < Yt.shape[1]).any() or (num_points_X < Xt.shape[1]).any()) and (
            num_points_Y != num_points_X
        ).any():
E       AttributeError: 'bool' object has no attribute 'any'

../pytorch3d/pytorch3d/ops/points_alignment.py:114: AttributeError
______________________ TestICP.test_heterogeneous_inputs _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_heterogeneous_inputs>
batch_size = 7

    def test_heterogeneous_inputs(self, batch_size=7):
        """
        Tests whether we get the same result when running ICP on
        a set of randomly-sized Pointclouds and on their padded versions.
        """
    
        torch.manual_seed(4)
        device = torch.device("cuda:0")
    
        for estimate_scale in (True, False):
            for max_n_points in (10, 30, 100):
                # initialize ground truth point clouds
                X_pcl, Y_pcl = [
                    TestCorrespondingPointsAlignment.init_point_cloud(
                        batch_size=batch_size,
                        n_points=max_n_points,
                        dim=3,
                        device=device,
                        use_pointclouds=True,
                        random_pcl_size=True,
                    )
                    for _ in range(2)
                ]
    
                # get the padded versions and their num of points
                X_padded = X_pcl.points_padded()
                Y_padded = Y_pcl.points_padded()
                n_points_X = X_pcl.num_points_per_cloud()
                n_points_Y = Y_pcl.num_points_per_cloud()
    
                # run icp with Pointlouds inputs
                (
                    _,
                    _,
                    Xt_pcl,
                    (R_pcl, T_pcl, s_pcl),
                    _,
>               ) = points_alignment.iterative_closest_point(
                    X_pcl,
                    Y_pcl,
                    estimate_scale=estimate_scale,
                    allow_reflection=False,
                    verbose=False,
                    max_iterations=100,
                )

../pytorch3d/tests/test_points_alignment.py:200: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../pytorch3d/pytorch3d/ops/points_alignment.py:103: in iterative_closest_point
    Xt, num_points_X = oputil.convert_pointclouds_to_tensor(X)
../pytorch3d/pytorch3d/ops/utils.py:84: in convert_pointclouds_to_tensor
    return convert_pointclouds_to_tensor(pcl)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pcl = <pytorch3d.structures.pointclouds.Pointclouds object at 0x750c81e76370>

    def convert_pointclouds_to_tensor(pcl):
        if isinstance(pcl, torch.Tensor):
            num_points = pcl.size(1)
            return (pcl, num_points)
        elif isinstance(pcl, Pointclouds):
            padded_tensor = pcl.to_padded_tensor()
            num_points = pcl.num_points_per_cloud()
            return (padded_tensor, num_points)
        else:
>           raise ValueError('Input must be a torch.Tensor or a Pointclouds object.')
E           ValueError: Input must be a torch.Tensor or a Pointclouds object.

../pytorch3d/pytorch3d/ops/temp.py:27: ValueError
_______________________ TestICP.test_init_transformation _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_init_transformation>
batch_size = 10

    def test_init_transformation(self, batch_size=10):
        """
        First runs a full ICP on a random problem. Then takes a given point
        in the history of ICP iteration transformations, initializes
        a second run of ICP with this transformation and checks whether
        both runs ended with the same solution.
        """
    
        device = torch.device("cuda:0")
    
        for dim in (2, 3, 11):
            for n_points_X in (30, 100):
                for n_points_Y in (30, 100):
                    # initialize ground truth point clouds
                    X, Y = [
                        TestCorrespondingPointsAlignment.init_point_cloud(
                            batch_size=batch_size,
                            n_points=n_points,
                            dim=dim,
                            device=device,
                            use_pointclouds=False,
                            random_pcl_size=True,
                        )
                        for n_points in (n_points_X, n_points_Y)
                    ]
    
                    # run full icp
                    (
                        converged,
                        _,
                        Xt,
                        (R, T, s),
                        t_hist,
>                   ) = points_alignment.iterative_closest_point(
                        X,
                        Y,
                        estimate_scale=False,
                        allow_reflection=False,
                        verbose=False,
                        max_iterations=100,
                    )

../pytorch3d/tests/test_points_alignment.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

X = tensor([[[ 1.9402e-01,  2.1614e+00],
         [-1.7205e-01,  8.4906e-01],
         [-1.9244e+00,  6.5299e-01],
       ...-3.6217e-01, -5.8366e-01],
         [-1.7007e+00,  3.6993e-01],
         [ 7.4330e-01, -1.1991e-01]]], device='cuda:0')
Y = tensor([[[ 1.3914e-01, -1.0822e-01],
         [-7.1742e-01,  7.5665e-01],
         [ 3.7149e-01, -1.0049e+00],
       ...-1.3905e+00, -1.1239e+00],
         [-1.7510e-02,  4.8009e-01],
         [-1.6156e-01, -1.1643e+00]]], device='cuda:0')
init_transform = None, max_iterations = 100, relative_rmse_thr = 1e-06
estimate_scale = False, allow_reflection = False, verbose = False

    def iterative_closest_point(
        X: Union[torch.Tensor, "Pointclouds"],
        Y: Union[torch.Tensor, "Pointclouds"],
        init_transform: Optional[SimilarityTransform] = None,
        max_iterations: int = 100,
        relative_rmse_thr: float = 1e-6,
        estimate_scale: bool = False,
        allow_reflection: bool = False,
        verbose: bool = False,
    ) -> ICPSolution:
        """
        Executes the iterative closest point (ICP) algorithm [1, 2] in order to find
        a similarity transformation (rotation `R`, translation `T`, and
        optionally scale `s`) between two given differently-sized sets of
        `d`-dimensional points `X` and `Y`, such that:
    
        `s[i] X[i] R[i] + T[i] = Y[NN[i]]`,
    
        for all batch indices `i` in the least squares sense. Here, Y[NN[i]] stands
        for the indices of nearest neighbors from `Y` to each point in `X`.
        Note, however, that the solution is only a local optimum.
    
        Args:
            **X**: Batch of `d`-dimensional points
                of shape `(minibatch, num_points_X, d)` or a `Pointclouds` object.
            **Y**: Batch of `d`-dimensional points
                of shape `(minibatch, num_points_Y, d)` or a `Pointclouds` object.
            **init_transform**: A named-tuple `SimilarityTransform` of tensors
                `R`, `T, `s`, where `R` is a batch of orthonormal matrices of
                shape `(minibatch, d, d)`, `T` is a batch of translations
                of shape `(minibatch, d)` and `s` is a batch of scaling factors
                of shape `(minibatch,)`.
            **max_iterations**: The maximum number of ICP iterations.
            **relative_rmse_thr**: A threshold on the relative root mean squared error
                used to terminate the algorithm.
            **estimate_scale**: If `True`, also estimates a scaling component `s`
                of the transformation. Otherwise assumes the identity
                scale and returns a tensor of ones.
            **allow_reflection**: If `True`, allows the algorithm to return `R`
                which is orthonormal but has determinant==-1.
            **verbose**: If `True`, prints status messages during each ICP iteration.
    
        Returns:
            A named tuple `ICPSolution` with the following fields:
            **converged**: A boolean flag denoting whether the algorithm converged
                successfully (=`True`) or not (=`False`).
            **rmse**: Attained root mean squared error after termination of ICP.
            **Xt**: The point cloud `X` transformed with the final transformation
                (`R`, `T`, `s`). If `X` is a `Pointclouds` object, returns an
                instance of `Pointclouds`, otherwise returns `torch.Tensor`.
            **RTs**: A named tuple `SimilarityTransform` containing
            a batch of similarity transforms with fields:
                **R**: Batch of orthonormal matrices of shape `(minibatch, d, d)`.
                **T**: Batch of translations of shape `(minibatch, d)`.
                **s**: batch of scaling factors of shape `(minibatch, )`.
            **t_history**: A list of named tuples `SimilarityTransform`
                the transformation parameters after each ICP iteration.
    
        References:
            [1] Besl & McKay: A Method for Registration of 3-D Shapes. TPAMI, 1992.
            [2] https://en.wikipedia.org/wiki/Iterative_closest_point
        """
    
        # make sure we convert input Pointclouds structures to
        # padded tensors of shape (N, P, 3)
        Xt, num_points_X = oputil.convert_pointclouds_to_tensor(X)
        Yt, num_points_Y = oputil.convert_pointclouds_to_tensor(Y)
    
        b, size_X, dim = Xt.shape
    
        if (Xt.shape[2] != Yt.shape[2]) or (Xt.shape[0] != Yt.shape[0]):
            raise ValueError(
                "Point sets X and Y have to have the same "
                + "number of batches and data dimensions."
            )
    
>       if ((num_points_Y < Yt.shape[1]).any() or (num_points_X < Xt.shape[1]).any()) and (
            num_points_Y != num_points_X
        ).any():
E       AttributeError: 'bool' object has no attribute 'any'

../pytorch3d/pytorch3d/ops/points_alignment.py:114: AttributeError
=============================== warnings summary ===============================
tests/test_points_alignment.py::TestICP::test_compare_with_trimesh
tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
tests/test_points_alignment.py::TestICP::test_init_transformation
  /local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
    self.trimesh_results = torch.load(trimesh_results_path)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh
FAILED ../pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
FAILED ../pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation
======================== 3 failed, 3 warnings in 1.30s =========================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 3 items

../pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh PASSED
../pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs FAILED
../pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation PASSED

=================================== FAILURES ===================================
______________________ TestICP.test_heterogeneous_inputs _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_heterogeneous_inputs>
batch_size = 7

    def test_heterogeneous_inputs(self, batch_size=7):
        """
        Tests whether we get the same result when running ICP on
        a set of randomly-sized Pointclouds and on their padded versions.
        """
    
        torch.manual_seed(4)
        device = torch.device("cuda:0")
    
        for estimate_scale in (True, False):
            for max_n_points in (10, 30, 100):
                # initialize ground truth point clouds
                X_pcl, Y_pcl = [
                    TestCorrespondingPointsAlignment.init_point_cloud(
                        batch_size=batch_size,
                        n_points=max_n_points,
                        dim=3,
                        device=device,
                        use_pointclouds=True,
                        random_pcl_size=True,
                    )
                    for _ in range(2)
                ]
    
                # get the padded versions and their num of points
                X_padded = X_pcl.points_padded()
                Y_padded = Y_pcl.points_padded()
                n_points_X = X_pcl.num_points_per_cloud()
                n_points_Y = Y_pcl.num_points_per_cloud()
    
                # run icp with Pointlouds inputs
                (
                    _,
                    _,
                    Xt_pcl,
                    (R_pcl, T_pcl, s_pcl),
                    _,
                ) = points_alignment.iterative_closest_point(
                    X_pcl,
                    Y_pcl,
                    estimate_scale=estimate_scale,
                    allow_reflection=False,
                    verbose=False,
                    max_iterations=100,
                )
                Xt_pcl = Xt_pcl.points_padded()
    
                # run icp with tensor inputs on each element
                # of the batch separately
                icp_results = [
                    points_alignment.iterative_closest_point(
                        X_[None, :n_X, :],
                        Y_[None, :n_Y, :],
                        estimate_scale=estimate_scale,
                        allow_reflection=False,
                        verbose=False,
                        max_iterations=100,
                    )
                    for X_, Y_, n_X, n_Y in zip(
                        X_padded, Y_padded, n_points_X, n_points_Y
                    )
                ]
    
                # parse out the transformation results
                R, T, s = [
                    torch.cat([x.RTs[i] for x in icp_results], dim=0) for i in range(3)
                ]
    
                # check that both sets of transforms are the same
                atol = 1e-5
>               self.assertClose(R_pcl, R, atol=atol)

../pytorch3d/tests/test_points_alignment.py:233: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../pytorch3d/tests/common_testing.py:209: in assertClose
    self.fail(err)
E   AssertionError: Not close. Max diff 1.4095808267593384. Max relative diff 9.08298397064209 Shape (7, 3, 3). At (4, 0, 0).
=============================== warnings summary ===============================
tests/test_points_alignment.py::TestICP::test_compare_with_trimesh
tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
tests/test_points_alignment.py::TestICP::test_init_transformation
  /local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
    self.trimesh_results = torch.load(trimesh_results_path)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
=================== 1 failed, 2 passed, 3 warnings in 1.93s ====================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.8.5, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/pytorch3d/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/pytorch3d
collecting ... collected 3 items

../pytorch3d/tests/test_points_alignment.py::TestICP::test_compare_with_trimesh PASSED
../pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs FAILED
../pytorch3d/tests/test_points_alignment.py::TestICP::test_init_transformation PASSED

=================================== FAILURES ===================================
______________________ TestICP.test_heterogeneous_inputs _______________________

self = <tests.test_points_alignment.TestICP testMethod=test_heterogeneous_inputs>
batch_size = 7

    def test_heterogeneous_inputs(self, batch_size=7):
        """
        Tests whether we get the same result when running ICP on
        a set of randomly-sized Pointclouds and on their padded versions.
        """
    
        torch.manual_seed(4)
        device = torch.device("cuda:0")
    
        for estimate_scale in (True, False):
            for max_n_points in (10, 30, 100):
                # initialize ground truth point clouds
                X_pcl, Y_pcl = [
                    TestCorrespondingPointsAlignment.init_point_cloud(
                        batch_size=batch_size,
                        n_points=max_n_points,
                        dim=3,
                        device=device,
                        use_pointclouds=True,
                        random_pcl_size=True,
                    )
                    for _ in range(2)
                ]
    
                # get the padded versions and their num of points
                X_padded = X_pcl.points_padded()
                Y_padded = Y_pcl.points_padded()
                n_points_X = X_pcl.num_points_per_cloud()
                n_points_Y = Y_pcl.num_points_per_cloud()
    
                # run icp with Pointlouds inputs
                (
                    _,
                    _,
                    Xt_pcl,
                    (R_pcl, T_pcl, s_pcl),
                    _,
                ) = points_alignment.iterative_closest_point(
                    X_pcl,
                    Y_pcl,
                    estimate_scale=estimate_scale,
                    allow_reflection=False,
                    verbose=False,
                    max_iterations=100,
                )
                Xt_pcl = Xt_pcl.points_padded()
    
                # run icp with tensor inputs on each element
                # of the batch separately
                icp_results = [
                    points_alignment.iterative_closest_point(
                        X_[None, :n_X, :],
                        Y_[None, :n_Y, :],
                        estimate_scale=estimate_scale,
                        allow_reflection=False,
                        verbose=False,
                        max_iterations=100,
                    )
                    for X_, Y_, n_X, n_Y in zip(
                        X_padded, Y_padded, n_points_X, n_points_Y
                    )
                ]
    
                # parse out the transformation results
                R, T, s = [
                    torch.cat([x.RTs[i] for x in icp_results], dim=0) for i in range(3)
                ]
    
                # check that both sets of transforms are the same
                atol = 1e-5
>               self.assertClose(R_pcl, R, atol=atol)

../pytorch3d/tests/test_points_alignment.py:233: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../pytorch3d/tests/common_testing.py:209: in assertClose
    self.fail(err)
E   AssertionError: Not close. Max diff 1.4095808267593384. Max relative diff 9.08298397064209 Shape (7, 3, 3). At (4, 0, 0).
=============================== warnings summary ===============================
tests/test_points_alignment.py::TestICP::test_compare_with_trimesh
tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
tests/test_points_alignment.py::TestICP::test_init_transformation
  /local/data0/moved_data/pytorch3d/tests/test_points_alignment.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
    self.trimesh_results = torch.load(trimesh_results_path)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../pytorch3d/tests/test_points_alignment.py::TestICP::test_heterogeneous_inputs
=================== 1 failed, 2 passed, 3 warnings in 1.92s ====================
