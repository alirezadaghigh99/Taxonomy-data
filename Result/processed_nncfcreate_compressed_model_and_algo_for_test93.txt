output file:
processed_nncfcreate_compressed_model_and_algo_for_test93.json
function:
create_compressed_model_and_algo_for_test
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4] FAILED', '../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1] FAILED', '../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0] FAILED', '../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2] FAILED', '../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3] FAILED'}

All Test Cases On Generated code:
INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx
============================= test session starts ==============================
platform linux -- Python 3.9.0, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/nncf/nncf/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/nncf/nncf/tests/torch
configfile: pytest.ini
plugins: mock-3.14.0, dependency-0.6.0
collecting ... collected 5 items

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0] FAILED
../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1] FAILED
../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2] FAILED
../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3] FAILED
../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4] FAILED

=================================== FAILURES ===================================
_______________________ test_quantization_preset[data0] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:315: in create_compressed_model_and_algo_for_test
    from .temp import create_compressed_model_and_algo_for_test
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import contextlib
    import numbers
    from abc import ABC
    from abc import abstractmethod
    from collections import defaultdict
    from copy import deepcopy
    from pathlib import Path
    from typing import Any, Callable, Dict, List, Tuple, TypeVar, Union
    import numpy as np
    import onnx
    import torch
    from onnx import numpy_helper
    from torch import nn
    from torch.nn import Module
    from torch.nn import functional as F
    from torch.utils.data import DataLoader
    from torch.utils.data import Dataset
    import nncf
    from nncf.common.graph.transformations.commands import TargetType
    from nncf.config import NNCFConfig
    from nncf.config.extractors import extract_algorithm_names
    from nncf.config.structures import BNAdaptationInitArgs
    from nncf.torch.algo_selector import PT_COMPRESSION_ALGORITHMS
    from nncf.torch.compression_method_api import PTCompressionAlgorithmController
    from nncf.torch.dynamic_graph.context import PreHookId
    from nncf.torch.dynamic_graph.io_handling import FillerInputInfo
    from nncf.torch.dynamic_graph.operation_address import OperationAddress
    from nncf.torch.dynamic_graph.scope import Scope
    from nncf.torch.graph.transformations.commands import PTInsertionCommand
    from nncf.torch.graph.transformations.commands import PTSharedFnInsertionCommand
    from nncf.torch.initialization import PTInitializingDataLoader
    from nncf.torch.initialization import register_default_init_args
    from nncf.torch.layer_utils import StatefullModuleInterface
    from nncf.torch.layers import NNCF_MODULES_MAP
    from nncf.torch.model_creation import create_compressed_model
    from nncf.torch.module_operations import UpdateWeight
    from nncf.torch.nncf_module_replacement import get_original_module_scope_from_nncf_module_scope
    from nncf.torch.nncf_network import NNCFNetwork
    from nncf.torch.utils import get_all_modules_by_type
    from tests.cross_fw.shared.command import Command as BaseCommand
    from tests.cross_fw.shared.comparator import BaseTensorListComparator
    from nncf import NNCFConfig
>   from nncf import create_compressed_model
E   ImportError: cannot import name 'create_compressed_model' from 'nncf' (/local/data0/moved_data/publishablew/nncf/nncf/nncf/__init__.py)

../publishablew/nncf/nncf/tests/torch/temp.py:43: ImportError
_______________________ test_quantization_preset[data1] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.AsymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'mixed', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:315: in create_compressed_model_and_algo_for_test
    from .temp import create_compressed_model_and_algo_for_test
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import contextlib
    import numbers
    from abc import ABC
    from abc import abstractmethod
    from collections import defaultdict
    from copy import deepcopy
    from pathlib import Path
    from typing import Any, Callable, Dict, List, Tuple, TypeVar, Union
    import numpy as np
    import onnx
    import torch
    from onnx import numpy_helper
    from torch import nn
    from torch.nn import Module
    from torch.nn import functional as F
    from torch.utils.data import DataLoader
    from torch.utils.data import Dataset
    import nncf
    from nncf.common.graph.transformations.commands import TargetType
    from nncf.config import NNCFConfig
    from nncf.config.extractors import extract_algorithm_names
    from nncf.config.structures import BNAdaptationInitArgs
    from nncf.torch.algo_selector import PT_COMPRESSION_ALGORITHMS
    from nncf.torch.compression_method_api import PTCompressionAlgorithmController
    from nncf.torch.dynamic_graph.context import PreHookId
    from nncf.torch.dynamic_graph.io_handling import FillerInputInfo
    from nncf.torch.dynamic_graph.operation_address import OperationAddress
    from nncf.torch.dynamic_graph.scope import Scope
    from nncf.torch.graph.transformations.commands import PTInsertionCommand
    from nncf.torch.graph.transformations.commands import PTSharedFnInsertionCommand
    from nncf.torch.initialization import PTInitializingDataLoader
    from nncf.torch.initialization import register_default_init_args
    from nncf.torch.layer_utils import StatefullModuleInterface
    from nncf.torch.layers import NNCF_MODULES_MAP
    from nncf.torch.model_creation import create_compressed_model
    from nncf.torch.module_operations import UpdateWeight
    from nncf.torch.nncf_module_replacement import get_original_module_scope_from_nncf_module_scope
    from nncf.torch.nncf_network import NNCFNetwork
    from nncf.torch.utils import get_all_modules_by_type
    from tests.cross_fw.shared.command import Command as BaseCommand
    from tests.cross_fw.shared.comparator import BaseTensorListComparator
    from nncf import NNCFConfig
>   from nncf import create_compressed_model
E   ImportError: cannot import name 'create_compressed_model' from 'nncf' (/local/data0/moved_data/publishablew/nncf/nncf/nncf/__init__.py)

../publishablew/nncf/nncf/tests/torch/temp.py:43: ImportError
_______________________ test_quantization_preset[data2] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:315: in create_compressed_model_and_algo_for_test
    from .temp import create_compressed_model_and_algo_for_test
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import contextlib
    import numbers
    from abc import ABC
    from abc import abstractmethod
    from collections import defaultdict
    from copy import deepcopy
    from pathlib import Path
    from typing import Any, Callable, Dict, List, Tuple, TypeVar, Union
    import numpy as np
    import onnx
    import torch
    from onnx import numpy_helper
    from torch import nn
    from torch.nn import Module
    from torch.nn import functional as F
    from torch.utils.data import DataLoader
    from torch.utils.data import Dataset
    import nncf
    from nncf.common.graph.transformations.commands import TargetType
    from nncf.config import NNCFConfig
    from nncf.config.extractors import extract_algorithm_names
    from nncf.config.structures import BNAdaptationInitArgs
    from nncf.torch.algo_selector import PT_COMPRESSION_ALGORITHMS
    from nncf.torch.compression_method_api import PTCompressionAlgorithmController
    from nncf.torch.dynamic_graph.context import PreHookId
    from nncf.torch.dynamic_graph.io_handling import FillerInputInfo
    from nncf.torch.dynamic_graph.operation_address import OperationAddress
    from nncf.torch.dynamic_graph.scope import Scope
    from nncf.torch.graph.transformations.commands import PTInsertionCommand
    from nncf.torch.graph.transformations.commands import PTSharedFnInsertionCommand
    from nncf.torch.initialization import PTInitializingDataLoader
    from nncf.torch.initialization import register_default_init_args
    from nncf.torch.layer_utils import StatefullModuleInterface
    from nncf.torch.layers import NNCF_MODULES_MAP
    from nncf.torch.model_creation import create_compressed_model
    from nncf.torch.module_operations import UpdateWeight
    from nncf.torch.nncf_module_replacement import get_original_module_scope_from_nncf_module_scope
    from nncf.torch.nncf_network import NNCFNetwork
    from nncf.torch.utils import get_all_modules_by_type
    from tests.cross_fw.shared.command import Command as BaseCommand
    from tests.cross_fw.shared.comparator import BaseTensorListComparator
    from nncf import NNCFConfig
>   from nncf import create_compressed_model
E   ImportError: cannot import name 'create_compressed_model' from 'nncf' (/local/data0/moved_data/publishablew/nncf/nncf/nncf/__init__.py)

../publishablew/nncf/nncf/tests/torch/temp.py:43: ImportError
_______________________ test_quantization_preset[data3] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.AsymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'mixed', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:315: in create_compressed_model_and_algo_for_test
    from .temp import create_compressed_model_and_algo_for_test
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import contextlib
    import numbers
    from abc import ABC
    from abc import abstractmethod
    from collections import defaultdict
    from copy import deepcopy
    from pathlib import Path
    from typing import Any, Callable, Dict, List, Tuple, TypeVar, Union
    import numpy as np
    import onnx
    import torch
    from onnx import numpy_helper
    from torch import nn
    from torch.nn import Module
    from torch.nn import functional as F
    from torch.utils.data import DataLoader
    from torch.utils.data import Dataset
    import nncf
    from nncf.common.graph.transformations.commands import TargetType
    from nncf.config import NNCFConfig
    from nncf.config.extractors import extract_algorithm_names
    from nncf.config.structures import BNAdaptationInitArgs
    from nncf.torch.algo_selector import PT_COMPRESSION_ALGORITHMS
    from nncf.torch.compression_method_api import PTCompressionAlgorithmController
    from nncf.torch.dynamic_graph.context import PreHookId
    from nncf.torch.dynamic_graph.io_handling import FillerInputInfo
    from nncf.torch.dynamic_graph.operation_address import OperationAddress
    from nncf.torch.dynamic_graph.scope import Scope
    from nncf.torch.graph.transformations.commands import PTInsertionCommand
    from nncf.torch.graph.transformations.commands import PTSharedFnInsertionCommand
    from nncf.torch.initialization import PTInitializingDataLoader
    from nncf.torch.initialization import register_default_init_args
    from nncf.torch.layer_utils import StatefullModuleInterface
    from nncf.torch.layers import NNCF_MODULES_MAP
    from nncf.torch.model_creation import create_compressed_model
    from nncf.torch.module_operations import UpdateWeight
    from nncf.torch.nncf_module_replacement import get_original_module_scope_from_nncf_module_scope
    from nncf.torch.nncf_network import NNCFNetwork
    from nncf.torch.utils import get_all_modules_by_type
    from tests.cross_fw.shared.command import Command as BaseCommand
    from tests.cross_fw.shared.comparator import BaseTensorListComparator
    from nncf import NNCFConfig
>   from nncf import create_compressed_model
E   ImportError: cannot import name 'create_compressed_model' from 'nncf' (/local/data0/moved_data/publishablew/nncf/nncf/nncf/__init__.py)

../publishablew/nncf/nncf/tests/torch/temp.py:43: ImportError
_______________________ test_quantization_preset[data4] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class '...ion.layers.AsymmetricQuantizer'>, 'overrided_param': {'weights': {'mode': 'asymmetric'}}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:315: in create_compressed_model_and_algo_for_test
    from .temp import create_compressed_model_and_algo_for_test
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    import contextlib
    import numbers
    from abc import ABC
    from abc import abstractmethod
    from collections import defaultdict
    from copy import deepcopy
    from pathlib import Path
    from typing import Any, Callable, Dict, List, Tuple, TypeVar, Union
    import numpy as np
    import onnx
    import torch
    from onnx import numpy_helper
    from torch import nn
    from torch.nn import Module
    from torch.nn import functional as F
    from torch.utils.data import DataLoader
    from torch.utils.data import Dataset
    import nncf
    from nncf.common.graph.transformations.commands import TargetType
    from nncf.config import NNCFConfig
    from nncf.config.extractors import extract_algorithm_names
    from nncf.config.structures import BNAdaptationInitArgs
    from nncf.torch.algo_selector import PT_COMPRESSION_ALGORITHMS
    from nncf.torch.compression_method_api import PTCompressionAlgorithmController
    from nncf.torch.dynamic_graph.context import PreHookId
    from nncf.torch.dynamic_graph.io_handling import FillerInputInfo
    from nncf.torch.dynamic_graph.operation_address import OperationAddress
    from nncf.torch.dynamic_graph.scope import Scope
    from nncf.torch.graph.transformations.commands import PTInsertionCommand
    from nncf.torch.graph.transformations.commands import PTSharedFnInsertionCommand
    from nncf.torch.initialization import PTInitializingDataLoader
    from nncf.torch.initialization import register_default_init_args
    from nncf.torch.layer_utils import StatefullModuleInterface
    from nncf.torch.layers import NNCF_MODULES_MAP
    from nncf.torch.model_creation import create_compressed_model
    from nncf.torch.module_operations import UpdateWeight
    from nncf.torch.nncf_module_replacement import get_original_module_scope_from_nncf_module_scope
    from nncf.torch.nncf_network import NNCFNetwork
    from nncf.torch.utils import get_all_modules_by_type
    from tests.cross_fw.shared.command import Command as BaseCommand
    from tests.cross_fw.shared.comparator import BaseTensorListComparator
    from nncf import NNCFConfig
>   from nncf import create_compressed_model
E   ImportError: cannot import name 'create_compressed_model' from 'nncf' (/local/data0/moved_data/publishablew/nncf/nncf/nncf/__init__.py)

../publishablew/nncf/nncf/tests/torch/temp.py:43: ImportError
=========================== short test summary info ============================
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0]
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1]
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2]
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3]
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4]
============================== 5 failed in 1.64s ===============================


Final Test Result:
INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx
============================= test session starts ==============================
platform linux -- Python 3.9.0, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/nncf/nncf/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/nncf/nncf/tests/torch
configfile: pytest.ini
plugins: mock-3.14.0, dependency-0.6.0
collecting ... collected 5 items

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
INFO:nncf:Compiling and loading torch extension: quantized_functions_cpu...
INFO:nncf:Finished loading torch extension: quantized_functions_cpu
FAILED
../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
FAILED
../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
FAILED
../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
FAILED
../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
INFO:nncf:Preset quantizer parameters {'mode'} explicitly overridden by config.
FAILED

=================================== FAILURES ===================================
_______________________ test_quantization_preset[data0] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
../publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
../publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
../publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
../publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
../publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
../publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
../publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data1] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.AsymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'mixed', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
../publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
../publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
../publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
../publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
../publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
../publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
../publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data2] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
../publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
../publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
../publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
../publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
../publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
../publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
../publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data3] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.AsymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'mixed', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
../publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
../publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
../publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
../publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
../publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
../publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
../publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data4] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class '...ion.layers.AsymmetricQuantizer'>, 'overrided_param': {'weights': {'mode': 'asymmetric'}}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
../publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
../publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
../publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
../publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
../publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
../publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
../publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
=============================== warnings summary ===============================
quantization/test_algo_quantization.py::test_quantization_preset[data0]
quantization/test_algo_quantization.py::test_quantization_preset[data1]
quantization/test_algo_quantization.py::test_quantization_preset[data2]
quantization/test_algo_quantization.py::test_quantization_preset[data3]
quantization/test_algo_quantization.py::test_quantization_preset[data4]
  /local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:105: FutureWarning: The 'nncf.torch.create_compressed_model' function is deprecated and will be removed in a future release.
  To perform post training quantization (PTQ) or quantization aware training (QAT), use the new nncf.quantize() API:
   - https://github.com/openvinotoolkit/nncf?tab=readme-ov-file#post-training-quantization
   - https://github.com/openvinotoolkit/nncf?tab=readme-ov-file#training-time-quantization
  Examples:
   - https://github.com/openvinotoolkit/nncf/tree/develop/examples/post_training_quantization/torch
   - https://github.com/openvinotoolkit/nncf/tree/develop/examples/quantization_aware_training/torch
    warning_deprecated(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0]
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1]
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2]
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3]
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4]
======================== 5 failed, 5 warnings in 3.22s =========================


Initial Result:
INFO:nncf:NNCF initialized successfully. Supported frameworks detected: torch, tensorflow, onnx
============================= test session starts ==============================
platform linux -- Python 3.9.0, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/nncf/nncf/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/nncf/nncf/tests/torch
configfile: pytest.ini
plugins: mock-3.14.0, dependency-0.6.0
collecting ... collected 5 items

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
INFO:nncf:Compiling and loading torch extension: quantized_functions_cpu...
INFO:nncf:Finished loading torch extension: quantized_functions_cpu
FAILED
../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
FAILED
../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
FAILED
../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
FAILED
../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4] WARNING:nncf:Initializer section not specified for quantization algorithm in NNCF config and quantization init args not supplied - the quantizer range initialization algorithm cannot proceed.
INFO:nncf:Preset quantizer parameters {'mode'} explicitly overridden by config.
FAILED

=================================== FAILURES ===================================
_______________________ test_quantization_preset[data0] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
../publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
../publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
../publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
../publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
../publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
../publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
../publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data1] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.AsymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'mixed', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
../publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
../publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
../publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
../publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
../publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
../publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
../publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data2] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
../publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
../publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
../publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
../publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
../publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
../publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
../publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data3] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.AsymmetricQuantizer'>, 'expected_weights_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'overrided_param': {}, 'preset': 'mixed', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
../publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
../publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
../publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
../publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
../publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
../publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
../publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
_______________________ test_quantization_preset[data4] ________________________

data = {'expected_activations_q': <class 'nncf.torch.quantization.layers.SymmetricQuantizer'>, 'expected_weights_q': <class '...ion.layers.AsymmetricQuantizer'>, 'overrided_param': {'weights': {'mode': 'asymmetric'}}, 'preset': 'performance', ...}

    @pytest.mark.parametrize("data", TEST_QUANTIZATION_PRESET_STRUCT)
    def test_quantization_preset(data):
        model = BasicConvTestModel()
        config = get_empty_config(input_sample_sizes=[1, 1, 4, 4])
        config["target_device"] = data["target_device"]
        config["compression"] = {"algorithm": "quantization", "preset": data["preset"]}
        config["compression"].update(data["overrided_param"])
        register_bn_adaptation_init_args(config)
>       _, compression_ctrl = create_compressed_model_and_algo_for_test(model, config)

../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py:683: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/nncf/nncf/tests/torch/helpers.py:414: in create_compressed_model_and_algo_for_test
    algo, model = create_compressed_model(
../publishablew/nncf/nncf/nncf/telemetry/decorator.py:79: in wrapped
    retval = fn(*args, **kwargs)
../publishablew/nncf/nncf/nncf/torch/model_creation.py:149: in create_compressed_model
    compressed_model = builder.apply_to(nncf_network)
../publishablew/nncf/nncf/nncf/torch/compression_method_api.py:127: in apply_to
    self.initialize(transformed_model)
../publishablew/nncf/nncf/nncf/torch/quantization/algo.py:1258: in initialize
    bn_adaptation.run(model)
../publishablew/nncf/nncf/nncf/common/initialization/batchnorm_adaptation.py:85: in run
    backend = get_backend(model)
../publishablew/nncf/nncf/nncf/common/utils/backend.py:134: in get_backend
    available_backends = get_available_backends()
../publishablew/nncf/nncf/nncf/common/utils/backend.py:46: in get_available_backends
    importlib.import_module(module_name)
/usr/local/lib/python3.9/importlib/__init__.py:127: in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
<frozen importlib._bootstrap>:1030: in _gcd_import
    ???
<frozen importlib._bootstrap>:1007: in _find_and_load
    ???
<frozen importlib._bootstrap>:986: in _find_and_load_unlocked
    ???
<frozen importlib._bootstrap>:680: in _load_unlocked
    ???
<frozen importlib._bootstrap_external>:790: in exec_module
    ???
<frozen importlib._bootstrap>:228: in _call_with_frames_removed
    ???
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/__init__.py:47: in <module>
    from tensorflow._api.v2 import __internal__
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/__init__.py:8: in <module>
    from tensorflow._api.v2.__internal__ import autograph
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/_api/v2/__internal__/autograph/__init__.py:8: in <module>
    from tensorflow.python.autograph.core.ag_ctx import control_status_ctx # line: 34
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/core/ag_ctx.py:21: in <module>
    from tensorflow.python.autograph.utils import ag_logging
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/__init__.py:17: in <module>
    from tensorflow.python.autograph.utils.context_managers import control_dependency_on_returns
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/autograph/utils/context_managers.py:19: in <module>
    from tensorflow.python.framework import ops
../publishablew/nncf/nncf/venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:5906: in <module>
    ) -> Optional[Callable[[Any], message.Message]]:
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:433: in Optional
    return Union[arg, type(None)]
/usr/local/lib/python3.9/typing.py:243: in inner
    return func(*args, **kwds)
/usr/local/lib/python3.9/typing.py:316: in __getitem__
    return self._getitem(self, parameters)
/usr/local/lib/python3.9/typing.py:421: in Union
    parameters = _remove_dups_flatten(parameters)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

parameters = (collections.abc.Callable[[typing.Any], google.protobuf.message.Message], <class 'NoneType'>)

    def _remove_dups_flatten(parameters):
        """An internal helper for Union creation and substitution: flatten Unions
        among parameters, then remove duplicates.
        """
        # Flatten out Union[Union[...], ...].
        params = []
        for p in parameters:
            if isinstance(p, _UnionGenericAlias):
                params.extend(p.__args__)
            elif isinstance(p, tuple) and len(p) > 0 and p[0] is Union:
                params.extend(p[1:])
            else:
                params.append(p)
        # Weed out strict duplicates, preserving the first of each occurrence.
>       all_params = set(params)
E       TypeError: unhashable type: 'list'

/usr/local/lib/python3.9/typing.py:215: TypeError
=============================== warnings summary ===============================
quantization/test_algo_quantization.py::test_quantization_preset[data0]
quantization/test_algo_quantization.py::test_quantization_preset[data1]
quantization/test_algo_quantization.py::test_quantization_preset[data2]
quantization/test_algo_quantization.py::test_quantization_preset[data3]
quantization/test_algo_quantization.py::test_quantization_preset[data4]
  /local/data0/moved_data/publishablew/nncf/nncf/nncf/torch/model_creation.py:105: FutureWarning: The 'nncf.torch.create_compressed_model' function is deprecated and will be removed in a future release.
  To perform post training quantization (PTQ) or quantization aware training (QAT), use the new nncf.quantize() API:
   - https://github.com/openvinotoolkit/nncf?tab=readme-ov-file#post-training-quantization
   - https://github.com/openvinotoolkit/nncf?tab=readme-ov-file#training-time-quantization
  Examples:
   - https://github.com/openvinotoolkit/nncf/tree/develop/examples/post_training_quantization/torch
   - https://github.com/openvinotoolkit/nncf/tree/develop/examples/quantization_aware_training/torch
    warning_deprecated(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data0]
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data1]
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data2]
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data3]
FAILED ../publishablew/nncf/nncf/tests/torch/quantization/test_algo_quantization.py::test_quantization_preset[data4]
======================== 5 failed, 5 warnings in 13.86s ========================
