output file:
processed_visiondraw_segmentation_masks168.json
function:
draw_segmentation_masks
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors4]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-#FF00FF] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors3] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors4]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors5]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-#FF00FF] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors4]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-None]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors5]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-#FF00FF] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-#FF00FF]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-#FF00FF]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors5] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors5] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-#FF00FF]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors5]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors3]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-blue] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors3]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors5] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-None] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors4]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors3]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-#FF00FF] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors5]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-None]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-#FF00FF] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors3] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors4] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors4] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-blue] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-None] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors5] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-None]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors4]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors5] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-blue] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-None]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-blue] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-blue]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-#FF00FF]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors3]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-blue] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors4]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors5]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-#FF00FF]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors3]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-#FF00FF] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors4]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-None]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors3] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors4] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-None] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors4]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-#FF00FF]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-#FF00FF]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-blue]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors5] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-#FF00FF] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-None] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors5] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-#FF00FF]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-blue]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors5]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-None] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors4] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors3]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors3] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors3] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-blue] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-blue]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors5]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-blue]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors4] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-blue]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors5] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors4] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-#FF00FF] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors5]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors3] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-None]', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-blue]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-None] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors4] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-blue] FAILED', 'FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-blue]', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-blue] FAILED', '../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors4] FAILED'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/vision/vision/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/vision/vision
configfile: pytest.ini
plugins: mock-3.14.0
collecting ... collected 48 items

../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-blue] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-#FF00FF] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors4] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors5] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-None] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-blue] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-#FF00FF] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors3] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors4] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors5] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-None] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-blue] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-#FF00FF] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors3] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors4] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors5] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-None] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-blue] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-#FF00FF] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors3] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors4] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors5] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-blue] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-#FF00FF] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors4] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors5] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-None] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-blue] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-#FF00FF] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors3] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors4] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors5] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-None] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-blue] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-#FF00FF] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors3] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors4] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors5] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-None] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-blue] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-#FF00FF] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors3] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors4] FAILED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors5] FAILED

=================================== FAILURES ===================================
___________________ test_draw_segmentation_masks[cpu-0-blue] ___________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
_________________ test_draw_segmentation_masks[cpu-0-#FF00FF] __________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
_________________ test_draw_segmentation_masks[cpu-0-colors4] __________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
_________________ test_draw_segmentation_masks[cpu-0-colors5] __________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
__________________ test_draw_segmentation_masks[cpu-0.5-None] __________________
../publishablew/vision/vision/test/test_utils.py:249: in test_draw_segmentation_masks
    assert out.dtype == dtype
E   assert torch.float32 == torch.uint8
E    +  where torch.float32 = tensor([[[232., 114., 203.,  ..., 168., 227., 239.],\n         [193.,  18., 162.,  ..., 165., 164., 100.],\n         [  1.,  74.,  38.,  ...,   7.,  11., 218.],\n         ...,\n         [179., 157., 175.,  ..., 248.,  38., 117.],\n         [  5., 128., 161.,  ..., 236., 247.,  12.],\n         [ 64., 137., 113.,  ...,  32., 149., 205.]],\n\n        [[ 42., 203., 250.,  ..., 183., 198., 235.],\n         [179., 240., 171.,  ...,  93.,  34.,  49.],\n         [155.,  88., 199.,  ..., 237., 151., 242.],\n         ...,\n         [ 92.,  53.,  39.,  ...,  95.,  99., 185.],\n         [138., 113.,  54.,  ..., 120., 141., 133.],\n         [ 70., 231., 148.,  ...,  79.,  99., 105.]],\n\n        [[ 33., 139.,   1.,  ..., 149., 217., 202.],\n         [254., 105., 233.,  ...,  49., 144., 148.],\n         [139., 207.,  54.,  ...,  87., 146.,  90.],\n         ...,\n         [170.,  99.,  62.,  ..., 143., 117., 167.],\n         [148., 233., 181.,  ..., 108.,  11., 225.],\n         [208., 120., 213.,  ...,  79., 107., 238.]]]).dtype
__________________ test_draw_segmentation_masks[cpu-0.5-blue] __________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
________________ test_draw_segmentation_masks[cpu-0.5-#FF00FF] _________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
________________ test_draw_segmentation_masks[cpu-0.5-colors3] _________________
../publishablew/vision/vision/test/test_utils.py:249: in test_draw_segmentation_masks
    assert out.dtype == dtype
E   assert torch.float32 == torch.uint8
E    +  where torch.float32 = tensor([[[232., 114., 203.,  ..., 168., 227., 239.],\n         [193.,  18., 162.,  ..., 165., 164., 100.],\n         [  1.,  74.,  38.,  ...,   7.,  11., 218.],\n         ...,\n         [179., 157., 175.,  ..., 248.,  38., 117.],\n         [  5., 128., 161.,  ..., 236., 247.,  12.],\n         [ 64., 137., 113.,  ...,  32., 149., 205.]],\n\n        [[ 42., 203., 250.,  ..., 183., 198., 235.],\n         [179., 240., 171.,  ...,  93.,  34.,  49.],\n         [155.,  88., 199.,  ..., 237., 151., 242.],\n         ...,\n         [ 92.,  53.,  39.,  ...,  95.,  99., 185.],\n         [138., 113.,  54.,  ..., 120., 141., 133.],\n         [ 70., 231., 148.,  ...,  79.,  99., 105.]],\n\n        [[ 33., 139.,   1.,  ..., 149., 217., 202.],\n         [254., 105., 233.,  ...,  49., 144., 148.],\n         [139., 207.,  54.,  ...,  87., 146.,  90.],\n         ...,\n         [170.,  99.,  62.,  ..., 143., 117., 167.],\n         [148., 233., 181.,  ..., 108.,  11., 225.],\n         [208., 120., 213.,  ...,  79., 107., 238.]]]).dtype
________________ test_draw_segmentation_masks[cpu-0.5-colors4] _________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
________________ test_draw_segmentation_masks[cpu-0.5-colors5] _________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
__________________ test_draw_segmentation_masks[cpu-0.7-None] __________________
../publishablew/vision/vision/test/test_utils.py:249: in test_draw_segmentation_masks
    assert out.dtype == dtype
E   assert torch.float32 == torch.uint8
E    +  where torch.float32 = tensor([[[232., 114., 203.,  ..., 168., 227., 239.],\n         [193.,  18., 162.,  ..., 165., 164., 100.],\n         [  1.,  74.,  38.,  ...,   7.,  11., 218.],\n         ...,\n         [179., 157., 175.,  ..., 248.,  38., 117.],\n         [  5., 128., 161.,  ..., 236., 247.,  12.],\n         [ 64., 137., 113.,  ...,  32., 149., 205.]],\n\n        [[ 42., 203., 250.,  ..., 183., 198., 235.],\n         [179., 240., 171.,  ...,  93.,  34.,  49.],\n         [155.,  88., 199.,  ..., 237., 151., 242.],\n         ...,\n         [ 92.,  53.,  39.,  ...,  95.,  99., 185.],\n         [138., 113.,  54.,  ..., 120., 141., 133.],\n         [ 70., 231., 148.,  ...,  79.,  99., 105.]],\n\n        [[ 33., 139.,   1.,  ..., 149., 217., 202.],\n         [254., 105., 233.,  ...,  49., 144., 148.],\n         [139., 207.,  54.,  ...,  87., 146.,  90.],\n         ...,\n         [170.,  99.,  62.,  ..., 143., 117., 167.],\n         [148., 233., 181.,  ..., 108.,  11., 225.],\n         [208., 120., 213.,  ...,  79., 107., 238.]]]).dtype
__________________ test_draw_segmentation_masks[cpu-0.7-blue] __________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
________________ test_draw_segmentation_masks[cpu-0.7-#FF00FF] _________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
________________ test_draw_segmentation_masks[cpu-0.7-colors3] _________________
../publishablew/vision/vision/test/test_utils.py:249: in test_draw_segmentation_masks
    assert out.dtype == dtype
E   assert torch.float32 == torch.uint8
E    +  where torch.float32 = tensor([[[232., 114., 203.,  ..., 168., 227., 239.],\n         [193.,  18., 162.,  ..., 165., 164., 100.],\n         [  1.,  74.,  38.,  ...,   7.,  11., 218.],\n         ...,\n         [179., 157., 175.,  ..., 248.,  38., 117.],\n         [  5., 128., 161.,  ..., 236., 247.,  12.],\n         [ 64., 137., 113.,  ...,  32., 149., 205.]],\n\n        [[ 42., 203., 250.,  ..., 183., 198., 235.],\n         [179., 240., 171.,  ...,  93.,  34.,  49.],\n         [155.,  88., 199.,  ..., 237., 151., 242.],\n         ...,\n         [ 92.,  53.,  39.,  ...,  95.,  99., 185.],\n         [138., 113.,  54.,  ..., 120., 141., 133.],\n         [ 70., 231., 148.,  ...,  79.,  99., 105.]],\n\n        [[ 33., 139.,   1.,  ..., 149., 217., 202.],\n         [254., 105., 233.,  ...,  49., 144., 148.],\n         [139., 207.,  54.,  ...,  87., 146.,  90.],\n         ...,\n         [170.,  99.,  62.,  ..., 143., 117., 167.],\n         [148., 233., 181.,  ..., 108.,  11., 225.],\n         [208., 120., 213.,  ...,  79., 107., 238.]]]).dtype
________________ test_draw_segmentation_masks[cpu-0.7-colors4] _________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
________________ test_draw_segmentation_masks[cpu-0.7-colors5] _________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
___________________ test_draw_segmentation_masks[cpu-1-None] ___________________
../publishablew/vision/vision/test/test_utils.py:268: in test_draw_segmentation_masks
    assert (out[:, mask & ~overlap] == color[:, None]).all()
E   AssertionError: assert tensor(False)
E    +  where tensor(False) = <built-in method all of Tensor object at 0x747fb3145190>()
E    +    where <built-in method all of Tensor object at 0x747fb3145190> = tensor([[235,...e=torch.uint8) == tensor([[0],\n...e=torch.uint8)
E         
E         Full diff:
E         - tensor([[0],
E         -         [0],
E         -         [0]], dtype=torch.uint8)
E         + tensor([[235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235,
E         +          235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235,...
E         
E         ...Full output truncated (16 lines hidden), use '-vv' to show.all
___________________ test_draw_segmentation_masks[cpu-1-blue] ___________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
_________________ test_draw_segmentation_masks[cpu-1-#FF00FF] __________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
_________________ test_draw_segmentation_masks[cpu-1-colors3] __________________
../publishablew/vision/vision/test/test_utils.py:276: in test_draw_segmentation_masks
    torch.testing.assert_close(out[:, overlap], interpolated_overlap, rtol=0.0, atol=1.0)
E   AssertionError: Tensor-likes are not close!
E   
E   Mismatched elements: 50 / 75 (66.7%)
E   Greatest absolute difference: 122 at index (2, 0) (up to 1.0 allowed)
E   Greatest relative difference: inf at index (1, 0) (up to 0.0 allowed)
_________________ test_draw_segmentation_masks[cpu-1-colors4] __________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
_________________ test_draw_segmentation_masks[cpu-1-colors5] __________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
__________________ test_draw_segmentation_masks[cuda-0-blue] ___________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
_________________ test_draw_segmentation_masks[cuda-0-#FF00FF] _________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
_________________ test_draw_segmentation_masks[cuda-0-colors4] _________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
_________________ test_draw_segmentation_masks[cuda-0-colors5] _________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
_________________ test_draw_segmentation_masks[cuda-0.5-None] __________________
../publishablew/vision/vision/test/test_utils.py:249: in test_draw_segmentation_masks
    assert out.dtype == dtype
E   AssertionError: assert torch.float32 == torch.uint8
E    +  where torch.float32 = tensor([[[119., 134.,  50.,  ..., 100., 146., 107.],\n         [ 93.,  20.,  76.,  ..., 170.,  17., 124.],\n         [160., 253., 180.,  ..., 107., 179.,  80.],\n         ...,\n         [ 91., 113., 224.,  ...,  90., 168.,  31.],\n         [237., 139.,   2.,  ...,  23.,  52.,  89.],\n         [252., 250.,  68.,  ...,  80., 106., 217.]],\n\n        [[ 20.,  25.,  54.,  ..., 245., 216.,  74.],\n         [234., 119., 158.,  ...,  82., 250., 196.],\n         [220.,  86.,  27.,  ..., 211., 167., 187.],\n         ...,\n         [146.,  91., 231.,  ..., 162.,  27., 146.],\n         [ 42., 199., 199.,  ..., 114., 233., 159.],\n         [157., 100., 175.,  ...,  79., 149., 246.]],\n\n        [[ 76., 253., 143.,  ..., 203., 101., 195.],\n         [196.,  27.,  38.,  ...,  26., 128., 113.],\n         [209., 251.,  27.,  ..., 161., 253.,  44.],\n         ...,\n         [146., 249.,  62.,  ...,  76.,  96., 200.],\n         [ 74.,  75.,   3.,  ..., 163., 105., 242.],\n         [213., 242.,  24.,  ..., 131.,  51., 204.]]], device='cuda:0').dtype
_________________ test_draw_segmentation_masks[cuda-0.5-blue] __________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
________________ test_draw_segmentation_masks[cuda-0.5-#FF00FF] ________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
________________ test_draw_segmentation_masks[cuda-0.5-colors3] ________________
../publishablew/vision/vision/test/test_utils.py:249: in test_draw_segmentation_masks
    assert out.dtype == dtype
E   AssertionError: assert torch.float32 == torch.uint8
E    +  where torch.float32 = tensor([[[119., 134.,  50.,  ..., 100., 146., 107.],\n         [ 93.,  20.,  76.,  ..., 170.,  17., 124.],\n         [160., 253., 180.,  ..., 107., 179.,  80.],\n         ...,\n         [ 91., 113., 224.,  ...,  90., 168.,  31.],\n         [237., 139.,   2.,  ...,  23.,  52.,  89.],\n         [252., 250.,  68.,  ...,  80., 106., 217.]],\n\n        [[ 20.,  25.,  54.,  ..., 245., 216.,  74.],\n         [234., 119., 158.,  ...,  82., 250., 196.],\n         [220.,  86.,  27.,  ..., 211., 167., 187.],\n         ...,\n         [146.,  91., 231.,  ..., 162.,  27., 146.],\n         [ 42., 199., 199.,  ..., 114., 233., 159.],\n         [157., 100., 175.,  ...,  79., 149., 246.]],\n\n        [[ 76., 253., 143.,  ..., 203., 101., 195.],\n         [196.,  27.,  38.,  ...,  26., 128., 113.],\n         [209., 251.,  27.,  ..., 161., 253.,  44.],\n         ...,\n         [146., 249.,  62.,  ...,  76.,  96., 200.],\n         [ 74.,  75.,   3.,  ..., 163., 105., 242.],\n         [213., 242.,  24.,  ..., 131.,  51., 204.]]], device='cuda:0').dtype
________________ test_draw_segmentation_masks[cuda-0.5-colors4] ________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
________________ test_draw_segmentation_masks[cuda-0.5-colors5] ________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
_________________ test_draw_segmentation_masks[cuda-0.7-None] __________________
../publishablew/vision/vision/test/test_utils.py:249: in test_draw_segmentation_masks
    assert out.dtype == dtype
E   AssertionError: assert torch.float32 == torch.uint8
E    +  where torch.float32 = tensor([[[119., 134.,  50.,  ..., 100., 146., 107.],\n         [ 93.,  20.,  76.,  ..., 170.,  17., 124.],\n         [160., 253., 180.,  ..., 107., 179.,  80.],\n         ...,\n         [ 91., 113., 224.,  ...,  90., 168.,  31.],\n         [237., 139.,   2.,  ...,  23.,  52.,  89.],\n         [252., 250.,  68.,  ...,  80., 106., 217.]],\n\n        [[ 20.,  25.,  54.,  ..., 245., 216.,  74.],\n         [234., 119., 158.,  ...,  82., 250., 196.],\n         [220.,  86.,  27.,  ..., 211., 167., 187.],\n         ...,\n         [146.,  91., 231.,  ..., 162.,  27., 146.],\n         [ 42., 199., 199.,  ..., 114., 233., 159.],\n         [157., 100., 175.,  ...,  79., 149., 246.]],\n\n        [[ 76., 253., 143.,  ..., 203., 101., 195.],\n         [196.,  27.,  38.,  ...,  26., 128., 113.],\n         [209., 251.,  27.,  ..., 161., 253.,  44.],\n         ...,\n         [146., 249.,  62.,  ...,  76.,  96., 200.],\n         [ 74.,  75.,   3.,  ..., 163., 105., 242.],\n         [213., 242.,  24.,  ..., 131.,  51., 204.]]], device='cuda:0').dtype
_________________ test_draw_segmentation_masks[cuda-0.7-blue] __________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
________________ test_draw_segmentation_masks[cuda-0.7-#FF00FF] ________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
________________ test_draw_segmentation_masks[cuda-0.7-colors3] ________________
../publishablew/vision/vision/test/test_utils.py:249: in test_draw_segmentation_masks
    assert out.dtype == dtype
E   AssertionError: assert torch.float32 == torch.uint8
E    +  where torch.float32 = tensor([[[119., 134.,  50.,  ..., 100., 146., 107.],\n         [ 93.,  20.,  76.,  ..., 170.,  17., 124.],\n         [160., 253., 180.,  ..., 107., 179.,  80.],\n         ...,\n         [ 91., 113., 224.,  ...,  90., 168.,  31.],\n         [237., 139.,   2.,  ...,  23.,  52.,  89.],\n         [252., 250.,  68.,  ...,  80., 106., 217.]],\n\n        [[ 20.,  25.,  54.,  ..., 245., 216.,  74.],\n         [234., 119., 158.,  ...,  82., 250., 196.],\n         [220.,  86.,  27.,  ..., 211., 167., 187.],\n         ...,\n         [146.,  91., 231.,  ..., 162.,  27., 146.],\n         [ 42., 199., 199.,  ..., 114., 233., 159.],\n         [157., 100., 175.,  ...,  79., 149., 246.]],\n\n        [[ 76., 253., 143.,  ..., 203., 101., 195.],\n         [196.,  27.,  38.,  ...,  26., 128., 113.],\n         [209., 251.,  27.,  ..., 161., 253.,  44.],\n         ...,\n         [146., 249.,  62.,  ...,  76.,  96., 200.],\n         [ 74.,  75.,   3.,  ..., 163., 105., 242.],\n         [213., 242.,  24.,  ..., 131.,  51., 204.]]], device='cuda:0').dtype
________________ test_draw_segmentation_masks[cuda-0.7-colors4] ________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
________________ test_draw_segmentation_masks[cuda-0.7-colors5] ________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
__________________ test_draw_segmentation_masks[cuda-1-None] ___________________
../publishablew/vision/vision/test/test_utils.py:268: in test_draw_segmentation_masks
    assert (out[:, mask & ~overlap] == color[:, None]).all()
E   AssertionError: assert tensor(False, device='cuda:0')
E    +  where tensor(False, device='cuda:0') = <built-in method all of Tensor object at 0x747fb31642f0>()
E    +    where <built-in method all of Tensor object at 0x747fb31642f0> = tensor([[235,...e=torch.uint8) == tensor([[0],\n...e=torch.uint8)
E         
E         Full diff:
E         - tensor([[0],
E         -         [0],
E         + tensor([[235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235,
E         +          235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235,
E         +          235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235, 235,...
E         
E         ...Full output truncated (18 lines hidden), use '-vv' to show.all
__________________ test_draw_segmentation_masks[cuda-1-blue] ___________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
_________________ test_draw_segmentation_masks[cuda-1-#FF00FF] _________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   TypeError: new(): invalid data type 'str'
_________________ test_draw_segmentation_masks[cuda-1-colors3] _________________
../publishablew/vision/vision/test/test_utils.py:276: in test_draw_segmentation_masks
    torch.testing.assert_close(out[:, overlap], interpolated_overlap, rtol=0.0, atol=1.0)
E   AssertionError: Tensor-likes are not close!
E   
E   Mismatched elements: 50 / 75 (66.7%)
E   Greatest absolute difference: 122 at index (2, 0) (up to 1.0 allowed)
E   Greatest relative difference: inf at index (1, 0) (up to 0.0 allowed)
_________________ test_draw_segmentation_masks[cuda-1-colors4] _________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
_________________ test_draw_segmentation_masks[cuda-1-colors5] _________________
../publishablew/vision/vision/test/test_utils.py:248: in test_draw_segmentation_masks
    out = utils.draw_segmentation_masks(img, masks, colors=colors, alpha=alpha)
../publishablew/vision/vision/venv/lib/python3.11/site-packages/torch/utils/_contextlib.py:116: in decorate_context
    return func(*args, **kwargs)
../publishablew/vision/vision/torchvision/utils.py:203: in draw_segmentation_masks
    return draw_segmentation_masks(image, masks, alpha, colors)
../publishablew/vision/vision/torchvision/temp.py:38: in draw_segmentation_masks
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
../publishablew/vision/vision/torchvision/temp.py:38: in <listcomp>
    colors = [torch.tensor(c, dtype=image.dtype, device=image.device) for c in colors]
E   ValueError: too many dimensions 'str'
=========================== short test summary info ============================
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-blue]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-#FF00FF]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors4]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors5]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-None]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-blue]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-#FF00FF]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors3]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors4]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors5]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-None]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-blue]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-#FF00FF]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors3]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors4]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors5]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-None]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-blue]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-#FF00FF]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors3]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors4]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors5]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-blue]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-#FF00FF]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors4]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors5]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-None]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-blue]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-#FF00FF]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors3]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors4]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors5]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-None]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-blue]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-#FF00FF]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors3]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors4]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors5]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-None]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-blue]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-#FF00FF]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors3]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors4]
FAILED ../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors5]
========================= 44 failed, 4 passed in 1.41s =========================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/vision/vision/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/vision/vision
configfile: pytest.ini
plugins: mock-3.14.0
collecting ... collected 48 items

../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors5] PASSED

============================== 48 passed in 0.37s ==============================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/vision/vision/venv/bin/python
cachedir: .pytest_cache
rootdir: /local/data0/moved_data/publishablew/vision/vision
configfile: pytest.ini
plugins: mock-3.14.0
collecting ... collected 48 items

../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.5-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-0.7-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cpu-1-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.5-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-0.7-colors5] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-None] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-blue] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-#FF00FF] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors3] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors4] PASSED
../publishablew/vision/vision/test/test_utils.py::test_draw_segmentation_masks[cuda-1-colors5] PASSED

============================== 48 passed in 0.41s ==============================
