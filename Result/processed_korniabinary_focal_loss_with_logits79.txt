output file:
processed_korniabinary_focal_loss_with_logits79.json
function:
binary_focal_loss_with_logits
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1]'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'onnxrt', 'openxla', 'cudagraphs', 'inductor', 'jit', None, 'tvm'}
model weights cached: ['checkpoints']

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1
collecting ... collected 59 items

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] FAILED

=================================== FAILURES ===================================
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f1330>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6068, 0.6041],
         [0.2059, 0.6346],
         [0.2257, 0.6907]],

        [[0.1124, 0.1478],
         [0.5362, 0.4747],
         [0.2863, 0.3775]]])
target = tensor([[[0.0626, 0.4888],
         [0.6524, 0.6294],
         [0.5922, 0.8496]],

        [[0.5783, 0.4097],
         [0.3758, 0.2669],
         [0.6501, 0.1764]]])
alpha = None, gamma = 0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f1150>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0967, 0.5166],
         [0.6263, 0.1114],
         [0.9613, 0.4935]],

        [[0.6601, 0.4555],
         [0.8533, 0.8760],
         [0.4057, 0.0949]]])
target = tensor([[[0.7800, 0.4929],
         [0.1082, 0.0669],
         [0.6615, 0.8354]],

        [[0.6864, 0.2600],
         [0.6379, 0.4668],
         [0.6315, 0.7549]]])
alpha = None, gamma = 0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f15d0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2799, 0.1896],
         [0.0405, 0.0889],
         [0.3589, 0.6066]],

        [[0.0408, 0.0689],
         [0.4056, 0.9755],
         [0.4365, 0.4845]]])
target = tensor([[[0.3500, 0.5522],
         [0.4106, 0.1276],
         [0.0766, 0.9913]],

        [[0.9726, 0.2232],
         [0.4680, 0.6827],
         [0.4078, 0.5987]]])
alpha = None, gamma = 0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f1690>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3194, 0.9004],
         [0.4675, 0.5139],
         [0.4846, 0.1103]],

        [[0.2435, 0.5007],
         [0.1832, 0.0516],
         [0.9969, 0.6020]]])
target = tensor([[[0.8118, 0.0267],
         [0.9110, 0.1893],
         [0.1646, 0.1091]],

        [[0.5429, 0.7307],
         [0.9048, 0.2181],
         [0.1405, 0.2485]]])
alpha = None, gamma = 0, reduction = 'none', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f1750>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4886, 0.8924],
         [0.0266, 0.8519],
         [0.2126, 0.2855]],

        [[0.4161, 0.1687],
         [0.8298, 0.6329],
         [0.3588, 0.9180]]])
target = tensor([[[0.8025, 0.7138],
         [0.9535, 0.1309],
         [0.8087, 0.2762]],

        [[0.4803, 0.0983],
         [0.1132, 0.1681],
         [0.7731, 0.9180]]])
alpha = None, gamma = 0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f1810>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7557, 0.9211],
         [0.1281, 0.4985],
         [0.4974, 0.5626]],

        [[0.0520, 0.4654],
         [0.4410, 0.7024],
         [0.6826, 0.7895]]])
target = tensor([[[0.9911, 0.2173],
         [0.6838, 0.4090],
         [0.6450, 0.4401]],

        [[0.6549, 0.1015],
         [0.9724, 0.4722],
         [0.5529, 0.6984]]])
alpha = None, gamma = 0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f1bd0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8854, 0.4114],
         [0.2314, 0.9119],
         [0.0900, 0.6008]],

        [[0.1818, 0.0689],
         [0.8523, 0.6922],
         [0.7443, 0.9769]]])
target = tensor([[[0.2614, 0.8794],
         [0.0465, 0.9693],
         [0.6172, 0.1112]],

        [[0.3146, 0.6434],
         [0.5271, 0.0935],
         [0.0327, 0.0062]]])
alpha = None, gamma = 0, reduction = 'none'
pos_weight = tensor([[0.4001],
        [0.2855],
        [0.4657]])
weight = tensor([[0.5495],
        [0.3589],
        [0.2774]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f1b10>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0159, 0.9136],
         [0.7847, 0.8588],
         [0.1270, 0.5577]],

        [[0.9752, 0.2354],
         [0.3453, 0.6988],
         [0.4443, 0.2131]]])
target = tensor([[[0.9668, 0.7754],
         [0.5003, 0.8498],
         [0.6659, 0.8652]],

        [[0.1132, 0.2452],
         [0.8693, 0.3304],
         [0.5184, 0.1958]]])
alpha = None, gamma = 0, reduction = 'mean'
pos_weight = tensor([[0.4331],
        [0.2289],
        [0.7246]])
weight = tensor([[0.8678],
        [0.5178],
        [0.9418]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f1e10>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1340, 0.9139],
         [0.3661, 0.0542],
         [0.3323, 0.3184]],

        [[0.8203, 0.8056],
         [0.2119, 0.4078],
         [0.6096, 0.5766]]])
target = tensor([[[0.7347, 0.8337],
         [0.7156, 0.8987],
         [0.9744, 0.1850]],

        [[0.2066, 0.3140],
         [0.0142, 0.5147],
         [0.1798, 0.1609]]])
alpha = None, gamma = 0, reduction = 'sum'
pos_weight = tensor([[0.5494],
        [0.5527],
        [0.2025]])
weight = tensor([[0.8184],
        [0.0301],
        [0.3699]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f2500>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5238, 0.5594],
         [0.1459, 0.2753],
         [0.9610, 0.4606]],

        [[0.6372, 0.1126],
         [0.8437, 0.6680],
         [0.4135, 0.6928]]])
target = tensor([[[0.6663, 0.7309],
         [0.2912, 0.7351],
         [0.2027, 0.3264]],

        [[0.3990, 0.1217],
         [0.0420, 0.3769],
         [0.9889, 0.8650]]])
alpha = None, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f2260>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9174, 0.8840],
         [0.6152, 0.0108],
         [0.7919, 0.9416]],

        [[0.2776, 0.8382],
         [0.9543, 0.8304],
         [0.8821, 0.7551]]])
target = tensor([[[0.8094, 0.6712],
         [0.7371, 0.3379],
         [0.9137, 0.0510]],

        [[0.6377, 0.7816],
         [0.7863, 0.8547],
         [0.3826, 0.0487]]])
alpha = None, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f2320>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9349, 0.4503],
         [0.9822, 0.6331],
         [0.2057, 0.9120]],

        [[0.8714, 0.4685],
         [0.6830, 0.2608],
         [0.4579, 0.4593]]])
target = tensor([[[0.9305, 0.2452],
         [0.5893, 0.6532],
         [0.3259, 0.6856]],

        [[0.0597, 0.0298],
         [0.8655, 0.8842],
         [0.3525, 0.5511]]])
alpha = None, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f23e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6007, 0.7173],
         [0.2135, 0.7385],
         [0.8484, 0.3105]],

        [[0.2289, 0.2057],
         [0.1565, 0.3655],
         [0.6747, 0.9682]]])
target = tensor([[[0.8051, 0.2607],
         [0.0850, 0.7804],
         [0.5674, 0.5645]],

        [[0.0764, 0.0139],
         [0.9570, 0.0673],
         [0.4159, 0.9061]]])
alpha = 0.2, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f24a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9769, 0.7909],
         [0.4020, 0.4279],
         [0.8606, 0.1756]],

        [[0.6831, 0.0645],
         [0.3282, 0.8246],
         [0.3369, 0.1644]]])
target = tensor([[[0.2559, 0.4415],
         [0.9288, 0.9474],
         [0.8223, 0.3513]],

        [[0.9441, 0.8371],
         [0.8556, 0.3410],
         [0.6565, 0.7007]]])
alpha = 0.2, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f21a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4008, 0.1162],
         [0.9245, 0.8937],
         [0.2700, 0.6481]],

        [[0.0569, 0.5118],
         [0.9996, 0.1557],
         [0.4778, 0.3629]]])
target = tensor([[[0.1024, 0.1660],
         [0.7157, 0.1981],
         [0.2554, 0.0342]],

        [[0.6325, 0.2221],
         [0.6195, 0.9002],
         [0.4718, 0.6994]]])
alpha = 0.2, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f2fb0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6096, 0.6574],
         [0.6998, 0.6997],
         [0.8606, 0.9124]],

        [[0.6248, 0.2856],
         [0.5415, 0.8685],
         [0.9342, 0.0589]]])
target = tensor([[[0.7630, 0.9511],
         [0.6327, 0.0398],
         [0.7779, 0.7030]],

        [[0.1809, 0.0949],
         [0.4971, 0.0584],
         [0.4708, 0.1267]]])
alpha = 0.5, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3070>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5718, 0.7519],
         [0.2916, 0.8841],
         [0.2985, 0.3390]],

        [[0.7655, 0.7649],
         [0.6175, 0.6970],
         [0.1806, 0.6934]]])
target = tensor([[[0.5860, 0.8819],
         [0.4775, 0.5924],
         [0.0485, 0.1311]],

        [[0.5071, 0.8291],
         [0.4912, 0.6436],
         [0.5809, 0.5027]]])
alpha = 0.5, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3130>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9051, 0.0427],
         [0.6325, 0.7594],
         [0.5752, 0.7538]],

        [[0.8322, 0.5048],
         [0.7310, 0.7466],
         [0.5571, 0.0214]]])
target = tensor([[[0.9332, 0.3351],
         [0.6991, 0.7982],
         [0.2076, 0.9590]],

        [[0.0582, 0.2880],
         [0.4410, 0.0942],
         [0.3156, 0.4376]]])
alpha = 0.5, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f31f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4641, 0.2321],
         [0.9479, 0.1954],
         [0.4388, 0.3328]],

        [[0.6681, 0.9907],
         [0.8628, 0.1897],
         [0.3872, 0.3559]]])
target = tensor([[[0.9322, 0.6528],
         [0.3749, 0.0013],
         [0.9571, 0.9402]],

        [[0.3379, 0.0551],
         [0.8978, 0.2828],
         [0.9243, 0.3321]]])
alpha = None, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f32b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6048, 0.4202],
         [0.0971, 0.5448],
         [0.9401, 0.6731]],

        [[0.2189, 0.9079],
         [0.0546, 0.4026],
         [0.1567, 0.0992]]])
target = tensor([[[0.2826, 0.0115],
         [0.3227, 0.5951],
         [0.9438, 0.3461]],

        [[0.4455, 0.1083],
         [0.0701, 0.8181],
         [0.3888, 0.5870]]])
alpha = None, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3370>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6805, 0.5820],
         [0.6252, 0.0773],
         [0.5751, 0.2241]],

        [[0.3134, 0.1072],
         [0.9817, 0.2793],
         [0.6717, 0.7544]]])
target = tensor([[[0.6622, 0.1553],
         [0.5203, 0.4088],
         [0.1645, 0.2402]],

        [[0.6593, 0.3599],
         [0.6345, 0.8607],
         [0.8884, 0.0544]]])
alpha = None, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3430>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4702, 0.7407],
         [0.6041, 0.7574],
         [0.2908, 0.8994]],

        [[0.6396, 0.2491],
         [0.4955, 0.6032],
         [0.9842, 0.8893]]])
target = tensor([[[0.0187, 0.1808],
         [0.7709, 0.1536],
         [0.6557, 0.4448]],

        [[0.3188, 0.6789],
         [0.2266, 0.8813],
         [0.6334, 0.8485]]])
alpha = 0.2, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f34f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8740, 0.5622],
         [0.3709, 0.9701],
         [0.4958, 0.0284]],

        [[0.0892, 0.0279],
         [0.6984, 0.4040],
         [0.4132, 0.8741]]])
target = tensor([[[0.3854, 0.7117],
         [0.6656, 0.3707],
         [0.7261, 0.6687]],

        [[0.7226, 0.9856],
         [0.2213, 0.1459],
         [0.0170, 0.3548]]])
alpha = 0.2, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f35b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7189, 0.0262],
         [0.0124, 0.1436],
         [0.0556, 0.4851]],

        [[0.0090, 0.2213],
         [0.1212, 0.5560],
         [0.9799, 0.6498]]])
target = tensor([[[0.8177, 0.4219],
         [0.7641, 0.7122],
         [0.7984, 0.2728]],

        [[0.1195, 0.3424],
         [0.4947, 0.3972],
         [0.0880, 0.9312]]])
alpha = 0.2, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3670>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5917, 0.8933],
         [0.0127, 0.4272],
         [0.3974, 0.0217]],

        [[0.6353, 0.4566],
         [0.4142, 0.4888],
         [0.5503, 0.5447]]])
target = tensor([[[0.6850, 0.6365],
         [0.2528, 0.0858],
         [0.3228, 0.6614]],

        [[0.1179, 0.0699],
         [0.4233, 0.8737],
         [0.8867, 0.6976]]])
alpha = 0.5, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3730>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8627, 0.0318],
         [0.3435, 0.5451],
         [0.0662, 0.7025]],

        [[0.4829, 0.6954],
         [0.3534, 0.9241],
         [0.4610, 0.0511]]])
target = tensor([[[0.4209, 0.7281],
         [0.1021, 0.0134],
         [0.2590, 0.1027]],

        [[0.3797, 0.0339],
         [0.0109, 0.2873],
         [0.9653, 0.2301]]])
alpha = 0.5, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f37f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5056, 0.0417],
         [0.7120, 0.2522],
         [0.8106, 0.9325]],

        [[0.2060, 0.2869],
         [0.4591, 0.5989],
         [0.6383, 0.7367]]])
target = tensor([[[0.6044, 0.6687],
         [0.1953, 0.3180],
         [0.3261, 0.7975]],

        [[0.3477, 0.9884],
         [0.4671, 0.8380],
         [0.1935, 0.0409]]])
alpha = 0.5, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f38b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5936, 0.5850],
         [0.6633, 0.8927],
         [0.5304, 0.7202]],

        [[0.5262, 0.9181],
         [0.9544, 0.9982],
         [0.3941, 0.3622]]])
target = tensor([[[0.7083, 0.7105],
         [0.3041, 0.3104],
         [0.2275, 0.0286]],

        [[0.0230, 0.8832],
         [0.9131, 0.4440],
         [0.0924, 0.3092]]])
alpha = None, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3970>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7498, 0.3677],
         [0.9291, 0.3892],
         [0.4050, 0.8727]],

        [[0.0647, 0.3031],
         [0.6324, 0.7824],
         [0.9014, 0.5360]]])
target = tensor([[[0.4708, 0.0135],
         [0.2626, 0.2263],
         [0.6062, 0.6778]],

        [[0.8566, 0.9045],
         [0.8398, 0.9526],
         [0.2625, 0.0081]]])
alpha = None, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3a30>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8618, 0.4024],
         [0.6144, 0.1149],
         [0.8745, 0.1306]],

        [[0.5987, 0.4004],
         [0.5352, 0.7325],
         [0.4333, 0.8272]]])
target = tensor([[[0.0100, 0.6472],
         [0.0622, 0.5558],
         [0.7268, 0.0064]],

        [[0.8514, 0.6090],
         [0.7820, 0.1273],
         [0.8120, 0.5714]]])
alpha = None, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3af0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7935, 0.6212],
         [0.1752, 0.7238],
         [0.0524, 0.7113]],

        [[0.9958, 0.5950],
         [0.3884, 0.9661],
         [0.7357, 0.2542]]])
target = tensor([[[0.1824, 0.7123],
         [0.9723, 0.9301],
         [0.0816, 0.7222]],

        [[0.9214, 0.7801],
         [0.1410, 0.1553],
         [0.8859, 0.0757]]])
alpha = 0.2, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3bb0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[9.3207e-02, 2.7236e-01],
         [1.5187e-01, 9.2382e-01],
         [4.9031e-04, 1.4646e-02]],

        [[5.0368e-01, 6.2163e-01],
         [3.0861e-01, 8.5493e-01],
         [2.9030e-01, 1.4845e-01]]])
target = tensor([[[0.8830, 0.3533],
         [0.8601, 0.0224],
         [0.9795, 0.4631]],

        [[0.7064, 0.2748],
         [0.4539, 0.5699],
         [0.6981, 0.8448]]])
alpha = 0.2, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3c70>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[1.9002e-04, 8.8778e-01],
         [4.6232e-01, 8.9915e-01],
         [1.6071e-01, 9.6098e-01]],

        [[8.7704e-01, 3.3584e-01],
         [8.2626e-01, 1.4340e-01],
         [8.6678e-01, 4.0149e-01]]])
target = tensor([[[0.3400, 0.4134],
         [0.8350, 0.7616],
         [0.8592, 0.2961]],

        [[0.3383, 0.6223],
         [0.1037, 0.1393],
         [0.1926, 0.9304]]])
alpha = 0.2, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3d30>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8158, 0.2420],
         [0.6828, 0.9561],
         [0.7043, 0.8788]],

        [[0.5138, 0.7565],
         [0.2145, 0.5850],
         [0.1615, 0.4212]]])
target = tensor([[[0.9627, 0.7631],
         [0.8192, 0.5747],
         [0.8855, 0.8559]],

        [[0.4013, 0.8460],
         [0.0412, 0.9917],
         [0.2050, 0.5452]]])
alpha = 0.5, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3df0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1521, 0.3986],
         [0.8433, 0.0659],
         [0.2234, 0.4617]],

        [[0.8789, 0.2173],
         [0.3517, 0.2578],
         [0.5951, 0.5774]]])
target = tensor([[[0.3685, 0.0695],
         [0.5810, 0.2637],
         [0.5639, 0.5650]],

        [[0.1050, 0.5380],
         [0.5670, 0.6947],
         [0.2603, 0.5542]]])
alpha = 0.5, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x7729190f3eb0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1415, 0.3471],
         [0.1120, 0.0368],
         [0.4735, 0.0747]],

        [[0.1386, 0.5302],
         [0.4796, 0.8627],
         [0.9049, 0.9002]]])
target = tensor([[[0.1268, 0.2460],
         [0.2336, 0.9287],
         [0.2713, 0.9252]],

        [[0.6999, 0.3439],
         [0.3468, 0.1487],
         [0.5867, 0.4054]]])
alpha = 0.5, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f244f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1359, 0.7584],
         [0.5916, 0.6139],
         [0.1500, 0.7214]],

        [[0.9834, 0.8986],
         [0.7029, 0.6709],
         [0.6362, 0.5152]]])
target = tensor([[[0.0123, 0.0830],
         [0.1622, 0.7649],
         [0.4255, 0.6483]],

        [[0.0157, 0.1352],
         [0.6338, 0.9998],
         [0.6303, 0.8522]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f24430>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7963, 0.5074],
         [0.2954, 0.1934],
         [0.2139, 0.2515]],

        [[0.5810, 0.1016],
         [0.0263, 0.3639],
         [0.6476, 0.1173]]])
target = tensor([[[0.3545, 0.4085],
         [0.8048, 0.1274],
         [0.7036, 0.4248]],

        [[0.9522, 0.4908],
         [0.3331, 0.0550],
         [0.2000, 0.4554]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f24310>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2479, 0.1375],
         [0.0979, 0.0476],
         [0.1926, 0.6285]],

        [[0.2315, 0.4755],
         [0.8524, 0.0387],
         [0.9749, 0.4600]]])
target = tensor([[[0.5007, 0.7264],
         [0.6887, 0.3423],
         [0.8219, 0.8193]],

        [[0.2074, 0.2615],
         [0.8406, 0.0918],
         [0.6407, 0.8911]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f24a00>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0782, 0.1305],
         [0.6526, 0.0341],
         [0.7857, 0.6282]],

        [[0.0825, 0.4976],
         [0.3773, 0.1903],
         [0.3545, 0.8034]]])
target = tensor([[[0.2694, 0.0863],
         [0.0839, 0.6472],
         [0.9516, 0.0909]],

        [[0.0413, 0.6978],
         [0.8468, 0.2921],
         [0.8699, 0.0401]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f24ac0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8271, 0.9897],
         [0.8142, 0.6917],
         [0.1418, 0.1201]],

        [[0.5024, 0.5067],
         [0.5471, 0.2569],
         [0.0977, 0.6649]]])
target = tensor([[[6.4345e-01, 6.2109e-01],
         [2.3491e-01, 9.4125e-02],
         [6.4650e-01, 2.2661e-01]],

        [[3.0348e-02, 8.5599e-01],
         [5.8981e-01, 8.3693e-01],
         [9.6850e-01, 8.0252e-04]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f24b80>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3625, 0.0344],
         [0.5386, 0.8406],
         [0.1395, 0.3998]],

        [[0.4530, 0.7142],
         [0.0343, 0.0063],
         [0.3820, 0.5946]]])
target = tensor([[[0.2942, 0.9280],
         [0.7747, 0.9415],
         [0.6988, 0.4879]],

        [[0.8031, 0.8017],
         [0.9391, 0.1067],
         [0.5138, 0.2948]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f24c40>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8931, 0.4857],
         [0.6037, 0.8521],
         [0.6205, 0.2914]],

        [[0.9863, 0.8008],
         [0.3243, 0.6247],
         [0.6368, 0.7346]]])
target = tensor([[[0.5722, 0.4622],
         [0.5104, 0.5382],
         [0.4432, 0.3664]],

        [[0.0882, 0.0581],
         [0.3048, 0.2881],
         [0.6450, 0.2098]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f24d00>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3514, 0.2936],
         [0.3109, 0.4335],
         [0.3218, 0.4040]],

        [[0.6439, 0.9321],
         [0.9336, 0.7314],
         [0.3970, 0.9616]]])
target = tensor([[[0.5443, 0.3583],
         [0.6855, 0.6394],
         [0.5464, 0.6028]],

        [[0.9528, 0.4852],
         [0.1237, 0.3338],
         [0.5133, 0.9667]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f24dc0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7136, 0.9021],
         [0.1086, 0.6305],
         [0.6047, 0.3270]],

        [[0.0562, 0.2952],
         [0.6193, 0.8337],
         [0.5930, 0.4730]]])
target = tensor([[[0.5183, 0.3160],
         [0.9092, 0.6037],
         [0.6773, 0.8977]],

        [[0.0679, 0.8457],
         [0.3674, 0.3335],
         [0.4023, 0.5065]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f24e80>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2654, 0.2126],
         [0.4683, 0.1295],
         [0.3685, 0.0351]],

        [[0.4564, 0.2837],
         [0.0502, 0.1107],
         [0.6557, 0.2430]]])
target = tensor([[[0.9724, 0.6524],
         [0.6866, 0.8889],
         [0.3847, 0.3397]],

        [[0.7221, 0.3635],
         [0.9899, 0.9310],
         [0.2641, 0.2873]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f24f40>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3943, 0.2609],
         [0.9940, 0.4914],
         [0.4977, 0.8810]],

        [[0.2124, 0.7521],
         [0.9710, 0.3428],
         [0.6906, 0.1164]]])
target = tensor([[[0.1695, 0.7648],
         [0.0583, 0.8756],
         [0.8472, 0.6269]],

        [[0.9050, 0.7646],
         [0.4753, 0.6650],
         [0.3144, 0.4011]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f25000>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5309, 0.6887],
         [0.4766, 0.3708],
         [0.2973, 0.4301]],

        [[0.4263, 0.5221],
         [0.5657, 0.7261],
         [0.5122, 0.6738]]])
target = tensor([[[0.4813, 0.6885],
         [0.3889, 0.5883],
         [0.0590, 0.3857]],

        [[0.5423, 0.1480],
         [0.8312, 0.0544],
         [0.0906, 0.1634]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f25480>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5669, 0.4215],
         [0.0416, 0.5150],
         [0.4729, 0.4516]],

        [[0.6724, 0.0303],
         [0.8318, 0.8691],
         [0.8665, 0.4578]]])
target = tensor([[[-1.0000e+02,  8.2521e-02],
         [ 4.9400e-01,  1.2068e-02],
         [-1.0000e+02,  8.2760e-01]],

        [[ 2.5845e-02, -1.0000e+02],
         [-1.0000e+02, -1.0000e+02],
         [-1.0000e+02,  1.5735e-01]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f25330>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0160, 0.4644],
         [0.4723, 0.0238],
         [0.9517, 0.2429]],

        [[0.0173, 0.6893],
         [0.7750, 0.0457],
         [0.3043, 0.4777]]])
target = tensor([[[ 4.8227e-02,  1.8843e-01],
         [ 2.5428e-02, -1.0000e+02],
         [-1.0000e+02,  6.2329e-01]],

        [[ 7.5196e-02, -1.0000e+02],
         [ 3.5249e-01, -1.0000e+02],
         [ 5.0042e-01,  3.9109e-01]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f257b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8264, 0.5406],
         [0.6729, 0.6266],
         [0.6339, 0.6390]],

        [[0.3395, 0.0350],
         [0.8645, 0.7590],
         [0.7521, 0.7553]]])
target = tensor([[[ 7.0890e-01,  4.2386e-01],
         [ 8.8611e-01,  1.8458e-01],
         [-1.0000e+02, -1.0000e+02]],

        [[ 5.1157e-03,  4.7923e-01],
         [-1.0000e+02,  7.8803e-01],
         [ 2.6874e-01,  8.6544e-01]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f25870>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8382, 0.3819],
         [0.2132, 0.0086],
         [0.0543, 0.3747]],

        [[0.6011, 0.5894],
         [0.4965, 0.0062],
         [0.1135, 0.2804]]])
target = tensor([[[  0.6698,   0.6289],
         [  0.5826, 255.0000],
         [255.0000, 255.0000]],

        [[  0.4106, 255.0000],
         [  0.6657,   0.4304],
         [  0.7408,   0.5824]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f25930>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1896, 0.0306],
         [0.4810, 0.3023],
         [0.1091, 0.6042]],

        [[0.1080, 0.1477],
         [0.6043, 0.5324],
         [0.3378, 0.8363]]])
target = tensor([[[255.0000,   0.3930],
         [  0.3777,   0.8774],
         [255.0000,   0.4341]],

        [[  0.9573, 255.0000],
         [255.0000, 255.0000],
         [255.0000,   0.7373]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f259f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5249, 0.6916],
         [0.5455, 0.7717],
         [0.8218, 0.9796]],

        [[0.2576, 0.4316],
         [0.0718, 0.8185],
         [0.0409, 0.8589]]])
target = tensor([[[9.1166e-01, 2.5500e+02],
         [9.8016e-01, 2.5500e+02],
         [2.5500e+02, 2.5500e+02]],

        [[6.7485e-01, 2.5500e+02],
         [3.0694e-02, 3.9044e-01],
         [7.6967e-01, 7.9745e-01]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_______ TestBinaryFocalLossWithLogits.test_dynamo[cpu-float32-inductor] ________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f25d80>
device = device(type='cpu'), dtype = torch.float32
torch_optimizer = functools.partial(<function compile at 0x7729ee5d9900>, backend='inductor')

    def test_dynamo(self, device, dtype, torch_optimizer):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        op = kornia.losses.binary_focal_loss_with_logits
        op_optimized = torch_optimizer(op)
    
        args = (0.25, 2.0)
>       actual = op_optimized(logits, labels, *args)

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:465: in _fn
    return fn(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1939, 0.1851],
         [0.7876, 0.3094],
         [0.9789, 0.3277]],

        [[0.4743, 0.3057],
         [0.1780, 0.1409],
         [0.1473, 0.8338]]])
target = tensor([[[0.0307, 0.1995],
         [0.8766, 0.4915],
         [0.4373, 0.4098]],

        [[0.3179, 0.2875],
         [0.0754, 0.0773],
         [0.0078, 0.3916]]])
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
______________ TestBinaryFocalLossWithLogits.test_gradcheck[cpu] _______________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f26020>
device = device(type='cpu')

    def test_gradcheck(self, device):
        logits = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        labels = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
>       self.gradcheck(op, (logits, labels, *args))

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7354, 0.3741],
         [0.6071, 0.9826],
         [0.5897, 0.3657]],

        [[0.6939, 0.5738],
         [0.8269, 0.4524],
         [0.8991, 0.3108]]], dtype=torch.float64, requires_grad=True)
target = tensor([[[0.9671, 0.2987],
         [0.0524, 0.7562],
         [0.7652, 0.9435]],

        [[0.3842, 0.8178],
         [0.0160, 0.8012],
         [0.6854, 0.7384]]], dtype=torch.float64, requires_grad=True)
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
________ TestBinaryFocalLossWithLogits.test_gradcheck_ignore_index[cpu] ________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f262c0>
device = device(type='cpu')

    def test_gradcheck_ignore_index(self, device):
        logits = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        labels = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        ignore = torch.rand(2, 3, 2, device=device) > 0.8
        labels[ignore] = -100
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
>       self.gradcheck(op, (logits, labels, *args), requires_grad=[True, False, False, False])

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7375, 0.6939],
         [0.6576, 0.1400],
         [0.7358, 0.6532]],

        [[0.5011, 0.6886],
         [0.2540, 0.9503],
         [0.2168, 0.4496]]], dtype=torch.float64, requires_grad=True)
target = tensor([[[ 9.8491e-01,  7.6065e-01],
         [ 8.3873e-01,  2.6727e-01],
         [ 1.1185e-01, -1.0000e+02]],

     ...877e-01, -1.0000e+02],
         [ 3.4702e-01,  5.6327e-01],
         [ 1.4455e-01,  3.0228e-02]]], dtype=torch.float64)
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
____________ TestBinaryFocalLossWithLogits.test_module[cpu-float32] ____________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f24130>
device = device(type='cpu'), dtype = torch.float32

    def test_module(self, device, dtype):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
        op_module = kornia.losses.BinaryFocalLossWithLogits(*args)
>       self.assert_close(op_module(logits, labels), op(logits, labels, *args))

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
../publishablew/kornia/kornia/kornia/losses/focal.py:261: in forward
    return binary_focal_loss_with_logits(pred, target, self.alpha, self.gamma, self.reduction, self.pos_weight, self.weight, self.ignore_index)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5045, 0.8637],
         [0.4598, 0.3893],
         [0.1172, 0.7534]],

        [[0.9872, 0.0909],
         [0.2555, 0.5391],
         [0.7662, 0.8272]]])
target = tensor([[[0.3051, 0.6446],
         [0.7221, 0.5237],
         [0.5467, 0.0627]],

        [[0.5746, 0.4341],
         [0.7413, 0.5273],
         [0.5429, 0.2763]]])
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
______ TestBinaryFocalLossWithLogits.test_numeric_stability[cpu-float32] _______

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x772918f266b0>
device = device(type='cpu'), dtype = torch.float32

    def test_numeric_stability(self, device, dtype):
        logits = torch.tensor([[100.0, -100]], dtype=dtype, device=device)
        labels = torch.tensor([[1.0, 0.0]], dtype=dtype, device=device)
    
        args = (0.25, 2.0)
>       actual = kornia.losses.binary_focal_loss_with_logits(logits, labels, *args)

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[ 100., -100.]]), target = tensor([[1., 0.]]), alpha = 0.25
gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
=========================== short test summary info ============================
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32]
============================== 59 failed in 0.90s ==============================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'inductor', 'jit', 'onnxrt', 'openxla', 'tvm', 'cudagraphs', None}
model weights cached: ['checkpoints']

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1
collecting ... collected 59 items

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] PASSED

============================== 59 passed in 2.13s ==============================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'cudagraphs', 'openxla', 'jit', 'onnxrt', 'tvm', 'inductor', None}
model weights cached: ['checkpoints']

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1
collecting ... collected 59 items

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] PASSED

============================== 59 passed in 2.07s ==============================
