output file:
processed_korniabinary_focal_loss_with_logits79.json
function:
binary_focal_loss_with_logits
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] FAILED', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2]', '../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2]', 'FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu]'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'onnxrt', 'openxla', 'cudagraphs', 'inductor', 'jit', 'tvm', None}
model weights cached: ['checkpoints']

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1
collecting ... collected 59 items

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] FAILED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] FAILED

=================================== FAILURES ===================================
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e17b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8308, 0.3878],
         [0.4266, 0.4121],
         [0.9365, 0.7646]],

        [[0.3378, 0.6534],
         [0.8118, 0.9742],
         [0.0643, 0.6918]]])
target = tensor([[[0.3356, 0.7170],
         [0.7346, 0.8216],
         [0.8633, 0.2209]],

        [[0.9260, 0.2476],
         [0.2144, 0.4432],
         [0.8225, 0.1619]]])
alpha = None, gamma = 0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e15d0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7367, 0.2457],
         [0.5993, 0.0804],
         [0.5813, 0.4772]],

        [[0.6477, 0.9277],
         [0.8640, 0.9338],
         [0.8868, 0.5926]]])
target = tensor([[[0.3318, 0.2162],
         [0.5912, 0.0984],
         [0.2249, 0.2842]],

        [[0.7205, 0.1144],
         [0.0851, 0.6761],
         [0.8037, 0.7248]]])
alpha = None, gamma = 0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32--100-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e1a50>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
ignore_index = -100

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2013, 0.6856],
         [0.7803, 0.1781],
         [0.7772, 0.9351]],

        [[0.4966, 0.1499],
         [0.4102, 0.2599],
         [0.3340, 0.4074]]])
target = tensor([[[0.9163, 0.5204],
         [0.8761, 0.9386],
         [0.1296, 0.8238]],

        [[0.7984, 0.2392],
         [0.0370, 0.8750],
         [0.2275, 0.2118]]])
alpha = None, gamma = 0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e1b10>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8300, 0.3874],
         [0.9288, 0.0076],
         [0.7133, 0.6492]],

        [[0.4898, 0.5327],
         [0.3924, 0.3087],
         [0.3980, 0.4053]]])
target = tensor([[[0.0448, 0.3217],
         [0.2762, 0.0522],
         [0.6471, 0.0493]],

        [[0.6915, 0.8886],
         [0.3266, 0.2712],
         [0.7697, 0.5960]]])
alpha = None, gamma = 0, reduction = 'none', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e1bd0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9088, 0.9776],
         [0.8986, 0.7779],
         [0.0479, 0.5933]],

        [[0.6251, 0.3961],
         [0.7097, 0.1566],
         [0.7432, 0.7184]]])
target = tensor([[[0.8955, 0.1847],
         [0.3276, 0.9882],
         [0.3419, 0.1278]],

        [[0.7400, 0.3020],
         [0.4044, 0.1885],
         [0.1479, 0.3188]]])
alpha = None, gamma = 0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss[cpu-float32-None-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e1c90>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
ignore_index = None

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    @pytest.mark.parametrize("ignore_index", [-100, None])
    def test_value_same_as_torch_bce_loss(self, device, dtype, reduction, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, ignore_index=ignore_index
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8925, 0.0433],
         [0.5958, 0.0508],
         [0.9915, 0.8736]],

        [[0.1376, 0.7389],
         [0.3804, 0.7250],
         [0.9860, 0.6317]]])
target = tensor([[[0.8364, 0.1645],
         [0.5246, 0.0273],
         [0.8714, 0.0948]],

        [[0.5538, 0.0021],
         [0.8988, 0.4649],
         [0.0491, 0.6598]]])
alpha = None, gamma = 0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = None

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e2050>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5195, 0.3847],
         [0.1223, 0.9658],
         [0.9711, 0.0912]],

        [[0.9742, 0.5712],
         [0.7258, 0.6587],
         [0.6743, 0.2795]]])
target = tensor([[[0.0654, 0.4864],
         [0.9920, 0.8768],
         [0.5363, 0.5140]],

        [[0.3505, 0.1625],
         [0.8372, 0.3031],
         [0.1180, 0.0361]]])
alpha = None, gamma = 0, reduction = 'none'
pos_weight = tensor([[0.5529],
        [0.2748],
        [0.0170]])
weight = tensor([[0.5588],
        [0.6804],
        [0.2832]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e1f90>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5674, 0.3822],
         [0.5997, 0.8709],
         [0.8820, 0.7328]],

        [[0.3359, 0.8339],
         [0.5758, 0.8065],
         [0.9718, 0.1456]]])
target = tensor([[[0.8181, 0.1935],
         [0.4970, 0.5180],
         [0.8718, 0.8757]],

        [[0.4398, 0.8460],
         [0.3325, 0.9642],
         [0.8331, 0.8222]]])
alpha = None, gamma = 0, reduction = 'mean'
pos_weight = tensor([[0.7729],
        [0.0251],
        [0.8487]])
weight = tensor([[0.9349],
        [0.0352],
        [0.5399]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e2290>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'

    @pytest.mark.parametrize("reduction", ["none", "mean", "sum"])
    def test_value_same_as_torch_bce_loss_pos_weight_weight(self, device, dtype, reduction):
        num_classes = 3
        logits = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
        labels = torch.rand(2, num_classes, 2, dtype=dtype, device=device)
    
        pos_weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
        weight = torch.rand(num_classes, 1, dtype=dtype, device=device)
    
>       focal_equivalent_bce_loss = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=None, gamma=0, reduction=reduction, pos_weight=pos_weight, weight=weight
        )

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5285, 0.4007],
         [0.5975, 0.1858],
         [0.1311, 0.9223]],

        [[0.9546, 0.8297],
         [0.7509, 0.3417],
         [0.4684, 0.0452]]])
target = tensor([[[0.2570, 0.3172],
         [0.9589, 0.7075],
         [0.1868, 0.3412]],

        [[0.4706, 0.9499],
         [0.7704, 0.5444],
         [0.2244, 0.1887]]])
alpha = None, gamma = 0, reduction = 'sum'
pos_weight = tensor([[0.5782],
        [0.3314],
        [0.3072]])
weight = tensor([[0.1843],
        [0.0534],
        [0.0033]])
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e2980>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2839, 0.8925],
         [0.0220, 0.4319],
         [0.0207, 0.3974]],

        [[0.7433, 0.1615],
         [0.3415, 0.6906],
         [0.1400, 0.7070]]])
target = tensor([[[0.2477, 0.0663],
         [0.8101, 0.6706],
         [0.3704, 0.8515]],

        [[0.7866, 0.8059],
         [0.6625, 0.4083],
         [0.5794, 0.8541]]])
alpha = None, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e26e0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0778, 0.4121],
         [0.6801, 0.5867],
         [0.0160, 0.8818]],

        [[0.6648, 0.3235],
         [0.3595, 0.4139],
         [0.1375, 0.1144]]])
target = tensor([[[0.4720, 0.0225],
         [0.4764, 0.6464],
         [0.2364, 0.7324]],

        [[0.3483, 0.1321],
         [0.5488, 0.1815],
         [0.8329, 0.6197]]])
alpha = None, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e27a0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1820, 0.9901],
         [0.3595, 0.1419],
         [0.6725, 0.8102]],

        [[0.4684, 0.2013],
         [0.5998, 0.7751],
         [0.2152, 0.2657]]])
target = tensor([[[1.5290e-01, 5.8057e-02],
         [1.3614e-01, 5.1270e-01],
         [4.5399e-01, 1.9464e-02]],

        [[7.1451e-01, 3.0306e-01],
         [5.8197e-01, 3.8513e-01],
         [1.3994e-01, 5.0408e-04]]])
alpha = None, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e2860>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8942, 0.3162],
         [0.8562, 0.5590],
         [0.2692, 0.0682]],

        [[0.2057, 0.1997],
         [0.8234, 0.7079],
         [0.7337, 0.3081]]])
target = tensor([[[0.0529, 0.5143],
         [0.2661, 0.2274],
         [0.0431, 0.7317]],

        [[0.0118, 0.6560],
         [0.3826, 0.6723],
         [0.8286, 0.9095]]])
alpha = 0.2, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e2920>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5174, 0.8026],
         [0.1960, 0.1830],
         [0.7537, 0.4529]],

        [[0.6046, 0.0543],
         [0.0107, 0.2512],
         [0.1237, 0.0364]]])
target = tensor([[[0.6363, 0.3625],
         [0.0973, 0.9138],
         [0.3430, 0.3757]],

        [[0.5922, 0.5328],
         [0.7332, 0.9495],
         [0.1711, 0.2885]]])
alpha = 0.2, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e2620>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2435, 0.6248],
         [0.4593, 0.2339],
         [0.3637, 0.2956]],

        [[0.2852, 0.3197],
         [0.2428, 0.5180],
         [0.4167, 0.3320]]])
target = tensor([[[0.5158, 0.2402],
         [0.2208, 0.4139],
         [0.0925, 0.9778]],

        [[0.1341, 0.7929],
         [0.4151, 0.8963],
         [0.5915, 0.7821]]])
alpha = 0.2, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e3430>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8005, 0.3624],
         [0.8879, 0.5421],
         [0.5208, 0.8668]],

        [[0.9730, 0.9728],
         [0.9910, 0.6503],
         [0.6158, 0.5669]]])
target = tensor([[[0.7122, 0.8868],
         [0.8624, 0.3780],
         [0.3881, 0.3343]],

        [[0.8317, 0.5008],
         [0.5691, 0.0995],
         [0.0739, 0.8994]]])
alpha = 0.5, gamma = 0.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e34f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9852, 0.1940],
         [0.5982, 0.9281],
         [0.1721, 0.9565]],

        [[0.9462, 0.4703],
         [0.6387, 0.6624],
         [0.8005, 0.1668]]])
target = tensor([[[0.3688, 0.5462],
         [0.5516, 0.5960],
         [0.8157, 0.2778]],

        [[0.7854, 0.4474],
         [0.4303, 0.8960],
         [0.7289, 0.6038]]])
alpha = 0.5, gamma = 0.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e35b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 0.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6290, 0.6307],
         [0.9946, 0.4699],
         [0.0680, 0.6823]],

        [[0.2894, 0.5017],
         [0.4193, 0.8548],
         [0.1524, 0.9651]]])
target = tensor([[[0.3673, 0.1852],
         [0.3714, 0.5662],
         [0.3871, 0.8137]],

        [[0.7157, 0.6887],
         [0.1828, 0.8762],
         [0.6544, 0.2578]]])
alpha = 0.5, gamma = 0.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e3670>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7369, 0.7291],
         [0.0298, 0.7491],
         [0.0269, 0.4577]],

        [[0.8226, 0.6015],
         [0.1033, 0.9887],
         [0.1508, 0.3342]]])
target = tensor([[[0.1247, 0.8509],
         [0.6053, 0.6414],
         [0.0219, 0.7275]],

        [[0.1654, 0.6088],
         [0.0751, 0.7294],
         [0.2376, 0.1932]]])
alpha = None, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e3730>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[9.0720e-01, 4.5024e-01],
         [4.8839e-01, 9.7342e-01],
         [9.7767e-02, 8.7273e-04]],

        [[5.6816e-01, 4.4633e-01],
         [7.2713e-01, 9.9344e-01],
         [4.5198e-01, 2.7250e-01]]])
target = tensor([[[0.2439, 0.1509],
         [0.1754, 0.0784],
         [0.9655, 0.5501]],

        [[0.9933, 0.8648],
         [0.0142, 0.0524],
         [0.2039, 0.5587]]])
alpha = None, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e37f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5122, 0.9417],
         [0.7546, 0.6568],
         [0.5963, 0.2971]],

        [[0.7146, 0.5339],
         [0.5801, 0.4487],
         [0.1311, 0.2957]]])
target = tensor([[[0.8680, 0.1084],
         [0.1070, 0.3741],
         [0.9453, 0.3627]],

        [[0.1772, 0.4697],
         [0.2154, 0.3607],
         [0.0127, 0.3308]]])
alpha = None, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e38b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7174, 0.7695],
         [0.5316, 0.3137],
         [0.4671, 0.8176]],

        [[0.4096, 0.7303],
         [0.9685, 0.7998],
         [0.2410, 0.3504]]])
target = tensor([[[0.6500, 0.7274],
         [0.0997, 0.6453],
         [0.9383, 0.9041]],

        [[0.3756, 0.5080],
         [0.3786, 0.5698],
         [0.4049, 0.8940]]])
alpha = 0.2, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e3970>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8202, 0.3583],
         [0.0517, 0.5897],
         [0.8569, 0.2653]],

        [[0.4700, 0.1220],
         [0.0826, 0.5795],
         [0.9062, 0.0167]]])
target = tensor([[[0.8496, 0.5871],
         [0.0760, 0.7002],
         [0.1533, 0.5216]],

        [[0.9194, 0.0924],
         [0.0636, 0.0798],
         [0.2922, 0.4066]]])
alpha = 0.2, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e3a30>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2577, 0.9946],
         [0.0146, 0.1807],
         [0.0943, 0.0722]],

        [[0.5492, 0.3268],
         [0.3718, 0.0229],
         [0.0426, 0.2831]]])
target = tensor([[[0.1427, 0.2523],
         [0.1674, 0.2700],
         [0.9715, 0.2101]],

        [[0.2728, 0.2990],
         [0.3243, 0.6706],
         [0.1899, 0.0794]]])
alpha = 0.2, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e3af0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1575, 0.2829],
         [0.5325, 0.1517],
         [0.7422, 0.7546]],

        [[0.0122, 0.1307],
         [0.6822, 0.5985],
         [0.2593, 0.5132]]])
target = tensor([[[0.4655, 0.4248],
         [0.5746, 0.1863],
         [0.6095, 0.6292]],

        [[0.7619, 0.1170],
         [0.3315, 0.5488],
         [0.9929, 0.8270]]])
alpha = 0.5, gamma = 1.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e3bb0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8814, 0.8056],
         [0.0467, 0.1547],
         [0.0255, 0.0819]],

        [[0.7251, 0.5870],
         [0.8660, 0.7340],
         [0.0728, 0.7257]]])
target = tensor([[[0.2923, 0.8701],
         [0.0379, 0.1884],
         [0.2216, 0.8568]],

        [[0.6903, 0.4995],
         [0.3479, 0.0711],
         [0.7932, 0.4980]]])
alpha = 0.5, gamma = 1.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e3c70>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 1.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5478, 0.3127],
         [0.8659, 0.4995],
         [0.6936, 0.7162]],

        [[0.9724, 0.3140],
         [0.9351, 0.9485],
         [0.0821, 0.3248]]])
target = tensor([[[0.6282, 0.5695],
         [0.7076, 0.4607],
         [0.4552, 0.8399]],

        [[0.2827, 0.7704],
         [0.9114, 0.3985],
         [0.2000, 0.7853]]])
alpha = 0.5, gamma = 1.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e3d30>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8670, 0.8268],
         [0.8284, 0.6992],
         [0.6137, 0.3564]],

        [[0.3190, 0.7963],
         [0.1498, 0.2781],
         [0.3008, 0.9267]]])
target = tensor([[[0.8528, 0.9685],
         [0.0463, 0.5856],
         [0.4961, 0.9135]],

        [[0.6167, 0.5244],
         [0.3659, 0.3022],
         [0.9231, 0.9208]]])
alpha = None, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e3df0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6152, 0.4526],
         [0.4057, 0.8159],
         [0.3519, 0.6295]],

        [[0.9710, 0.4673],
         [0.0934, 0.8529],
         [0.0185, 0.5822]]])
target = tensor([[[0.9035, 0.9192],
         [0.0655, 0.8418],
         [0.9519, 0.0347]],

        [[0.6356, 0.0814],
         [0.6150, 0.3414],
         [0.5656, 0.4213]]])
alpha = None, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e3eb0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = None, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2100, 0.3454],
         [0.7205, 0.8329],
         [0.3139, 0.9413]],

        [[0.9871, 0.9525],
         [0.4248, 0.4158],
         [0.7471, 0.9620]]])
target = tensor([[[0.0917, 0.3265],
         [0.1876, 0.6427],
         [0.4458, 0.9552]],

        [[0.1915, 0.8686],
         [0.8810, 0.0146],
         [0.3050, 0.8215]]])
alpha = None, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb275e3f70>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2941, 0.2610],
         [0.2941, 0.8857],
         [0.0525, 0.2365]],

        [[0.4747, 0.9179],
         [0.1247, 0.2280],
         [0.9291, 0.9025]]])
target = tensor([[[0.1413, 0.1621],
         [0.0882, 0.0229],
         [0.1043, 0.3968]],

        [[0.5584, 0.1278],
         [0.8941, 0.2751],
         [0.2561, 0.8417]]])
alpha = 0.2, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f14070>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3861, 0.2523],
         [0.5961, 0.2863],
         [0.5664, 0.0519]],

        [[0.8891, 0.3898],
         [0.0168, 0.4065],
         [0.0365, 0.8919]]])
target = tensor([[[0.2394, 0.9832],
         [0.4496, 0.8417],
         [0.4985, 0.3287]],

        [[0.1042, 0.6552],
         [0.8193, 0.8770],
         [0.9481, 0.1462]]])
alpha = 0.2, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f14130>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.2, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0213, 0.0496],
         [0.0954, 0.3691],
         [0.6819, 0.7842]],

        [[0.4455, 0.9255],
         [0.8053, 0.0148],
         [0.0237, 0.9046]]])
target = tensor([[[0.1638, 0.2345],
         [0.6769, 0.0183],
         [0.4318, 0.3545]],

        [[0.0894, 0.8373],
         [0.8858, 0.6650],
         [0.9749, 0.3212]]])
alpha = 0.2, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f141f0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.0549, 0.2709],
         [0.5938, 0.0038],
         [0.8211, 0.3540]],

        [[0.7162, 0.0602],
         [0.4467, 0.8017],
         [0.0440, 0.6219]]])
target = tensor([[[0.2764, 0.2631],
         [0.3484, 0.3290],
         [0.1019, 0.1833]],

        [[0.2170, 0.7134],
         [0.0972, 0.3779],
         [0.8124, 0.7316]]])
alpha = 0.5, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f142b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.1119, 0.0446],
         [0.0810, 0.5419],
         [0.8642, 0.7667]],

        [[0.1672, 0.9830],
         [0.3449, 0.5208],
         [0.1467, 0.3686]]])
target = tensor([[[0.9442, 0.1589],
         [0.6705, 0.3226],
         [0.3085, 0.5550]],

        [[0.3320, 0.3350],
         [0.8629, 0.0440],
         [0.2349, 0.1095]]])
alpha = 0.5, gamma = 2.0, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f14370>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), alpha = 0.5, gamma = 2.0

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("alpha", [None, 0.2, 0.5])
    @pytest.mark.parametrize("gamma", [0.0, 1.0, 2.0])
    def test_shape_alpha_gamma(self, device, dtype, reduction, expected_shape, alpha, gamma):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=alpha, gamma=gamma, reduction=reduction
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:47: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6693, 0.7691],
         [0.1864, 0.9155],
         [0.5306, 0.8057]],

        [[0.0749, 0.5189],
         [0.0465, 0.8662],
         [0.6197, 0.5870]]])
target = tensor([[[0.1996, 0.8378],
         [0.1894, 0.9293],
         [0.2733, 0.5334]],

        [[0.5302, 0.5786],
         [0.0769, 0.3553],
         [0.9958, 0.3543]]])
alpha = 0.5, gamma = 2.0, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f14970>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3582, 0.9889],
         [0.1038, 0.2047],
         [0.2394, 0.3477]],

        [[0.6406, 0.8218],
         [0.0441, 0.4211],
         [0.2204, 0.3820]]])
target = tensor([[[0.9766, 0.7537],
         [0.2167, 0.7360],
         [0.2291, 0.0857]],

        [[0.6694, 0.0955],
         [0.5042, 0.9672],
         [0.3001, 0.8125]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f148b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9598, 0.2821],
         [0.5795, 0.2462],
         [0.6372, 0.6601]],

        [[0.5184, 0.0531],
         [0.2932, 0.8547],
         [0.2665, 0.5412]]])
target = tensor([[[0.2748, 0.9331],
         [0.0708, 0.6106],
         [0.8457, 0.0884]],

        [[0.7656, 0.6658],
         [0.8711, 0.9372],
         [0.6039, 0.7232]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f14790>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = None, weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9149, 0.4607],
         [0.5962, 0.7648],
         [0.6199, 0.4469]],

        [[0.5841, 0.2490],
         [0.6683, 0.8340],
         [0.3176, 0.3568]]])
target = tensor([[[0.9263, 0.8554],
         [0.9551, 0.2975],
         [0.6808, 0.5281]],

        [[0.2882, 0.9793],
         [0.1047, 0.8630],
         [0.6038, 0.3766]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f14e80>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2387, 0.0146],
         [0.1155, 0.9812],
         [0.4611, 0.0147]],

        [[0.7072, 0.6330],
         [0.0571, 0.2530],
         [0.8515, 0.5435]]])
target = tensor([[[0.2327, 0.1667],
         [0.8633, 0.5138],
         [0.7214, 0.7604]],

        [[0.0441, 0.5763],
         [0.0235, 0.6350],
         [0.4444, 0.5558]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f14f40>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5632, 0.5800],
         [0.1762, 0.9568],
         [0.5980, 0.0206]],

        [[0.7976, 0.0564],
         [0.2864, 0.1891],
         [0.2170, 0.6232]]])
target = tensor([[[0.6802, 0.4036],
         [0.1861, 0.6444],
         [0.4836, 0.6714]],

        [[0.1067, 0.8575],
         [0.1689, 0.7241],
         [0.4339, 0.1704]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f15000>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = tensor([1., 2., 5.]), weight = None

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7519, 0.1562],
         [0.6629, 0.6016],
         [0.4152, 0.7986]],

        [[0.8543, 0.8024],
         [0.0977, 0.7183],
         [0.6088, 0.9296]]])
target = tensor([[[0.8468, 0.0701],
         [0.1284, 0.4721],
         [0.8751, 0.4700]],

        [[0.3710, 0.7859],
         [0.3904, 0.2803],
         [0.2934, 0.9056]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = tensor([1., 2., 5.])
weight = None, ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f150c0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6489, 0.9574],
         [0.7586, 0.0477],
         [0.6598, 0.2146]],

        [[0.9336, 0.7620],
         [0.8783, 0.6083],
         [0.0239, 0.9964]]])
target = tensor([[[0.3668, 0.5239],
         [0.1284, 0.1456],
         [0.5046, 0.2285]],

        [[0.7739, 0.2789],
         [0.8652, 0.1570],
         [0.2855, 0.8146]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f15180>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2000, 0.1462],
         [0.4878, 0.0260],
         [0.7417, 0.9765]],

        [[0.2436, 0.7767],
         [0.4394, 0.7334],
         [0.3368, 0.6398]]])
target = tensor([[[0.5892, 0.7148],
         [0.5945, 0.4231],
         [0.7215, 0.5989]],

        [[0.2397, 0.4508],
         [0.8830, 0.9978],
         [0.9702, 0.4814]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f15240>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6550, 0.6519],
         [0.9682, 0.5483],
         [0.1923, 0.8682]],

        [[0.6213, 0.3945],
         [0.0439, 0.4383],
         [0.7117, 0.3258]]])
target = tensor([[[0.6230, 0.5022],
         [0.8585, 0.3790],
         [0.4427, 0.0843]],

        [[0.3289, 0.7901],
         [0.6800, 0.8473],
         [0.6279, 0.2221]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f15300>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6701, 0.6435],
         [0.4558, 0.4809],
         [0.3874, 0.3561]],

        [[0.1057, 0.8508],
         [0.0732, 0.6172],
         [0.6270, 0.9454]]])
target = tensor([[[0.7899, 0.9323],
         [0.0719, 0.7626],
         [0.2908, 0.4270]],

        [[0.4221, 0.9776],
         [0.2631, 0.9520],
         [0.5026, 0.2196]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f153c0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6716, 0.2152],
         [0.0116, 0.4949],
         [0.3653, 0.7247]],

        [[0.5885, 0.5454],
         [0.1350, 0.1337],
         [0.7150, 0.0861]]])
target = tensor([[[0.5326, 0.2676],
         [0.0320, 0.3325],
         [0.5418, 0.2791]],

        [[0.5096, 0.3106],
         [0.9553, 0.5105],
         [0.2478, 0.7759]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f15480>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000])

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("pos_weight", [None, (1, 2, 5)])
    @pytest.mark.parametrize("weight", [None, (0.2, 0.5, 0.8)])
    def test_shape_pos_weight_weight(self, device, dtype, reduction, expected_shape, pos_weight, weight):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        pos_weight = None if pos_weight is None else torch.tensor(pos_weight, dtype=dtype, device=device)
        weight = None if weight is None else torch.tensor(weight, dtype=dtype, device=device)
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, pos_weight=pos_weight, weight=weight
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.8390, 0.9106],
         [0.4305, 0.7427],
         [0.0314, 0.8650]],

        [[0.5337, 0.8095],
         [0.2649, 0.6713],
         [0.8420, 0.1117]]])
target = tensor([[[0.1090, 0.6325],
         [0.5726, 0.2993],
         [0.6471, 0.6184]],

        [[0.6929, 0.3712],
         [0.2148, 0.5985],
         [0.5004, 0.0604]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = tensor([1., 2., 5.])
weight = tensor([0.2000, 0.5000, 0.8000]), ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f15900>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2235, 0.8903],
         [0.1522, 0.4926],
         [0.1126, 0.1124]],

        [[0.4541, 0.4042],
         [0.7258, 0.7611],
         [0.8013, 0.1596]]])
target = tensor([[[ 8.9457e-01,  4.5286e-02],
         [ 4.2012e-01,  1.2560e-01],
         [-1.0000e+02,  6.7998e-01]],

        [[ 1.0923e-01,  8.5430e-01],
         [ 9.5211e-01, -1.0000e+02],
         [ 8.8169e-01,  8.3524e-01]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f157b0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.4400, 0.0693],
         [0.1492, 0.7776],
         [0.9435, 0.0864]],

        [[0.0923, 0.3555],
         [0.7450, 0.3854],
         [0.1046, 0.1791]]])
target = tensor([[[-100.0000, -100.0000],
         [   0.4882,    0.6248],
         [-100.0000,    0.3708]],

        [[   0.7853,    0.3282],
         [   0.8675, -100.0000],
         [   0.4814,    0.4016]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f15c30>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), ignore_index = -100

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.3952, 0.1250],
         [0.4589, 0.1054],
         [0.1983, 0.2565]],

        [[0.0272, 0.4995],
         [0.1740, 0.7834],
         [0.3732, 0.7849]]])
target = tensor([[[-1.0000e+02,  5.5247e-01],
         [ 4.4249e-01, -1.0000e+02],
         [ 7.4719e-01,  8.3505e-01]],

        [[ 8.5191e-01, -1.0000e+02],
         [ 9.2901e-02,  1.8053e-01],
         [-1.0000e+02,  2.7205e-01]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-none-expected_shape0] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f15cf0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'none'
expected_shape = (2, 3, 2), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9330, 0.8879],
         [0.3589, 0.8748],
         [0.6205, 0.2853]],

        [[0.3827, 0.5956],
         [0.2600, 0.7702],
         [0.2149, 0.9846]]])
target = tensor([[[2.7202e-01, 1.3277e-01],
         [4.9125e-01, 3.1571e-01],
         [2.5500e+02, 2.2425e-01]],

        [[2.5500e+02, 5.7609e-01],
         [4.2920e-01, 6.8594e-01],
         [2.5500e+02, 2.5500e+02]]])
alpha = 0.8, gamma = 0.5, reduction = 'none', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f15db0>
device = device(type='cpu'), dtype = torch.float32, reduction = 'mean'
expected_shape = (), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.7989, 0.1452],
         [0.9723, 0.9463],
         [0.5856, 0.3480]],

        [[0.1788, 0.1873],
         [0.3630, 0.7650],
         [0.0721, 0.7392]]])
target = tensor([[[2.5500e+02, 2.3968e-01],
         [2.5500e+02, 2.5500e+02],
         [2.5500e+02, 3.8097e-01]],

        [[8.5007e-01, 2.5500e+02],
         [9.1190e-01, 2.5500e+02],
         [2.5500e+02, 7.6640e-02]]])
alpha = 0.8, gamma = 0.5, reduction = 'mean', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_ TestBinaryFocalLossWithLogits.test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] _

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f15e70>
device = device(type='cpu'), dtype = torch.float32, reduction = 'sum'
expected_shape = (), ignore_index = 255

    @pytest.mark.parametrize("reduction,expected_shape", [("none", (2, 3, 2)), ("mean", ()), ("sum", ())])
    @pytest.mark.parametrize("ignore_index", [-100, 255])
    def test_shape_ignore_index(self, device, dtype, reduction, expected_shape, ignore_index):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        ignore = torch.rand(2, 3, 2, device=device) > 0.6
        labels[ignore] = ignore_index
    
>       actual_shape = kornia.losses.binary_focal_loss_with_logits(
            logits, labels, alpha=0.8, gamma=0.5, reduction=reduction, ignore_index=ignore_index
        ).shape

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:76: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2549, 0.3966],
         [0.7722, 0.2376],
         [0.7907, 0.4127]],

        [[0.5791, 0.3269],
         [0.3531, 0.9934],
         [0.0046, 0.4643]]])
target = tensor([[[1.1489e-01, 4.3901e-01],
         [2.5500e+02, 4.5338e-01],
         [2.5500e+02, 1.2681e-01]],

        [[7.2917e-01, 2.5500e+02],
         [9.8113e-01, 2.5500e+02],
         [2.5500e+02, 2.8683e-02]]])
alpha = 0.8, gamma = 0.5, reduction = 'sum', pos_weight = None, weight = None
ignore_index = 255

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
_______ TestBinaryFocalLossWithLogits.test_dynamo[cpu-float32-inductor] ________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f16200>
device = device(type='cpu'), dtype = torch.float32
torch_optimizer = functools.partial(<function compile at 0x78fc00dc5900>, backend='inductor')

    def test_dynamo(self, device, dtype, torch_optimizer):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        op = kornia.losses.binary_focal_loss_with_logits
        op_optimized = torch_optimizer(op)
    
        args = (0.25, 2.0)
>       actual = op_optimized(logits, labels, *args)

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:465: in _fn
    return fn(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.2316, 0.4256],
         [0.6073, 0.8070],
         [0.3970, 0.8759]],

        [[0.3407, 0.5737],
         [0.8594, 0.6514],
         [0.7014, 0.3605]]])
target = tensor([[[0.5089, 0.2034],
         [0.2440, 0.2055],
         [0.2797, 0.8427]],

        [[0.4102, 0.7812],
         [0.8137, 0.3951],
         [0.3006, 0.2886]]])
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
______________ TestBinaryFocalLossWithLogits.test_gradcheck[cpu] _______________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f164a0>
device = device(type='cpu')

    def test_gradcheck(self, device):
        logits = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        labels = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
>       self.gradcheck(op, (logits, labels, *args))

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:99: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.5099, 0.2988],
         [0.9540, 0.0955],
         [0.8466, 0.4845]],

        [[0.0303, 0.5336],
         [0.9809, 0.3103],
         [0.2891, 0.6436]]], dtype=torch.float64, requires_grad=True)
target = tensor([[[0.6498, 0.4079],
         [0.3196, 0.7068],
         [0.9876, 0.8823]],

        [[0.5564, 0.4486],
         [0.9798, 0.0550],
         [0.1009, 0.5848]]], dtype=torch.float64, requires_grad=True)
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
________ TestBinaryFocalLossWithLogits.test_gradcheck_ignore_index[cpu] ________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f16740>
device = device(type='cpu')

    def test_gradcheck_ignore_index(self, device):
        logits = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        labels = torch.rand(2, 3, 2, device=device, dtype=torch.float64)
        ignore = torch.rand(2, 3, 2, device=device) > 0.8
        labels[ignore] = -100
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
>       self.gradcheck(op, (logits, labels, *args), requires_grad=[True, False, False, False])

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:109: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.9801, 0.3722],
         [0.5232, 0.2735],
         [0.8853, 0.9040]],

        [[0.0885, 0.1285],
         [0.2914, 0.1084],
         [0.1090, 0.3624]]], dtype=torch.float64, requires_grad=True)
target = tensor([[[ 9.9397e-01,  2.4200e-02],
         [-1.0000e+02, -1.0000e+02],
         [ 6.2151e-02, -1.0000e+02]],

     ...536e-01,  6.6762e-01],
         [ 5.7676e-01, -1.0000e+02],
         [ 8.5208e-01, -1.0000e+02]]], dtype=torch.float64)
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
____________ TestBinaryFocalLossWithLogits.test_module[cpu-float32] ____________

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f145b0>
device = device(type='cpu'), dtype = torch.float32

    def test_module(self, device, dtype):
        logits = torch.rand(2, 3, 2, dtype=dtype, device=device)
        labels = torch.rand(2, 3, 2, dtype=dtype, device=device)
    
        args = (0.25, 2.0)
        op = kornia.losses.binary_focal_loss_with_logits
        op_module = kornia.losses.BinaryFocalLossWithLogits(*args)
>       self.assert_close(op_module(logits, labels), op(logits, labels, *args))

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1736: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1747: in _call_impl
    return forward_call(*args, **kwargs)
../publishablew/kornia/kornia/kornia/losses/focal.py:261: in forward
    return binary_focal_loss_with_logits(pred, target, self.alpha, self.gamma, self.reduction, self.pos_weight, self.weight, self.ignore_index)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[[0.6533, 0.2517],
         [0.4696, 0.5910],
         [0.4972, 0.4009]],

        [[0.8144, 0.4505],
         [0.1762, 0.7898],
         [0.8211, 0.3335]]])
target = tensor([[[0.8673, 0.5340],
         [0.5304, 0.7318],
         [0.3240, 0.6980]],

        [[0.4211, 0.6639],
         [0.8627, 0.0021],
         [0.5564, 0.8759]]])
alpha = 0.25, gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
______ TestBinaryFocalLossWithLogits.test_numeric_stability[cpu-float32] _______

self = <test_focal_loss.TestBinaryFocalLossWithLogits object at 0x78fb26f16b30>
device = device(type='cpu'), dtype = torch.float32

    def test_numeric_stability(self, device, dtype):
        logits = torch.tensor([[100.0, -100]], dtype=dtype, device=device)
        labels = torch.tensor([[1.0, 0.0]], dtype=dtype, device=device)
    
        args = (0.25, 2.0)
>       actual = kornia.losses.binary_focal_loss_with_logits(logits, labels, *args)

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

pred = tensor([[ 100., -100.]]), target = tensor([[1., 0.]]), alpha = 0.25
gamma = 2.0, reduction = 'none', pos_weight = None, weight = None
ignore_index = -100

    def binary_focal_loss_with_logits(pred: Tensor, target: Tensor, alpha: Optional[float]=0.25, gamma: float=2.0, reduction: str='none', pos_weight: Optional[Tensor]=None, weight: Optional[Tensor]=None, ignore_index: Optional[int]=-100) -> Tensor:
        from .temp import binary_focal_loss_with_logits
>       return binary_focal_loss_with_logits(pred, target, alpha, gamma, reduction, pos_weight, weight, ignore_index)
E       TypeError: binary_focal_loss_with_logits() takes from 2 to 7 positional arguments but 8 were given

../publishablew/kornia/kornia/kornia/losses/focal.py:131: TypeError
=========================== short test summary info ============================
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32]
FAILED ../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32]
============================== 59 failed in 0.90s ==============================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'jit', 'tvm', 'cudagraphs', 'openxla', 'inductor', 'onnxrt', None}
model weights cached: ['checkpoints']

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1
collecting ... collected 59 items

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] PASSED

============================== 59 passed in 2.11s ==============================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'jit', 'inductor', 'tvm', 'cudagraphs', 'onnxrt', 'openxla', None}
model weights cached: ['checkpoints']

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1
collecting ... collected 59 items

../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-none] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-mean] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32--100-sum] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-none] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-mean] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss[cpu-float32-None-sum] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-none] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-mean] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_value_same_as_torch_bce_loss_pos_weight_weight[cpu-float32-sum] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.2-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-0.0-0.5-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.2-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-1.0-0.5-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.2-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_alpha_gamma[cpu-float32-2.0-0.5-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-None-pos_weight1-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-None-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_pos_weight_weight[cpu-float32-weight1-pos_weight1-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32--100-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-none-expected_shape0] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-mean-expected_shape1] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_shape_ignore_index[cpu-float32-255-sum-expected_shape2] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_dynamo[cpu-float32-inductor] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck[cpu] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_gradcheck_ignore_index[cpu] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_module[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/losses/test_focal_loss.py::TestBinaryFocalLossWithLogits::test_numeric_stability[cpu-float32] PASSED

============================== 59 passed in 2.42s ==============================
