output file:
processed_korniaequalize_clahe28.json
function:
equalize_clahe
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3]', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3]', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]]', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1]', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1]', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got]', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3]', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got]', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] FAILED', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1]', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] FAILED', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got]', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] FAILED', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] FAILED', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] FAILED', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] FAILED', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0]', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] FAILED', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] FAILED', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None]', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2]', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32]', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3]', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu]', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1]', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1]', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] FAILED', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] FAILED', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32]', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] FAILED', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32]', 'FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32]', '../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] FAILED'}

All Test Cases On Generated code:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'inductor', 'openxla', 'jit', 'cudagraphs', 'tvm', 'onnxrt', None}
model weights cached: ['checkpoints']

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1
collecting ... collected 25 items

../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] FAILED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] FAILED

=================================== FAILURES ===================================
___________________ TestEqualization.test_smoke[cpu-float32] ___________________

self = <test_equalization.TestEqualization object at 0x7b4bf9cdce20>
device = device(type='cpu'), dtype = torch.float32

    def test_smoke(self, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.0556, 0.8676, 0.8544, 0.6349, 0.7768, 0.8811, 0.3983, 0.3656,
           0.6346, 0.4704, 0.7947, 0.9525, ...         0.4837, 0.1117, 0.0293, 0.2443, 0.6759, 0.4019, 0.7280, 0.9444,
           0.8130, 0.1961, 0.9985, 0.7879]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
>       input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
E       RuntimeError: maximum size for tensor at dimension 4 is 1 but size is 2

../publishablew/kornia/kornia/kornia/enhance/temp.py:29: RuntimeError
____________ TestEqualization.test_cardinality[cpu-float32-None-1] _____________

self = <test_equalization.TestEqualization object at 0x7b4bf9cdd2d0>, B = None
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.4377, 0.4235, 0.3991, 0.0710, 0.5162, 0.9256, 0.1019, 0.2443,
           0.8354, 0.2737, 0.1075, 0.0956, ...         0.3986, 0.9092, 0.2144, 0.7975, 0.2425, 0.2515, 0.0426, 0.0530,
           0.3986, 0.4220, 0.1260, 0.2940]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
>       input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
E       RuntimeError: maximum size for tensor at dimension 4 is 1 but size is 2

../publishablew/kornia/kornia/kornia/enhance/temp.py:29: RuntimeError
____________ TestEqualization.test_cardinality[cpu-float32-None-3] _____________

self = <test_equalization.TestEqualization object at 0x7b4bf9cdd210>, B = None
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.6485, 0.7795, 0.5741, 0.3242, 0.0054, 0.6769, 0.4567, 0.6934,
           0.6058, 0.9837, 0.4218, 0.4174, ...         0.2280, 0.0504, 0.5805, 0.6660, 0.6828, 0.1963, 0.3577, 0.7121,
           0.9179, 0.7458, 0.9833, 0.6659]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
>       input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
E       RuntimeError: maximum size for tensor at dimension 4 is 1 but size is 2

../publishablew/kornia/kornia/kornia/enhance/temp.py:29: RuntimeError
______________ TestEqualization.test_cardinality[cpu-float32-1-1] ______________

self = <test_equalization.TestEqualization object at 0x7b4bf9cdd690>, B = 1
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.2602, 0.0266, 0.1107, 0.1778, 0.3599, 0.2245, 0.7401, 0.4749,
           0.7566, 0.6903, 0.2304, 0.7704, ...         0.4682, 0.8821, 0.6682, 0.2536, 0.8400, 0.3033, 0.8656, 0.2901,
           0.3655, 0.4223, 0.4715, 0.3079]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
>       input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
E       RuntimeError: maximum size for tensor at dimension 4 is 1 but size is 2

../publishablew/kornia/kornia/kornia/enhance/temp.py:29: RuntimeError
______________ TestEqualization.test_cardinality[cpu-float32-1-3] ______________

self = <test_equalization.TestEqualization object at 0x7b4bf9cdd750>, B = 1
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[6.4406e-01, 6.4383e-01, 1.7400e-01, 1.0322e-01, 3.7001e-01,
           3.6627e-01, 9.1769e-01, 5.5319e-01, ...291e-03, 3.2802e-01, 6.3302e-01, 3.7362e-01,
           4.4487e-02, 8.8121e-01, 3.9163e-01, 4.0261e-01, 5.9115e-01]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
>       input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
E       RuntimeError: maximum size for tensor at dimension 4 is 1 but size is 2

../publishablew/kornia/kornia/kornia/enhance/temp.py:29: RuntimeError
______________ TestEqualization.test_cardinality[cpu-float32-4-1] ______________

self = <test_equalization.TestEqualization object at 0x7b4bf9cdd810>, B = 4
C = 1, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.6705, 0.2362, 0.4754, 0.9490, 0.5748, 0.6128, 0.8065, 0.9276,
           0.1251, 0.7675, 0.9499, 0.5050, ...         0.1922, 0.3098, 0.2216, 0.3396, 0.3038, 0.5198, 0.1633, 0.1517,
           0.9666, 0.7877, 0.3383, 0.3450]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
>       input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
E       RuntimeError: maximum size for tensor at dimension 4 is 1 but size is 2

../publishablew/kornia/kornia/kornia/enhance/temp.py:29: RuntimeError
______________ TestEqualization.test_cardinality[cpu-float32-4-3] ______________

self = <test_equalization.TestEqualization object at 0x7b4bf9cdd8d0>, B = 4
C = 3, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("B, C", [(None, 1), (None, 3), (1, 1), (1, 3), (4, 1), (4, 3)])
    def test_cardinality(self, B, C, device, dtype):
        H, W = 10, 20
        if B is None:
            img = torch.rand(C, H, W, device=device, dtype=dtype)
        else:
            img = torch.rand(B, C, H, W, device=device, dtype=dtype)
>       res = enhance.equalize_clahe(img)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:29: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.6779, 0.6145, 0.4713,  ..., 0.2989, 0.1690, 0.2989],
          [0.8991, 0.9561, 0.8002,  ..., 0.3070, 0.8...27, 0.0602, 0.9583,  ..., 0.2383, 0.9835, 0.4090],
          [0.8434, 0.5012, 0.1772,  ..., 0.9686, 0.4110, 0.4742]]]])
clip_limit = 40.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
>       input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
E       RuntimeError: maximum size for tensor at dimension 4 is 1 but size is 2

../publishablew/kornia/kornia/kornia/enhance/temp.py:29: RuntimeError
_________ TestEqualization.test_optional_params[cpu-float32-0.0-None] __________

self = <test_equalization.TestEqualization object at 0x7b4bf9cddc60>, clip = 0.0
grid = None, device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
            res = enhance.equalize_clahe(img, grid_size=grid)
        elif grid is None:
>           res = enhance.equalize_clahe(img, clip_limit=clip)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:39: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.1131, 0.7500, 0.8400, 0.8277, 0.0385, 0.4172, 0.4395, 0.7529,
           0.1026, 0.8485, 0.3530, 0.9455, ...         0.0318, 0.1709, 0.5227, 0.8654, 0.8408, 0.6604, 0.1676, 0.5300,
           0.9613, 0.2454, 0.4513, 0.6739]]]])
clip_limit = 0.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
>       input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
E       RuntimeError: maximum size for tensor at dimension 4 is 1 but size is 2

../publishablew/kornia/kornia/kornia/enhance/temp.py:29: RuntimeError
________ TestEqualization.test_optional_params[cpu-float32-None-grid1] _________

self = <test_equalization.TestEqualization object at 0x7b4bf9cddba0>
clip = None, grid = (2, 2), device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
>           res = enhance.equalize_clahe(img, grid_size=grid)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:37: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.2611, 0.6921, 0.9186, 0.9319, 0.2068, 0.6070, 0.9617, 0.7436,
           0.7978, 0.2011, 0.4311, 0.2343, ...         0.2895, 0.6146, 0.2044, 0.6764, 0.6292, 0.4193, 0.2631, 0.7419,
           0.6175, 0.2993, 0.3632, 0.9808]]]])
clip_limit = 40.0, grid_size = (2, 2), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
>       input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
E       RuntimeError: maximum size for tensor at dimension 4 is 5 but size is 10

../publishablew/kornia/kornia/kornia/enhance/temp.py:29: RuntimeError
_________ TestEqualization.test_optional_params[cpu-float32-2.0-grid2] _________

self = <test_equalization.TestEqualization object at 0x7b4bf9cddf00>, clip = 2.0
grid = (2, 2), device = device(type='cpu'), dtype = torch.float32

    @pytest.mark.parametrize("clip, grid", [(0.0, None), (None, (2, 2)), (2.0, (2, 2))])
    def test_optional_params(self, clip, grid, device, dtype):
        C, H, W = 1, 10, 20
        img = torch.rand(C, H, W, device=device, dtype=dtype)
        if clip is None:
            res = enhance.equalize_clahe(img, grid_size=grid)
        elif grid is None:
            res = enhance.equalize_clahe(img, clip_limit=clip)
        else:
>           res = enhance.equalize_clahe(img, clip, grid)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[3.5183e-02, 7.4005e-01, 8.2726e-01, 2.7799e-01, 5.3334e-01,
           8.1967e-01, 1.0059e-01, 1.1362e-01, ...378e-01, 4.5935e-02, 4.2595e-01, 3.1426e-01,
           4.3205e-01, 4.4417e-01, 6.4217e-01, 9.9005e-01, 2.3386e-01]]]])
clip_limit = 2.0, grid_size = (2, 2), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
>       input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
E       RuntimeError: maximum size for tensor at dimension 4 is 5 but size is 10

../publishablew/kornia/kornia/kornia/enhance/temp.py:29: RuntimeError
_ TestEqualization.test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] _

self = <test_equalization.TestEqualization object at 0x7b4bf9cde350>, B = 1
clip = 1, grid = (2, 2), exception_type = <class 'TypeError'>
expected_error_msg = 'Input clip_limit type is not float. Got'

    @pytest.mark.parametrize(
        "B, clip, grid, exception_type, expected_error_msg",
        [
            (0, 1.0, (2, 2), ValueError, "Invalid input tensor, it is empty."),  # from perform_keep_shape_image
            (1, 1, (2, 2), TypeError, "Input clip_limit type is not float. Got"),
            (1, 2.0, 2, TypeError, "Input grid_size type is not Tuple. Got"),
            (1, 2.0, (2, 2, 2), TypeError, "Input grid_size is not a Tuple with 2 elements. Got 3"),
            (1, 2.0, (2, 2.0), TypeError, "Input grid_size type is not valid, must be a Tuple[int, int]"),
            (1, 2.0, (2, 0), ValueError, "Input grid_size elements must be positive. Got"),
        ],
    )
    def test_exception(self, B, clip, grid, exception_type, expected_error_msg):
        C, H, W = 1, 10, 20
        img = torch.rand(B, C, H, W)
        with pytest.raises(exception_type) as errinfo:
            enhance.equalize_clahe(img, clip, grid)
>       assert expected_error_msg in str(errinfo)
E       assert 'Input clip_limit type is not float. Got' in "<ExceptionInfo TypeError('clip_limit must be a float.') tblen=4>"
E        +  where "<ExceptionInfo TypeError('clip_limit must be a float.') tblen=4>" = str(<ExceptionInfo TypeError('clip_limit must be a float.') tblen=4>)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:61: AssertionError
_ TestEqualization.test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] _

self = <test_equalization.TestEqualization object at 0x7b4bf9cdcca0>, B = 1
clip = 2.0, grid = 2, exception_type = <class 'TypeError'>
expected_error_msg = 'Input grid_size type is not Tuple. Got'

    @pytest.mark.parametrize(
        "B, clip, grid, exception_type, expected_error_msg",
        [
            (0, 1.0, (2, 2), ValueError, "Invalid input tensor, it is empty."),  # from perform_keep_shape_image
            (1, 1, (2, 2), TypeError, "Input clip_limit type is not float. Got"),
            (1, 2.0, 2, TypeError, "Input grid_size type is not Tuple. Got"),
            (1, 2.0, (2, 2, 2), TypeError, "Input grid_size is not a Tuple with 2 elements. Got 3"),
            (1, 2.0, (2, 2.0), TypeError, "Input grid_size type is not valid, must be a Tuple[int, int]"),
            (1, 2.0, (2, 0), ValueError, "Input grid_size elements must be positive. Got"),
        ],
    )
    def test_exception(self, B, clip, grid, exception_type, expected_error_msg):
        C, H, W = 1, 10, 20
        img = torch.rand(B, C, H, W)
        with pytest.raises(exception_type) as errinfo:
            enhance.equalize_clahe(img, clip, grid)
>       assert expected_error_msg in str(errinfo)
E       assert 'Input grid_size type is not Tuple. Got' in "<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>"
E        +  where "<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>" = str(<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:61: AssertionError
_ TestEqualization.test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] _

self = <test_equalization.TestEqualization object at 0x7b4bf9cde560>, B = 1
clip = 2.0, grid = (2, 2, 2), exception_type = <class 'TypeError'>
expected_error_msg = 'Input grid_size is not a Tuple with 2 elements. Got 3'

    @pytest.mark.parametrize(
        "B, clip, grid, exception_type, expected_error_msg",
        [
            (0, 1.0, (2, 2), ValueError, "Invalid input tensor, it is empty."),  # from perform_keep_shape_image
            (1, 1, (2, 2), TypeError, "Input clip_limit type is not float. Got"),
            (1, 2.0, 2, TypeError, "Input grid_size type is not Tuple. Got"),
            (1, 2.0, (2, 2, 2), TypeError, "Input grid_size is not a Tuple with 2 elements. Got 3"),
            (1, 2.0, (2, 2.0), TypeError, "Input grid_size type is not valid, must be a Tuple[int, int]"),
            (1, 2.0, (2, 0), ValueError, "Input grid_size elements must be positive. Got"),
        ],
    )
    def test_exception(self, B, clip, grid, exception_type, expected_error_msg):
        C, H, W = 1, 10, 20
        img = torch.rand(B, C, H, W)
        with pytest.raises(exception_type) as errinfo:
            enhance.equalize_clahe(img, clip, grid)
>       assert expected_error_msg in str(errinfo)
E       assert 'Input grid_size is not a Tuple with 2 elements. Got 3' in "<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>"
E        +  where "<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>" = str(<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:61: AssertionError
_ TestEqualization.test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] _

self = <test_equalization.TestEqualization object at 0x7b4bf9cde620>, B = 1
clip = 2.0, grid = (2, 2.0), exception_type = <class 'TypeError'>
expected_error_msg = 'Input grid_size type is not valid, must be a Tuple[int, int]'

    @pytest.mark.parametrize(
        "B, clip, grid, exception_type, expected_error_msg",
        [
            (0, 1.0, (2, 2), ValueError, "Invalid input tensor, it is empty."),  # from perform_keep_shape_image
            (1, 1, (2, 2), TypeError, "Input clip_limit type is not float. Got"),
            (1, 2.0, 2, TypeError, "Input grid_size type is not Tuple. Got"),
            (1, 2.0, (2, 2, 2), TypeError, "Input grid_size is not a Tuple with 2 elements. Got 3"),
            (1, 2.0, (2, 2.0), TypeError, "Input grid_size type is not valid, must be a Tuple[int, int]"),
            (1, 2.0, (2, 0), ValueError, "Input grid_size elements must be positive. Got"),
        ],
    )
    def test_exception(self, B, clip, grid, exception_type, expected_error_msg):
        C, H, W = 1, 10, 20
        img = torch.rand(B, C, H, W)
        with pytest.raises(exception_type) as errinfo:
            enhance.equalize_clahe(img, clip, grid)
>       assert expected_error_msg in str(errinfo)
E       assert 'Input grid_size type is not valid, must be a Tuple[int, int]' in "<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>"
E        +  where "<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>" = str(<ExceptionInfo TypeError('grid_size must be a tuple of two integers.') tblen=4>)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:61: AssertionError
_ TestEqualization.test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] _

self = <test_equalization.TestEqualization object at 0x7b4bf9cde6e0>, B = 1
clip = 2.0, grid = (2, 0), exception_type = <class 'ValueError'>
expected_error_msg = 'Input grid_size elements must be positive. Got'

    @pytest.mark.parametrize(
        "B, clip, grid, exception_type, expected_error_msg",
        [
            (0, 1.0, (2, 2), ValueError, "Invalid input tensor, it is empty."),  # from perform_keep_shape_image
            (1, 1, (2, 2), TypeError, "Input clip_limit type is not float. Got"),
            (1, 2.0, 2, TypeError, "Input grid_size type is not Tuple. Got"),
            (1, 2.0, (2, 2, 2), TypeError, "Input grid_size is not a Tuple with 2 elements. Got 3"),
            (1, 2.0, (2, 2.0), TypeError, "Input grid_size type is not valid, must be a Tuple[int, int]"),
            (1, 2.0, (2, 0), ValueError, "Input grid_size elements must be positive. Got"),
        ],
    )
    def test_exception(self, B, clip, grid, exception_type, expected_error_msg):
        C, H, W = 1, 10, 20
        img = torch.rand(B, C, H, W)
        with pytest.raises(exception_type) as errinfo:
            enhance.equalize_clahe(img, clip, grid)
>       assert expected_error_msg in str(errinfo)
E       assert 'Input grid_size elements must be positive. Got' in "<ExceptionInfo ValueError('All elements of grid_size must be positive.') tblen=4>"
E        +  where "<ExceptionInfo ValueError('All elements of grid_size must be positive.') tblen=4>" = str(<ExceptionInfo ValueError('All elements of grid_size must be positive.') tblen=4>)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:61: AssertionError
______________ TestEqualization.test_exception_tensor_dims[dims0] ______________

self = <test_equalization.TestEqualization object at 0x7b4bf9cde8f0>
dims = (1, 1, 1, 1, 1)

    @pytest.mark.parametrize("dims", [(1, 1, 1, 1, 1), (1, 1)])
    def test_exception_tensor_dims(self, dims):
        img = torch.rand(dims)
        with pytest.raises(ValueError):
>           enhance.equalize_clahe(img)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.2685]]]]), clip_limit = 40.0, grid_size = (8, 8)
slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
>       input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
E       RuntimeError: step is 0 but must be > 0

../publishablew/kornia/kornia/kornia/enhance/temp.py:29: RuntimeError
______________ TestEqualization.test_exception_tensor_dims[dims1] ______________

self = <test_equalization.TestEqualization object at 0x7b4bf9cde9b0>
dims = (1, 1)

    @pytest.mark.parametrize("dims", [(1, 1, 1, 1, 1), (1, 1)])
    def test_exception_tensor_dims(self, dims):
        img = torch.rand(dims)
        with pytest.raises(ValueError):
>           enhance.equalize_clahe(img)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:67: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[0.9108]]]]), clip_limit = 40.0, grid_size = (8, 8)
slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
>       input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
E       RuntimeError: step is 0 but must be > 0

../publishablew/kornia/kornia/kornia/enhance/temp.py:29: RuntimeError
_____________________ TestEqualization.test_gradcheck[cpu] _____________________

self = <test_equalization.TestEqualization object at 0x7b4bf9cdeec0>
device = device(type='cpu')

    def test_gradcheck(self, device):
        torch.random.manual_seed(4)
        bs, channels, height, width = 1, 1, 11, 11
        inputs = torch.rand(bs, channels, height, width, device=device, dtype=torch.float64)
    
        def grad_rot(data, a, b, c):
            rot = rotate(data, torch.tensor(30.0, dtype=data.dtype, device=device))
            return enhance.equalize_clahe(rot, a, b, c)
    
>       self.gradcheck(grad_rot, (inputs, 40.0, (2, 2), True), nondet_tol=1e-4)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:82: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/testing/base.py:143: in gradcheck
    return gradcheck(func, inputs, raise_exception=raise_exception, fast_mode=fast_mode, **kwargs)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2052: in gradcheck
    return _gradcheck_helper(**args)
../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/autograd/gradcheck.py:2074: in _gradcheck_helper
    func_out = func(*tupled_inputs)
../publishablew/kornia/kornia/tests/enhance/test_equalization.py:80: in grad_rot
    return enhance.equalize_clahe(rot, a, b, c)
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[[[0.0000, 0.0234, 0.1876, 0.1713, 0.2786]],

           [[0.0000, 0.5070, 0.7818, 0.3679, 0.6310]],

      ...0.3366, 0.6769, 0.4723]],

           [[0.5591, 0.6181, 0.5055, 0.8121, 0.0323]]]]]],
       grad_fn=<UnfoldBackward0>)
clip_limit = 40.0, grid_size = (2, 2), slow_and_differentiable = True

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
        input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
>       input = input.contiguous().view(*batch_dims, C, grid_size[0], grid_size[1], tile_h, tile_w)
E       RuntimeError: shape '[1, 1, 2, 2, 5, 5]' is invalid for input of size 110

../publishablew/kornia/kornia/kornia/enhance/temp.py:30: RuntimeError
____________________ TestEqualization.test_he[cpu-float32] _____________________

self = <test_equalization.TestEqualization object at 0x7b4bf9cdf700>
img = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])

    def test_he(self, img):
        # should be similar to enhance.equalize but slower. Similar because the lut is computed in a different way.
        clip_limit: float = 0.0
        grid_size: Tuple = (1, 1)
>       res = enhance.equalize_clahe(img, clip_limit=clip_limit, grid_size=grid_size)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:107: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
../publishablew/kornia/kornia/kornia/enhance/temp.py:51: in equalize_clahe
    output[..., i, j, :, :] = apply_clahe(input[..., i, j, :, :])
../publishablew/kornia/kornia/kornia/enhance/temp.py:42: in apply_clahe
    tile_eq = torch.interp(tile_flat, torch.linspace(0, 1, 256), cdf)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'interp'

    def __getattr__(name):
        # Deprecated attrs
        replacement = _deprecated_attrs.get(name)
        if replacement is not None:
            import warnings
    
            warnings.warn(
                f"'{name}' is deprecated, please use '{replacement.__module__}.{replacement.__name__}()'",
                stacklevel=2,
            )
            return replacement()
    
        # Lazy modules
        if name in _lazy_modules:
            return importlib.import_module(f".{name}", __name__)
    
>       raise AttributeError(f"module '{__name__}' has no attribute '{name}'")
E       AttributeError: module 'torch' has no attribute 'interp'

../publishablew/kornia/kornia/venv/lib/python3.10/site-packages/torch/__init__.py:2562: AttributeError
____________________ TestEqualization.test_ahe[cpu-float32] ____________________

self = <test_equalization.TestEqualization object at 0x7b4bf9cdfa60>
img = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])

    def test_ahe(self, img):
        clip_limit: float = 0.0
        grid_size: Tuple = (8, 8)
>       res = enhance.equalize_clahe(img, clip_limit=clip_limit, grid_size=grid_size)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:148: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[[[0.0000, 0.0000]],

           [[0.0526, 0.0526]],

           [[0.1053, 0.1053]],

           [[0.1579, 0...[[0.8421, 0.8421]],

           [[0.8947, 0.8947]],

           [[0.9474, 0.9474]],

           [[1.0000, 1.0000]]]]]])
clip_limit = 0.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
        input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
>       input = input.contiguous().view(*batch_dims, C, grid_size[0], grid_size[1], tile_h, tile_w)
E       RuntimeError: shape '[1, 1, 8, 8, 2, 2]' is invalid for input of size 400

../publishablew/kornia/kornia/kornia/enhance/temp.py:30: RuntimeError
___________________ TestEqualization.test_clahe[cpu-float32] ___________________

self = <test_equalization.TestEqualization object at 0x7b4bf9cdfdc0>
img = tensor([[[[0.0000, 0.0526, 0.1053, 0.1579, 0.2105, 0.2632, 0.3158, 0.3684,
           0.4211, 0.4737, 0.5263, 0.5789, ...         0.4211, 0.4737, 0.5263, 0.5789, 0.6316, 0.6842, 0.7368, 0.7895,
           0.8421, 0.8947, 0.9474, 1.0000]]]])

    def test_clahe(self, img):
        clip_limit: float = 2.0
        grid_size: Tuple = (8, 8)
>       res = enhance.equalize_clahe(img, clip_limit=clip_limit, grid_size=grid_size)

../publishablew/kornia/kornia/tests/enhance/test_equalization.py:189: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/kornia/kornia/kornia/utils/image.py:272: in _wrapper
    output = f(input, *args, **kwargs)
../publishablew/kornia/kornia/kornia/enhance/equalization.py:205: in equalize_clahe
    return equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

input = tensor([[[[[[0.0000, 0.0000]],

           [[0.0526, 0.0526]],

           [[0.1053, 0.1053]],

           [[0.1579, 0...[[0.8421, 0.8421]],

           [[0.8947, 0.8947]],

           [[0.9474, 0.9474]],

           [[1.0000, 1.0000]]]]]])
clip_limit = 2.0, grid_size = (8, 8), slow_and_differentiable = False

    def equalize_clahe(input, clip_limit, grid_size, slow_and_differentiable=False):
        if not isinstance(clip_limit, float):
            raise TypeError('clip_limit must be a float.')
        if not (isinstance(grid_size, tuple) and len(grid_size) == 2 and all((isinstance(x, int) for x in grid_size))):
            raise TypeError('grid_size must be a tuple of two integers.')
        if any((x <= 0 for x in grid_size)):
            raise ValueError('All elements of grid_size must be positive.')
        input = input.float()
        original_shape = input.shape
        batch_dims = original_shape[:-3]
        C, H, W = original_shape[-3:]
        tile_h = H // grid_size[0]
        tile_w = W // grid_size[1]
        pad_h = grid_size[0] * tile_h - H if H % grid_size[0] != 0 else 0
        pad_w = grid_size[1] * tile_w - W if W % grid_size[1] != 0 else 0
        if pad_h > 0 or pad_w > 0:
            input = F.pad(input, (0, pad_w, 0, pad_h), mode='reflect')
        _, H, W = input.shape[-3:]
        input = input.unfold(-2, tile_h, tile_h).unfold(-1, tile_w, tile_w)
>       input = input.contiguous().view(*batch_dims, C, grid_size[0], grid_size[1], tile_h, tile_w)
E       RuntimeError: shape '[1, 1, 8, 8, 2, 2]' is invalid for input of size 400

../publishablew/kornia/kornia/kornia/enhance/temp.py:30: RuntimeError
=========================== short test summary info ============================
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32]
FAILED ../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32]
=================== 21 failed, 3 passed, 1 skipped in 0.51s ====================


Final Test Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'cudagraphs', 'onnxrt', 'inductor', 'tvm', 'jit', 'openxla', None}
model weights cached: ['checkpoints']

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1
collecting ... collected 25 items

../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] PASSED

======================== 24 passed, 1 skipped in 0.22s =========================


Initial Result:
Setting up torch compile...
============================= test session starts ==============================
platform linux -- Python 3.10.12, pytest-8.3.3, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/kornia/kornia/venv/bin/python
cachedir: .pytest_cache

cpu info:
	- Model name: AMD Ryzen 7 PRO 5845 8-Core Processor
	- Architecture: x86_64
	- CPU(s): 16
	- Thread(s) per core: 2
	- CPU max MHz: 4661.7178
	- CPU min MHz: 2200.0000
gpu info: {'GPU 0': 'NVIDIA GeForce RTX 3060'}
main deps:
    - kornia-0.7.4
    - torch-2.5.1+cu124
        - commit: a8d6afb511a69687bbb2b7e88a3cf67917e1697e
        - cuda: 12.4
        - nvidia-driver: 555.42.02
x deps:
    - accelerate-1.1.1
dev deps:
    - kornia_rs-0.1.7
    - onnx-1.17.0
gcc info: (Ubuntu 10.5.0-1ubuntu1~22.04) 10.5.0
available optimizers: {'', 'tvm', 'cudagraphs', 'openxla', 'inductor', 'onnxrt', 'jit', None}
model weights cached: ['checkpoints']

rootdir: /local/data0/moved_data/publishablew/kornia/kornia
configfile: pyproject.toml
plugins: timeout-2.3.1
collecting ... collected 25 items

../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_smoke[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-1] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-None-3] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-1] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-1-3] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-1] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_cardinality[cpu-float32-4-3] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-0.0-None] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-None-grid1] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_optional_params[cpu-float32-2.0-grid2] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[0-1.0-grid0-ValueError-Invalid input tensor, it is empty.] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-1-grid1-TypeError-Input clip_limit type is not float. Got] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-2-TypeError-Input grid_size type is not Tuple. Got] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid3-TypeError-Input grid_size is not a Tuple with 2 elements. Got 3] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid4-TypeError-Input grid_size type is not valid, must be a Tuple[int, int]] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception[1-2.0-grid5-ValueError-Input grid_size elements must be positive. Got] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims0] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_dims[dims1] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_exception_tensor_type PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_gradcheck[cpu] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_jit[cpu-float32] SKIPPED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_module PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_he[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_ahe[cpu-float32] PASSED
../publishablew/kornia/kornia/tests/enhance/test_equalization.py::TestEqualization::test_clahe[cpu-float32] PASSED

======================== 24 passed, 1 skipped in 0.34s =========================
