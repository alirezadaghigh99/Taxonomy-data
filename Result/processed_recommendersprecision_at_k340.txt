output file:
processed_recommendersprecision_at_k340.json
function:
precision_at_k
Error Cases:

Pass or Failed: 0

Related Failed Test Cases:
{'FAILED ../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_precision_at_k', '../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_precision_at_k FAILED', 'FAILED ../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_errors', '../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_errors FAILED'}

All Test Cases On Generated code:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/recommenders/recommenders/venv/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/local/data0/moved_data/Organized_benchmark/.hypothesis/examples'))
rootdir: /local/data0/moved_data/publishablew/recommenders/recommenders
configfile: pyproject.toml
plugins: typeguard-4.4.1, hypothesis-6.123.13, anyio-4.8.0
collecting ... collected 32 items

../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_column_dtypes_match PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_merge_rating PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_merge_ranking PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_rmse PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_mae PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_rsquared PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_exp_var PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_get_top_k_items PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_get_top_k_items_largek PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_ndcg_at_k PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_map PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_map_at_k PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_precision_at_k FAILED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_recall_at_k PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_r_precision PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_auc PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_logloss PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_errors FAILED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_catalog_coverage PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_distributional_coverage PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_item_novelty PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_novelty PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_diversity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_item_serendipity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_serendipity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_diversity_item_feature_vector PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity_item_feature_vector PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_item_serendipity_item_feature_vector PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_serendipity_item_feature_vector PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity_item_feature_vector PASSED

=================================== FAILURES ===================================
__________________________ test_python_precision_at_k __________________________

rating_true =     userID  itemID  rating
0        1       3       3
1        2       1       5
2        2       4       5
3        2... 12       3
14       3      13       2
15       3      14       1
16       1       1       5
17       1       2       4
rating_pred =     userID  itemID  prediction  rating
0        1      12          12       3
1        2      10          14       5
2... 2
15       3      14           5       1
16       1       3          14       5
17       1      10          13       4
rating_nohit =     userID  itemID  prediction
0        1     100          12
1        2     100          14
2        2     100       ...     3     100           6
15       3     100           5
16       1     100          14
17       1     100          13

    def test_python_precision_at_k(rating_true, rating_pred, rating_nohit):
        assert (
>           precision_at_k(
                rating_true=rating_true,
                rating_pred=rating_true,
                col_prediction=DEFAULT_RATING_COL,
                k=10,
            )
            == 0.6
        )

../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:251: in precision_at_k
    return precision_at_k(rating_true, rating_pred, col_user, col_item, col_prediction, relevancy_method, k, threshold)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

rating_true =     userID  itemID  rating
0        1       3       3
1        2       1       5
2        2       4       5
3        2... 12       3
14       3      13       2
15       3      14       1
16       1       1       5
17       1       2       4
rating_pred =     userID  itemID  rating
16       1       1       5
17       1       2       4
0        1       3       3
1        2... 10       3
12       3      11       3
13       3      12       3
14       3      13       2
15       3      14       1
col_user = 'userID', col_item = 'itemID', col_prediction = 'rating'
relevancy_method = 'top_k', k = 10, threshold = 10

    def precision_at_k(rating_true, rating_pred, col_user, col_item, col_prediction, relevancy_method='threshold', k=10, threshold=3.5):
        """
        Calculate precision at K for a recommendation system.
    
        Parameters:
        - rating_true: pandas DataFrame, true ratings with columns [user, item, rating]
        - rating_pred: pandas DataFrame, predicted ratings with columns [user, item, prediction]
        - col_user: str, column name for user
        - col_item: str, column name for item
        - col_prediction: str, column name for prediction
        - relevancy_method: str, method for determining relevancy ('threshold' or other methods)
        - k: int, number of top K items per user
        - threshold: float, threshold for determining relevancy
    
        Returns:
        - float, precision at K
        """
        rating_pred = rating_pred.sort_values(by=[col_user, col_prediction], ascending=[True, False])
        top_k_pred = rating_pred.groupby(col_user).head(k)
        if relevancy_method == 'threshold':
            rating_true['relevant'] = rating_true[col_prediction] >= threshold
        else:
>           raise ValueError('Unsupported relevancy method')
E           ValueError: Unsupported relevancy method

../publishablew/recommenders/recommenders/recommenders/evaluation/temp.py:31: ValueError
______________________________ test_python_errors ______________________________

rating_true =     userID  itemID  rating
0        1       3       3
1        2       1       5
2        2       4       5
3        2... 12       3
14       3      13       2
15       3      14       1
16       1       1       5
17       1       2       4
rating_pred =     userID  itemID  prediction  rating
0        1      12          12       3
1        2      10          14       5
2... 2
15       3      14           5       1
16       1       3          14       5
17       1      10          13       4

    def test_python_errors(rating_true, rating_pred):
        with pytest.raises(ColumnMismatchError):
            rmse(rating_true, rating_true, col_user="not_user")
    
        with pytest.raises(ColumnMismatchError):
            mae(
                rating_pred,
                rating_pred,
                col_rating=DEFAULT_PREDICTION_COL,
                col_user="not_user",
            )
    
        with pytest.raises(ColumnMismatchError):
            rsquared(rating_true, rating_pred, col_item="not_item")
    
        with pytest.raises(ColumnMismatchError):
            exp_var(
                rating_pred,
                rating_pred,
                col_rating=DEFAULT_PREDICTION_COL,
                col_item="not_item",
            )
    
        with pytest.raises(ColumnMismatchError):
>           precision_at_k(rating_true, rating_pred, col_prediction="not_prediction")

../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py:444: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:251: in precision_at_k
    return precision_at_k(rating_true, rating_pred, col_user, col_item, col_prediction, relevancy_method, k, threshold)
../publishablew/recommenders/recommenders/recommenders/evaluation/temp.py:26: in precision_at_k
    rating_pred = rating_pred.sort_values(by=[col_user, col_prediction], ascending=[True, False])
../publishablew/recommenders/recommenders/venv/lib/python3.11/site-packages/pandas/core/frame.py:7172: in sort_values
    keys = [self._get_label_or_level_values(x, axis=axis) for x in by]
../publishablew/recommenders/recommenders/venv/lib/python3.11/site-packages/pandas/core/frame.py:7172: in <listcomp>
    keys = [self._get_label_or_level_values(x, axis=axis) for x in by]
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self =     userID  itemID  prediction  rating
0        1      12          12       3
1        2      10          14       5
2... 2
15       3      14           5       1
16       1       3          14       5
17       1      10          13       4
key = 'not_prediction', axis = 0

    @final
    def _get_label_or_level_values(self, key: Level, axis: AxisInt = 0) -> ArrayLike:
        """
        Return a 1-D array of values associated with `key`, a label or level
        from the given `axis`.
    
        Retrieval logic:
          - (axis=0): Return column values if `key` matches a column label.
            Otherwise return index level values if `key` matches an index
            level.
          - (axis=1): Return row values if `key` matches an index label.
            Otherwise return column level values if 'key' matches a column
            level
    
        Parameters
        ----------
        key : Hashable
            Label or level name.
        axis : int, default 0
            Axis that levels are associated with (0 for index, 1 for columns)
    
        Returns
        -------
        np.ndarray or ExtensionArray
    
        Raises
        ------
        KeyError
            if `key` matches neither a label nor a level
        ValueError
            if `key` matches multiple labels
        """
        axis = self._get_axis_number(axis)
        other_axes = [ax for ax in range(self._AXIS_LEN) if ax != axis]
    
        if self._is_label_reference(key, axis=axis):
            self._check_label_or_level_ambiguity(key, axis=axis)
            values = self.xs(key, axis=other_axes[0])._values
        elif self._is_level_reference(key, axis=axis):
            values = self.axes[axis].get_level_values(key)._values
        else:
>           raise KeyError(key)
E           KeyError: 'not_prediction'

../publishablew/recommenders/recommenders/venv/lib/python3.11/site-packages/pandas/core/generic.py:1911: KeyError
=============================== warnings summary ===============================
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_distributional_coverage
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:959: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    d_coverage = -df_entropy.agg({'entropy(i)': 'sum'})[0]

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_novelty
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_novelty
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:798: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    avg_novelty = reco_item_novelty.agg({'product': 'sum'})[0] / n_recommendations

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_diversity
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_diversity_item_feature_vector
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity_item_feature_vector
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:668: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
  The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.
  
  For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.
  
  
    item_pair_sim[col_sim].fillna(0, inplace=True)

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity_item_feature_vector
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:732: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    avg_diversity = df_user_diversity.agg({'user_diversity': 'mean'})[0]

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_item_serendipity
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_item_serendipity_item_feature_vector
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_serendipity_item_feature_vector
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity_item_feature_vector
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:842: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
  The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.
  
  For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.
  
  
    reco_train_user_item_sim[col_sim].fillna(0, inplace=True)

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity_item_feature_vector
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:902: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    avg_serendipity = df_user_serendipity.agg({'user_serendipity': 'mean'})[0]

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED ../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_precision_at_k
FAILED ../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_errors
================== 2 failed, 30 passed, 14 warnings in 0.58s ===================


Final Test Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/recommenders/recommenders/venv/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/local/data0/moved_data/Organized_benchmark/.hypothesis/examples'))
rootdir: /local/data0/moved_data/publishablew/recommenders/recommenders
configfile: pyproject.toml
plugins: typeguard-4.4.1, hypothesis-6.123.13, anyio-4.8.0
collecting ... collected 32 items

../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_column_dtypes_match PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_merge_rating PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_merge_ranking PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_rmse PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_mae PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_rsquared PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_exp_var PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_get_top_k_items PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_get_top_k_items_largek PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_ndcg_at_k PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_map PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_map_at_k PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_precision_at_k PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_recall_at_k PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_r_precision PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_auc PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_logloss PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_errors PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_catalog_coverage PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_distributional_coverage PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_item_novelty PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_novelty PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_diversity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_item_serendipity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_serendipity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_diversity_item_feature_vector PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity_item_feature_vector PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_item_serendipity_item_feature_vector PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_serendipity_item_feature_vector PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity_item_feature_vector PASSED

=============================== warnings summary ===============================
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_distributional_coverage
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:1714: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    d_coverage = -df_entropy.agg({"entropy(i)": "sum"})[0]

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_novelty
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_novelty
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:1435: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    avg_novelty = reco_item_novelty.agg({"product": "sum"})[0] / n_recommendations

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_diversity
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_diversity_item_feature_vector
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity_item_feature_vector
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:1233: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
  The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.
  
  For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.
  
  
    item_pair_sim[col_sim].fillna(0, inplace=True)

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity_item_feature_vector
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:1348: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    avg_diversity = df_user_diversity.agg({"user_diversity": "mean"})[0]

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_item_serendipity
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_item_serendipity_item_feature_vector
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_serendipity_item_feature_vector
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity_item_feature_vector
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:1511: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
  The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.
  
  For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.
  
  
    reco_train_user_item_sim[col_sim].fillna(0, inplace=True)

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity_item_feature_vector
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:1639: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    avg_serendipity = df_user_serendipity.agg({"user_serendipity": "mean"})[0]

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================= 32 passed, 14 warnings in 0.34s ========================


Initial Result:
============================= test session starts ==============================
platform linux -- Python 3.11.10, pytest-8.3.4, pluggy-1.5.0 -- /local/data0/moved_data/publishablew/recommenders/recommenders/venv/bin/python
cachedir: .pytest_cache
hypothesis profile 'default' -> database=DirectoryBasedExampleDatabase(PosixPath('/local/data0/moved_data/Organized_benchmark/.hypothesis/examples'))
rootdir: /local/data0/moved_data/publishablew/recommenders/recommenders
configfile: pyproject.toml
plugins: typeguard-4.4.1, hypothesis-6.123.13, anyio-4.8.0
collecting ... collected 32 items

../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_column_dtypes_match PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_merge_rating PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_merge_ranking PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_rmse PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_mae PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_rsquared PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_exp_var PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_get_top_k_items PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_get_top_k_items_largek PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_ndcg_at_k PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_map PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_map_at_k PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_precision_at_k PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_recall_at_k PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_r_precision PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_auc PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_logloss PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_python_errors PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_catalog_coverage PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_distributional_coverage PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_item_novelty PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_novelty PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_diversity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_item_serendipity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_serendipity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_diversity_item_feature_vector PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity_item_feature_vector PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_item_serendipity_item_feature_vector PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_serendipity_item_feature_vector PASSED
../publishablew/recommenders/recommenders/tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity_item_feature_vector PASSED

=============================== warnings summary ===============================
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_distributional_coverage
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:1714: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    d_coverage = -df_entropy.agg({"entropy(i)": "sum"})[0]

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_novelty
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_novelty
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:1435: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    avg_novelty = reco_item_novelty.agg({"product": "sum"})[0] / n_recommendations

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_diversity
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_diversity_item_feature_vector
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity_item_feature_vector
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:1233: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
  The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.
  
  For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.
  
  
    item_pair_sim[col_sim].fillna(0, inplace=True)

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_diversity_item_feature_vector
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:1348: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    avg_diversity = df_user_diversity.agg({"user_diversity": "mean"})[0]

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_item_serendipity
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_item_serendipity_item_feature_vector
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_user_serendipity_item_feature_vector
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity_item_feature_vector
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:1511: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.
  The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.
  
  For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.
  
  
    reco_train_user_item_sim[col_sim].fillna(0, inplace=True)

tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity
tests/unit/recommenders/evaluation/test_python_evaluation.py::test_serendipity_item_feature_vector
  /local/data0/moved_data/publishablew/recommenders/recommenders/recommenders/evaluation/python_evaluation.py:1639: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`
    avg_serendipity = df_user_serendipity.agg({"user_serendipity": "mean"})[0]

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
======================= 32 passed, 14 warnings in 0.33s ========================
